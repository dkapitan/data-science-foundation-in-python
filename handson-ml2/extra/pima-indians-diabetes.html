
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Pima Indians Diabetes &#8212; Data Science Foundation Curriculum</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://jads-nl.github.io/data-science-foundation-curriculum/handson-ml2/extra/pima-indians-diabetes.html" />
    <link rel="shortcut icon" href="../../_static/favicon-32x32.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Introduction to data visualization with Python" href="../../visualization/introduction-to-interactive-data-visualization.html" />
    <link rel="prev" title="Ames Housing case - examples of possible solutions" href="ames-housing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/jads-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science Foundation Curriculum</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../index.html">
   Why this JupyterBook?
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Statistical Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../islr/introduction.html">
   Introduction to ISLRv2
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../islr/labs.html">
   Labs
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_02.3_introduction.html">
     Lab 2.3: Introduction to Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_03.6_linear_regression.html">
     Lab 3.6: Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_04.7_classification_methods.html">
     Lab 4.7: Classification Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_05.3_cross_validation_and_the_bootstrap.html">
     Lab 5.3: Cross-Validation and the Bootstrap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.1_subset_selection_methods.html">
     Lab 6.5.1: Subset Selection Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.2_ridge_regression_and_the_lasso.html">
     Lab 6.5.2: Ridge Regression and the Lasso
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.3_pcr_and_pls_regression.html">
     Lab 6.5.3: PCR and PLS Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_07.8_non_linear_modelling.html">
     Lab 7.8: Non-linear Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_08.3_decision_trees.html">
     Lab 8.3: Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_09.6_support_vector_machines.html">
     Lab 9.6: Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.2_multilayer_network_on_mnist_digit_data.html">
     Lab 10.9.2: A Multilayer Network on the MNIST Digit Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.3_convolutional_neural_networks.html">
     Lab 10.9.3: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_12.5_unsupervised_learning.html">
     Lab 12.5: Unsupervised Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../islr/exercises.html">
   Exercises
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter2/index.html">
     Chapter 2
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise1.html">
       Exercise 2.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise2.html">
       Exercise 2.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise3.html">
       Exercise 2.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise4.html">
       Exercise 2.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise5.html">
       Exercise 2.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise6.html">
       Exercise 2.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise7.html">
       Exercise 2.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise8.html">
       Exercise 2.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise9.html">
       Exercise 2.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise10.html">
       Exercise 2.10
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter3/index.html">
     Chapter 3
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise1.html">
       Exercise 3.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise2.html">
       Exercise 3.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise3.html">
       Exercise 3.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise4.html">
       Exercise 3.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise5.html">
       Exercise 3.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise6.html">
       Exercise 3.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise7.html">
       Exercise 3.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise8.html">
       Exercise 3.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise9.html">
       Exercise 3.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise10.html">
       Exercise 3.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise11.html">
       Exercise 3.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise12.html">
       Exercise 3.12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise13.html">
       Exercise 3.13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise14.html">
       Exercise 3.14
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise15.html">
       Exercise 3.15
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter4/index.html">
     Chapter 4
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise1.html">
       Exercise 4.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise2.html">
       Exercise 4.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise3.html">
       Exercise 4.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise4.html">
       Exercise 4.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise5.html">
       Exercise 4.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise6.html">
       Exercise 4.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise7.html">
       Exercise 4.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise8.html">
       Exercise 4.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise9.html">
       Exercise 4.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise10.html">
       Exercise 10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise11.html">
       Exercise 11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise12.html">
       Exercise 12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise13.html">
       Exercise 4.13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise14.html">
       Exercise 4.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise15.html">
       Exercise 4.12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise16.html">
       Exercise 4.16
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter5/index.html">
     Chapter 5
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise1.html">
       Exercise 5.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise2.html">
       Exercise 5.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise3.html">
       Problem 5.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise4.html">
       Exercise 5.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise5.html">
       Exercise 5.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise6.html">
       Exercise 5.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise7.html">
       Exercise 5.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise8.html">
       Exercise 5.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise9.html">
       Exercise 5.9
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter6/index.html">
     Chapter 6
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise1.html">
       Exercise 6.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise2.html">
       Exercise 6.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise3.html">
       Exercise 6.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise4.html">
       Exercise 6.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise5.html">
       Exercise 6.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise6.html">
       Exercise 6.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise7.html">
       Exercise 6.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise8.html">
       Exercise 6.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise9.html">
       Exercise 6.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise10.html">
       Exercise 6.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise11.html">
       Exercise 6.11
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter7/index.html">
     Chapter 7
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise1.html">
       Exercise 7.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise2.html">
       Exercise 7.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise3.html">
       Exercise 7.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise4.html">
       Exercise 7.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise5.html">
       Exercise 7.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise6.html">
       Exercise 7.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise7.html">
       Exercise 7.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise8.html">
       Exercise 7.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise9.html">
       Exercise 7.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise10.html">
       Exercise 7.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise11.html">
       Exercise 7.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise12.html">
       Exercise 7.12
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter8/index.html">
     Chapter 8
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise1.html">
       Exercise 8.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise2.html">
       Exercise 8.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise3.html">
       Exercise 8.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise4.html">
       Exercise 8.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise5.html">
       Exercise 8.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise6.html">
       Exercise 8.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise7.html">
       Exercise 8.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise8.html">
       Exercise 8.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise9.html">
       Exercise 8.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise10.html">
       Exercise 8.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise11.html">
       Exercise 8.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise12.html">
       Exercise 8.12
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter9/index.html">
     Chapter 9
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise1.html">
       Exercise 9.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise2.html">
       Exercise 9.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise3.html">
       Exercise 9.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise4.html">
       Exercise 9.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise5.html">
       Exercise 9.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise6.html">
       Exercise 9.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise7.html">
       Exercise 9.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise8.html">
       Exercise 9.8
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter12/index.html">
     Chapter 12
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise1.html">
       Exercise 12.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise2.html">
       Exercise 12.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise3.html">
       Exercise 12.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise4.html">
       Exercise 12.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise5.html">
       Exercise 12.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise6.html">
       Exercise 12.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise7.html">
       Exercise 12.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise8.html">
       Exercise 10.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise9.html">
       Exercise 12.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise10.html">
       Exercise 12.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise11.html">
       Exercise 12.11
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hands-on Machine Learning in Python
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../introduction.html">
   Hands-on Machine Learning with Aurélien Géron
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/01_the_machine_learning_landscape.html">
     Chapter 1 – The Machine Learning landscape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/02_end_to_end_machine_learning_project.html">
     Chapter 2 – End-to-end Machine Learning project
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/03_classification.html">
     Chapter 3 – Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/04_training_linear_models.html">
     Chapter 4 – Training Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/05_support_vector_machines.html">
     Chapter 5 – Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/06_decision_trees.html">
     Chapter 6 – Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/07_ensemble_learning_and_random_forests.html">
     Chapter 7 – Ensemble Learning and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/08_dimensionality_reduction.html">
     Chapter 8 – Dimensionality Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/09_unsupervised_learning.html">
     Chapter 9 – Unsupervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/10_neural_nets_with_keras.html">
     Chapter 10 – Introduction to Artificial Neural Networks with Keras
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/11_training_deep_neural_networks.html">
     Chapter 11 – Training Deep Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/12_custom_models_and_training_with_tensorflow.html">
     Chapter 12 – Custom Models and Training with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/13_loading_and_preprocessing_data.html">
     Chapter 13 – Loading and Preprocessing Data with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/14_deep_computer_vision_with_cnns.html">
     Chapter 14 – Deep Computer Vision Using Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/15_processing_sequences_using_rnns_and_cnns.html">
     Chapter 15 – Processing Sequences Using RNNs and CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/16_nlp_with_rnns_and_attention.html">
     Chapter 16 – Natural Language Processing with RNNs and Attention**
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/17_autoencoders_and_gans.html">
     Chapter 17 – Autoencoders and GANs**
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/18_reinforcement_learning.html">
     Chapter 18 – Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/19_training_and_deploying_at_scale.html">
     Chapter 19 – Training and Deploying TensorFlow Models at Scale
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../extra.html">
   Miscellaneous tips &amp; tricks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="overfitting.html">
     Overfitting vs. underfitting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="effective-python-and-idiomatic-pandas.html">
     Effective Python and idiomatic pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/math_linear_algebra.html">
     Math primer - Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/math_differential_calculus.html">
     Math primer - Differential Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/extra_autodiff.html">
     Implementation of autodiff techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../original/extra_gradient_descent_comparison.html">
     Comparison of Batch, Mini-Batch and Stochastic Gradient Descent
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../projects.html">
   Discover projects
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="pandas-profiling.html">
     Pandas profiling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ames-housing.html">
     Ames Housing case - examples of possible solutions
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Pima Indians Diabetes
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data visualization with Altair
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../visualization/introduction-to-interactive-data-visualization.html">
   Introduction to data visualization with Python
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../visualization/altair_get_started.html">
   Getting Started with Altair
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_introduction.html">
     Introduction to Altair
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_marks_encoding.html">
     Data Types, Graphical Marks, and Visual Encoding Channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_data_transformation.html">
     Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_scales_axes_legends.html">
     Scales, Axes, and Legends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_view_composition.html">
     Multi-View Composition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_interaction.html">
     Interaction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_cartographic.html">
     Cartographic Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_debugging.html">
     Altair Debugging Guide
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Interpretable Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../iml/introduction.html">
   Introduction to IML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_partial_dependence.html">
     Partial Dependence and Individual Conditional Expectation Plots
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_permutation_importance.html">
     Permutation Importance vs Random Forest Feature Importance (MDI)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_permutation_importance_multicollinear.html">
     Permutation Importance with Multicollinear or Correlated Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/interpreting-machine-learning-models.html">
     IML with Pima Indians and the Titanic datasets
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Principles of time-series forecasting
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../fpp/introduction.html">
   Introduction to FPP3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../fpp/examples-time-series-forecasting-with-python.html">
   Examples of time-series forecasting with Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Natural language processing with spaCy
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/introduction.html">
   Introduction to NLP with spaCy
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../nlp/dutch-restaurant-reviews.html">
   Dutch restaurant reviews
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-dutch-restaurant-reviews.html">
     Analyzing Dutch restaurant reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/prepare-restoreviews-dataset.html">
     Fetch and prepare reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-pipeline-example.html">
     Predict detractors from reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/language-detection-with-character-quadgrams.html">
     Extra: language detection with character quadgrams
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-model-sizes.html">
     Extra: plot of transformer model sizes
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/handson-ml2/extra/pima-indians-diabetes.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/jads-nl/data-science-foundation-curriculum"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/jads-nl/data-science-foundation-curriculum/issues/new?title=Issue%20on%20page%20%2Fhandson-ml2/extra/pima-indians-diabetes.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/jads-nl/data-science-foundation-curriculum/main?urlpath=tree/data_science_foundation_curriculum/handson-ml2/extra/pima-indians-diabetes.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/jads-nl/data-science-foundation-curriculum/blob/main/data_science_foundation_curriculum/handson-ml2/extra/pima-indians-diabetes.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#attribution">
   Attribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-dm-phase-1-business-understanding">
   CRISP-DM Phase 1: Business Understanding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#understanding-type-2-diabetes">
     Understanding Type-2 diabetes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#background">
     Background
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-dm-phase-2-data-understanding">
   CRISP-DM Phase 2: Data Understanding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-do-the-variables-in-the-data-represent">
     What do the variables in the data represent?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-was-the-sample-obtained-what-is-the-data-generating-model">
     How was the sample obtained? What is the data generating model?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepare-the-python-configuration">
     Prepare the python configuration
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#importing-the-data">
   Importing the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#checks-on-data-quality">
   Checks on data quality
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspect-whether-the-data-has-missing-values">
     Inspect whether the data has missing values
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspect-the-outcome-variable">
     Inspect the outcome variable
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspect-the-distribution-of-the-predictor-variables">
     Inspect the distribution of the predictor variables.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions-from-the-descriptives-of-the-data">
     Conclusions from the descriptives of the data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-dm-phase-3-prepare-the-data">
   CRISP-DM Phase 3: Prepare the data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dealing-with-outliers">
     Dealing with outliers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-training-set-and-test-set">
     Create training set and test set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#descriptives-of-the-training-data-set">
     Descriptives of the training data set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dealing-with-missing-values">
     Dealing with missing values
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions-on-missing-values-sofar">
     Conclusions on missing values sofar
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#replace-the-zero-values-with-the-median-for-the-training-set-and-the-test-set">
     Replace the zero values with the median for the training set and the test set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspecting-the-distribution-of-the-predictors-after-imputation">
     Inspecting the distribution of the predictors after imputation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-correlations-among-the-explanatory-variables-and-the-outcome">
     Explore correlations among the explanatory variables and the outcome
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-bivariate-relations-between-the-predictor-variables">
     Explore bivariate relations between the predictor variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-bivariate-relations-between-the-predictor-variables-with-color-coding-for-the-outcome-variable">
     Explore bivariate relations between the predictor variables with color coding for the outcome variable
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions-from-the-bivariate-distributions">
     Conclusions from the bivariate distributions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-distribution-of-explanatory-variables-for-each-group-diabetes-type-2-versus-healthy">
     Explore distribution of explanatory variables for each group (diabetes type-2 versus healthy)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#separate-the-predictor-variables-from-the-outcome-variable">
     Separate the predictor variables from the outcome variable
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scale-the-data">
     Scale the data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-dm-phase-4-modeling">
   CRISP-DM Phase 4: Modeling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-evaluation">
     Model evaluation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#results-logistic-regression-analysis">
     Results logistic regression analysis
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy-sensitivity-and-specificity">
     Accuracy, Sensitivity and Specificity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lasso">
     Lasso
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#k-nearest-neighbors">
     K-nearest neighbors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-bayes-classifier">
     Naive Bayes classifier
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest-classifier">
     Random Forest Classifier
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gradient-boosting-classifier">
     Gradient Boosting Classifier
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary-of-the-results">
   Summary of the results
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretation-of-the-results">
   Interpretation of the results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comment-from-daniel">
     Comment from Daniel
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-dm-phase-5-evaluation">
   CRISP-DM Phase 5: Evaluation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#back-to-modeling-phase-4-transform-some-predictor-variables">
   Back to Modeling Phase 4: Transform some predictor variables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression-with-transformed-predictors">
     Logistic regression with transformed predictors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions-transformation-plots">
     Conclusions transformation plots
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-all-models-on-transformed-predictor-variables">
     Run all models on transformed predictor variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions-transformed-variables">
     Conclusions transformed variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#work-in-progress-smote-sampling">
     Work in progress: SMOTE sampling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#work-in-progress-explanation-of-the-models">
     Work in progress: explanation of the models
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Pima Indians Diabetes</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#attribution">
   Attribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-dm-phase-1-business-understanding">
   CRISP-DM Phase 1: Business Understanding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#understanding-type-2-diabetes">
     Understanding Type-2 diabetes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#background">
     Background
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-dm-phase-2-data-understanding">
   CRISP-DM Phase 2: Data Understanding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-do-the-variables-in-the-data-represent">
     What do the variables in the data represent?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-was-the-sample-obtained-what-is-the-data-generating-model">
     How was the sample obtained? What is the data generating model?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepare-the-python-configuration">
     Prepare the python configuration
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#importing-the-data">
   Importing the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#checks-on-data-quality">
   Checks on data quality
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspect-whether-the-data-has-missing-values">
     Inspect whether the data has missing values
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspect-the-outcome-variable">
     Inspect the outcome variable
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspect-the-distribution-of-the-predictor-variables">
     Inspect the distribution of the predictor variables.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions-from-the-descriptives-of-the-data">
     Conclusions from the descriptives of the data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-dm-phase-3-prepare-the-data">
   CRISP-DM Phase 3: Prepare the data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dealing-with-outliers">
     Dealing with outliers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-training-set-and-test-set">
     Create training set and test set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#descriptives-of-the-training-data-set">
     Descriptives of the training data set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dealing-with-missing-values">
     Dealing with missing values
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions-on-missing-values-sofar">
     Conclusions on missing values sofar
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#replace-the-zero-values-with-the-median-for-the-training-set-and-the-test-set">
     Replace the zero values with the median for the training set and the test set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspecting-the-distribution-of-the-predictors-after-imputation">
     Inspecting the distribution of the predictors after imputation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-correlations-among-the-explanatory-variables-and-the-outcome">
     Explore correlations among the explanatory variables and the outcome
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-bivariate-relations-between-the-predictor-variables">
     Explore bivariate relations between the predictor variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-bivariate-relations-between-the-predictor-variables-with-color-coding-for-the-outcome-variable">
     Explore bivariate relations between the predictor variables with color coding for the outcome variable
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions-from-the-bivariate-distributions">
     Conclusions from the bivariate distributions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-distribution-of-explanatory-variables-for-each-group-diabetes-type-2-versus-healthy">
     Explore distribution of explanatory variables for each group (diabetes type-2 versus healthy)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#separate-the-predictor-variables-from-the-outcome-variable">
     Separate the predictor variables from the outcome variable
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scale-the-data">
     Scale the data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-dm-phase-4-modeling">
   CRISP-DM Phase 4: Modeling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-evaluation">
     Model evaluation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#results-logistic-regression-analysis">
     Results logistic regression analysis
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy-sensitivity-and-specificity">
     Accuracy, Sensitivity and Specificity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lasso">
     Lasso
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#k-nearest-neighbors">
     K-nearest neighbors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-bayes-classifier">
     Naive Bayes classifier
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest-classifier">
     Random Forest Classifier
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gradient-boosting-classifier">
     Gradient Boosting Classifier
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary-of-the-results">
   Summary of the results
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretation-of-the-results">
   Interpretation of the results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comment-from-daniel">
     Comment from Daniel
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-dm-phase-5-evaluation">
   CRISP-DM Phase 5: Evaluation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#back-to-modeling-phase-4-transform-some-predictor-variables">
   Back to Modeling Phase 4: Transform some predictor variables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression-with-transformed-predictors">
     Logistic regression with transformed predictors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions-transformation-plots">
     Conclusions transformation plots
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-all-models-on-transformed-predictor-variables">
     Run all models on transformed predictor variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusions-transformed-variables">
     Conclusions transformed variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#work-in-progress-smote-sampling">
     Work in progress: SMOTE sampling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#work-in-progress-explanation-of-the-models">
     Work in progress: explanation of the models
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <p><a href="https://colab.research.google.com/github/laurencefrank/JADS_DS/blob/main/ReportDiscoverProjectLaurenceFrank.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="tex2jax_ignore mathjax_ignore section" id="pima-indians-diabetes">
<h1>Pima Indians Diabetes<a class="headerlink" href="#pima-indians-diabetes" title="Permalink to this headline">¶</a></h1>
<div class="section" id="attribution">
<h2>Attribution<a class="headerlink" href="#attribution" title="Permalink to this headline">¶</a></h2>
<p>This notebook presents a solution to the Pima Indians Diabetes prediction problem. It was written by Laurence Frank. The code has been reviewed and improved by Daniel Kapitan for educational purposes.</p>
<p>© 2020 by <a class="reference external" href="https://www.linkedin.com/in/laurencefrank/">Laurence Frank</a> and <a class="reference external" href="https://www.linkedin.com/in/dkapitan">Daniel Kapitan</a>. This work is licensed under a <a class="reference external" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>
<p><img alt="CC BY-SA 4.0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></p>
</div>
<div class="section" id="crisp-dm-phase-1-business-understanding">
<h2>CRISP-DM Phase 1: Business Understanding<a class="headerlink" href="#crisp-dm-phase-1-business-understanding" title="Permalink to this headline">¶</a></h2>
<div class="section" id="understanding-type-2-diabetes">
<h3>Understanding Type-2 diabetes<a class="headerlink" href="#understanding-type-2-diabetes" title="Permalink to this headline">¶</a></h3>
<p>A description of the data are available at <a class="reference external" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database">Kaggle</a>:</p>
<p>The following two articles give more background about this data set:</p>
<ul class="simple">
<li><p>Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., &amp; Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. <em>In Proceedings of the Symposium on Computer Applications and Medical Care</em> (pp. 261–265). IEEE Computer Society Press.</p></li>
<li><p>Schulz, L.O., Bennett, P.H., Ravussin, E., Kidd, J.R., Kidd, K.K., Esparza, J., Valencia, M.E. (2006). Effects of Traditional and Western Environments on Prevalence of Type 2 Diabetes in Pima Indians in Mexico and the U.S. <em>Diabetes Care 29</em>:1866–187</p></li>
</ul>
</div>
<div class="section" id="background">
<h3>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h3>
<p>The article by Smith et al. (1988) explains more about the background of the data. The population for this study was the Pima Indian population near Phoenix, Arizona. That population has been under continuous study since 1965 by the National Institute of Diabetes and Digestive and Kidney Diseases because of its high incidence rate of diabetes.</p>
<p>Eight variables were chosen to form the basis for forecasting the onset of diabetes within five years in Pima Indian women. Those variables were chosen because they have been found to be significant riskfactors for diabetes among Pimas or other populations.</p>
<p><em>Objectives</em></p>
<p>The goal of this analysis is:</p>
<ul class="simple">
<li><p>To explore how the eight variables are related to onset of diabetes within five years in this sample of Pima Indian women;</p></li>
<li><p>To explore whether it is possible to predict the onset of diabetes with considerable precision.</p></li>
</ul>
<p><em>Business success criteria</em>
The project will be succesfull:</p>
<ul class="simple">
<li><p>when we will have more insight into how these eight risk factors are related to the onset of diabetes.</p></li>
<li><p>when we can achieve a sensitivity of 0.75 or higher in predicting diabetes.</p></li>
</ul>
</div>
</div>
<div class="section" id="crisp-dm-phase-2-data-understanding">
<h2>CRISP-DM Phase 2: Data Understanding<a class="headerlink" href="#crisp-dm-phase-2-data-understanding" title="Permalink to this headline">¶</a></h2>
<p>Data understanding comprises the following activities:</p>
<p><strong>Collect Initial Data</strong></p>
<p>In this project the data are already collected. The sample consists of 768 women Pima Indians.
The following variables are available in the data set:</p>
<ol class="simple">
<li><p>Number of pregnancies</p></li>
<li><p>Glucose</p></li>
<li><p>BloodPressure: Diastolic blood pressure (mm Hg)</p></li>
<li><p>Skin thickness: Triceps skin fold thickness (mm)</p></li>
<li><p>Insulin: 2-Hour serum insulin (mu U/ml)</p></li>
<li><p>BMI: Body mass index (weight in kg/(height in m)^2)</p></li>
<li><p>Diabetes pedigree function</p></li>
<li><p>Age: Age (years)</p></li>
<li><p>Outcome (binary 0, 1) for diabetes (1) and no diabetes (2)</p></li>
</ol>
<div class="section" id="what-do-the-variables-in-the-data-represent">
<h3>What do the variables in the data represent?<a class="headerlink" href="#what-do-the-variables-in-the-data-represent" title="Permalink to this headline">¶</a></h3>
<p><em>Number of pregnancies</em> is clear.</p>
<p><em>Glucose</em>
The variable <code class="docutils literal notranslate"><span class="pre">glucose</span></code> respresents plasma glucose concentration at 2 hours in an oral glucose tolerance test. Googling for reference values in persons without and with diabetes reveals <a class="reference external" href="https://www.mayoclinic.org/tests-procedures/glucose-tolerance-test/about/pac-20394296">https://www.mayoclinic.org/tests-procedures/glucose-tolerance-test/about/pac-20394296</a> and <a class="reference external" href="https://dtc.ucsf.edu/types-of-diabetes/type2/understanding-type-2-diabetes/basic-facts/diagnosing-diabetes/:">https://dtc.ucsf.edu/types-of-diabetes/type2/understanding-type-2-diabetes/basic-facts/diagnosing-diabetes/:</a></p>
<p>If you’re being tested for type 2 diabetes, two hours after drinking the glucose solution:</p>
<ul class="simple">
<li><p>A normal blood glucose level is lower than 140 mg/dL (7.8 mmol/L).</p></li>
<li><p>A blood glucose level between 140 and 199 mg/dL (7.8 and 11 mmol/L) is considered impaired glucose tolerance, or prediabetes. If you have prediabetes, you’re at risk of eventually developing type 2 diabetes. You’re also at risk of developing heart disease, even if you don’t develop diabetes.</p></li>
<li><p>A blood glucose level of 200 mg/dL (11.1 mmol/L) or higher may indicate diabetes.</p></li>
</ul>
<p><em>Blood pressure</em></p>
<p>Reference values for diastolic blood pressure are:
For a normal reading, your blood pressure needs to show a top number (systolic pressure) that’s between 90 and less than 120 and a bottom number (diastolic pressure) that’s between 60 and less than 80.</p>
<p><em>Skin thickness</em></p>
<p><a class="reference external" href="https://nutritionalassessment.mumc.nl/en/skinfold-measurements">Googling</a> reveals that triceps skin fold thickness is used to estimate the total percentage of body fat.
A skinfold caliper is used to assess the skinfold thickness, so that a prediction of the total amount of body fat can be made. This method is based on the hypothesis that the body fat is equally distributed over the body and that the thickness of the skinfold is a measure for subcutaneous fat.
Reference values are: For adults, the standard normal values for triceps skinfolds are: 2.5mm (men) or about 20% fat; 18.0mm (women) or about 30% fat.</p>
<p><em>Insulin</em>.</p>
<p>2 hours after glucose administration the reference values are: 16-166 mIU/L (111-1153 pmol/L)  Uh/ml</p>
<p><em>BMI</em></p>
<p>Reference values are:</p>
<ul class="simple">
<li><p>Below 18.5 = underweight range.</p></li>
<li><p>Between 18.5 and 24.9 = healthy weight range.</p></li>
<li><p>Between 25 and 29.9 = overweight range.</p></li>
<li><p>Between 30 and 39.9 = obese range.</p></li>
</ul>
<p><em>Diabetes pedigree function</em></p>
<p>The Diabetes Pedigree Function (DPF) was developed by Smith, et al. (1988) to provide a synthesis of the diabetes mellitus history in relatives and the genetic relationship of those relatives to the subject. The DPF uses information from parents, grandparents, siblings, aunts and uncles, and first cousins. It provides a measure of the expected genetic influence of affected and unaffected relatives on the subject’s eventual diabetes risk.
The value of the DPF increases as the number of relatives who developed DM increases, as the age at which those relaves developed DM decreases,and as the percentage of genes that they share with the subject increases. The value of the DPF decreases as the number of relatives who never developed DM increases, as their ages at their last examination increase, and as the percent of genes that they share with the subject increases.</p>
<p><strong>How are glucose and insulin related with each other in connection to Type-2 diabetes?</strong></p>
<p><a class="reference external" href="https://www.diabetes.org/diabetes-risk/prevention/high-blood-sugar">See this webpage</a>:
If you have type 2 diabetes, your body does not use insulin properly. This is called insulin resistance. At first, the beta cells make extra insulin to make up for it. But, over time your pancreas can’t make enough insulin to keep your blood sugar at normal levels. Type 2 diabetes develops most often in middle-aged and older adults but can appear in young people.</p>
</div>
<div class="section" id="how-was-the-sample-obtained-what-is-the-data-generating-model">
<h3>How was the sample obtained? What is the data generating model?<a class="headerlink" href="#how-was-the-sample-obtained-what-is-the-data-generating-model" title="Permalink to this headline">¶</a></h3>
<p>The cases in the data set were selected as follows.</p>
<p>Diabetes was defined as a plasma glucose concentration greater then 200 mg/dl two hours following the ingestion of 75 gm of a carbohydrate solution. Cases were drawn from the pool of examinations which met the following criteria:</p>
<ol class="simple">
<li><p>The subject was female.</p></li>
<li><p>The subject was &gt;= 21 year of age at the time of the index examination. An index examination refers to the study that was chosen for use in this model. It does not necesarily correspond to the chronologically first examination for this subject.</p></li>
<li><p>Only one examination was selected per subject. That examination was one that revealed a nondiabetic GTT and met one of the following two criteria:</p>
<ul class="simple">
<li><p>Diabetes was diagnosed within five years of the examination, OR</p></li>
<li><p>A GTT performed five or more years later failed to reveal diabetes melitus.</p></li>
</ul>
</li>
<li><p>If diabetes occurred within one year of an examination, that examination was excluded from the study to remove from the forecasting model those cases that were potentialy easier to forecast. In 75% of the excluded examinations, DM was diagnosed within six months.</p></li>
</ol>
<p><strong>In conlusion</strong>, the outcome variable (diabetes yes or no) reflects the status of the subjects <em>at least five years later</em> than the predicting variables were measured. This means that the predicting variables reflect the situation of the subject before being eventually diagnosed with diabetes.</p>
<p>These data are from a select sample of Pima Indians, where only women from 21 years and older are included. It is known that this ethnic group has a very high incidence of Diabetes type 2.</p>
<p>From a methodological perspective, the design of this study is far from optimal. First, there seem to be more measurements available for the subjects: subjects were measured several times, but only one occasion is included in the data set. From a statistical point of vue this means that relevant information is thrown away: how the values on the risk factors evolve over time, which allows for better prediction.
Also, the subjects who were diagnosed with diabetes within one year of an examination were removed from the study because they were potentially easier to forecast. This information would have been helpfull. I guess the goal of this study is to be able to identify persons who are at risk for developping type-2 diabetes to be able to work on prevention. I understand that it is better to identify these persons 5 years before onset of the disease, but one year before is also usefull information. A longitudinal prospective study would give more information about how the values of the risk factors evolve over time and would allow for better prediction models.</p>
<p>In fact, what we are asked to do with the data is to predict based on only one measurement occasion if a Pima-Indian woman will develop Diabetes Type-2 in five years time or more. But in the daily practice, more measurement values are available. I assume that the study design is not optimal and that it will be difficult to develop a good prediction model with these data.</p>
</div>
<div class="section" id="prepare-the-python-configuration">
<h3>Prepare the python configuration<a class="headerlink" href="#prepare-the-python-configuration" title="Permalink to this headline">¶</a></h3>
<p>Load the packages and configure the plot environment. Uncomment the followig cell and run it when using Google Colab.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># # update Google Colab</span>
<span class="c1"># # we want to use sklearn &gt;= 0.23 for visualizing pipelines</span>
<span class="c1"># !pip install -U scikit-learn shap imblearn</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">copy</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">tarfile</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">importlib</span><span class="o">,</span> <span class="nn">pprint</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">requests.compat</span> <span class="kn">import</span> <span class="n">urljoin</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_transformer</span><span class="p">,</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">enet_path</span><span class="p">,</span>
    <span class="n">Lasso</span><span class="p">,</span>
    <span class="n">LassoCV</span><span class="p">,</span>
    <span class="n">lasso_path</span><span class="p">,</span>
    <span class="n">LogisticRegression</span><span class="p">,</span>
    <span class="n">Ridge</span><span class="p">,</span>
    <span class="n">RidgeCV</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">accuracy_score</span><span class="p">,</span>
    <span class="n">classification_report</span><span class="p">,</span>
    <span class="n">confusion_matrix</span><span class="p">,</span>
    <span class="n">f1_score</span><span class="p">,</span>
    <span class="n">mean_squared_error</span><span class="p">,</span>
    <span class="n">plot_confusion_matrix</span><span class="p">,</span>
    <span class="n">precision_recall_curve</span><span class="p">,</span>
    <span class="n">precision_score</span><span class="p">,</span>
    <span class="n">plot_precision_recall_curve</span><span class="p">,</span>
    <span class="n">r2_score</span><span class="p">,</span>
    <span class="n">recall_score</span><span class="p">,</span>
    <span class="n">roc_auc_score</span><span class="p">,</span>
    <span class="n">roc_curve</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">cross_val_score</span><span class="p">,</span>
    <span class="n">GridSearchCV</span><span class="p">,</span>
    <span class="n">KFold</span><span class="p">,</span>
    <span class="n">StratifiedShuffleSplit</span><span class="p">,</span>
    <span class="n">train_test_split</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">RobustScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="c1"># statsmodels is a Python module that provides classes and functions</span>
<span class="c1"># for the estimation of many different statistical models, as well as</span>
<span class="c1"># for conducting statistical tests, and statistical data exploration.</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="c1"># To explain the results of machine learning algorithms</span>
<span class="kn">import</span> <span class="nn">shap</span>


<span class="c1"># To plot pretty figures</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s2">&quot;axes&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s2">&quot;xtick&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s2">&quot;ytick&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># setting to visualize pipelines</span>
<span class="c1"># see https://towardsdatascience.com/are-you-using-pipeline-in-scikit-learn-ac4cd85cb27f</span>
<span class="n">sklearn</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s1">&#39;diagram&#39;</span><span class="p">)</span>

<span class="n">SEED</span> <span class="o">=</span> <span class="mi">88</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="importing-the-data">
<h2>Importing the data<a class="headerlink" href="#importing-the-data" title="Permalink to this headline">¶</a></h2>
<p>Import the data from the following url (raw csv format):</p>
<p><a class="reference external" href="https://raw.githubusercontent.com/jads-nl/discover-projects/main/pima-indians-diabetes/diabetes.csv">https://raw.githubusercontent.com/jads-nl/discover-projects/main/pima-indians-diabetes/diabetes.csv</a></p>
<p>With <code class="docutils literal notranslate"><span class="pre">pandas.read_csv</span></code> import the csv file and transform into a pandas data frame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pima_diabetes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/jads-nl/discover-projects/main/pima-indians-diabetes/diabetes.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="checks-on-data-quality">
<h2>Checks on data quality<a class="headerlink" href="#checks-on-data-quality" title="Permalink to this headline">¶</a></h2>
<p>Show basic information about the imported data frame with <code class="docutils literal notranslate"><span class="pre">.info()</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 768 entries, 0 to 767
Data columns (total 9 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   Pregnancies               768 non-null    int64  
 1   Glucose                   768 non-null    int64  
 2   BloodPressure             768 non-null    int64  
 3   SkinThickness             768 non-null    int64  
 4   Insulin                   768 non-null    int64  
 5   BMI                       768 non-null    float64
 6   DiabetesPedigreeFunction  768 non-null    float64
 7   Age                       768 non-null    int64  
 8   Outcome                   768 non-null    int64  
dtypes: float64(2), int64(7)
memory usage: 54.1 KB
</pre></div>
</div>
</div>
</div>
<p>There are 9 columns (variables in the data) and 768 rows (observations).
For each variable, it says 768. Does this mean that there are 768 valid values for each variable, and no missing values?</p>
<p>Inspect the first 5 rows of the data frame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pregnancies</th>
      <th>Glucose</th>
      <th>BloodPressure</th>
      <th>SkinThickness</th>
      <th>Insulin</th>
      <th>BMI</th>
      <th>DiabetesPedigreeFunction</th>
      <th>Age</th>
      <th>Outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6</td>
      <td>148</td>
      <td>72</td>
      <td>35</td>
      <td>0</td>
      <td>33.6</td>
      <td>0.627</td>
      <td>50</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>85</td>
      <td>66</td>
      <td>29</td>
      <td>0</td>
      <td>26.6</td>
      <td>0.351</td>
      <td>31</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8</td>
      <td>183</td>
      <td>64</td>
      <td>0</td>
      <td>0</td>
      <td>23.3</td>
      <td>0.672</td>
      <td>32</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>89</td>
      <td>66</td>
      <td>23</td>
      <td>94</td>
      <td>28.1</td>
      <td>0.167</td>
      <td>21</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>137</td>
      <td>40</td>
      <td>35</td>
      <td>168</td>
      <td>43.1</td>
      <td>2.288</td>
      <td>33</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="section" id="inspect-whether-the-data-has-missing-values">
<h3>Inspect whether the data has missing values<a class="headerlink" href="#inspect-whether-the-data-has-missing-values" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pregnancies                 0
Glucose                     0
BloodPressure               0
SkinThickness               0
Insulin                     0
BMI                         0
DiabetesPedigreeFunction    0
Age                         0
Outcome                     0
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Visualize missing value patterns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">isnull</span><span class="p">(),</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_18_0.png" src="../../_images/pima-indians-diabetes_18_0.png" />
</div>
</div>
<p>A totally black rectangle: this means that all cells in the data set have values, but is not clear yet whether there are missing values present or not. Missing values can be coded as missing with a specific value (for example 999). From the first inspection of the data I notice that the first three observations have insuline values equal to zero. From the information I collected about the meaning of the variables in this data set, it is clear that insuline values equal to zere are unlikely to occur. So, this means that the zero’s in this variable do not represent realistic values in real life and are probably a code for a missing value.</p>
<p>Let’s explore the variables in the data set to get an idea of the distribution of the values and to see whether there are more coded missing values.</p>
</div>
<div class="section" id="inspect-the-outcome-variable">
<h3>Inspect the outcome variable<a class="headerlink" href="#inspect-the-outcome-variable" title="Permalink to this headline">¶</a></h3>
<p>What is the number (and proportion) of Diabetes type 2 cases in this data set?</p>
<p>There are 768 Pima women in the data and 268 (35%) of these women were diagnosed with Diabetes Type-2.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pima_diabetes</span><span class="p">[</span><span class="s2">&quot;Outcome&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    500
1    268
Name: Outcome, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Percentage of diabetes Type-2 cases in the data</span>
<span class="n">Pima_diabetes</span><span class="p">[</span><span class="s2">&quot;Outcome&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">Pima_diabetes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    65.104167
1    34.895833
Name: Outcome, dtype: float64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="inspect-the-distribution-of-the-predictor-variables">
<h3>Inspect the distribution of the predictor variables.<a class="headerlink" href="#inspect-the-distribution-of-the-predictor-variables" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_24_0.png" src="../../_images/pima-indians-diabetes_24_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pregnancies</th>
      <th>Glucose</th>
      <th>BloodPressure</th>
      <th>SkinThickness</th>
      <th>Insulin</th>
      <th>BMI</th>
      <th>DiabetesPedigreeFunction</th>
      <th>Age</th>
      <th>Outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.845052</td>
      <td>120.894531</td>
      <td>69.105469</td>
      <td>20.536458</td>
      <td>79.799479</td>
      <td>31.992578</td>
      <td>0.471876</td>
      <td>33.240885</td>
      <td>0.348958</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.369578</td>
      <td>31.972618</td>
      <td>19.355807</td>
      <td>15.952218</td>
      <td>115.244002</td>
      <td>7.884160</td>
      <td>0.331329</td>
      <td>11.760232</td>
      <td>0.476951</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.078000</td>
      <td>21.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.000000</td>
      <td>99.000000</td>
      <td>62.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>27.300000</td>
      <td>0.243750</td>
      <td>24.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>117.000000</td>
      <td>72.000000</td>
      <td>23.000000</td>
      <td>30.500000</td>
      <td>32.000000</td>
      <td>0.372500</td>
      <td>29.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.000000</td>
      <td>140.250000</td>
      <td>80.000000</td>
      <td>32.000000</td>
      <td>127.250000</td>
      <td>36.600000</td>
      <td>0.626250</td>
      <td>41.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>17.000000</td>
      <td>199.000000</td>
      <td>122.000000</td>
      <td>99.000000</td>
      <td>846.000000</td>
      <td>67.100000</td>
      <td>2.420000</td>
      <td>81.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="conclusions-from-the-descriptives-of-the-data">
<h3>Conclusions from the descriptives of the data<a class="headerlink" href="#conclusions-from-the-descriptives-of-the-data" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Age</span></code> follows a skewed distribution and shows that there are relatively more younger women than older women in the sample. Also note that there are no women younger than 21 years in this data set because of the way the sample was selected by the researchers. This means that the learning algoritm will only be able to generalize to a population of women with this age distribution.</p>
<p>The shape of the distribution of <code class="docutils literal notranslate"><span class="pre">BMI</span></code> is more or less normal with a few outliers with very high BMI values. The mean BMI is quite high with a value of 32, which corresponds to the category “obese”. There are also subjects with BMI values equal to zero, which is not a realistic value and is therefore to be considered as a missing value coded as zero.</p>
<p>The distribution of <code class="docutils literal notranslate"><span class="pre">Bloodpressure</span></code> shows that most subjects have a diastolic bloodpressure between 60 and 80, which is the healthy range, but there are a considerable number subjects with bloodpressure values that are too high. Also, for this variable there are values equal to zero, which might be codes for missing values.</p>
<p>The distribution of <code class="docutils literal notranslate"><span class="pre">DiabetesPedigreeFunction</span></code> is skewed with most values falling in the lower ranger of the possible scores, which seems to indicate that most of the subjects in the sample have lower expected genetic influence of affected relatives.</p>
<p>The distribution of <code class="docutils literal notranslate"><span class="pre">Glucose</span></code> shows that all subjects have glucose levels lower than 200 mg/dL, which is the threshold for being classified as diabetes patient (levels of Glucose equal to 200 mg/dL and higher). This result is to be expected because of the way the sample was constructed: only one examination was selected per subject and that examination was one that revealed a nondiabetic glucose tolerance test. The distrubution shows that the median value of glucose in the sample is equal to 117 mg/dL, which is lower than 140mg/dL and corresponds to a normal blood glucose level. The highest 25% of the glucose values in this sample are higher than 140 mg/dL, which corresponds to being at risk for developing type 2 diabetes.</p>
<p>The distribution of <code class="docutils literal notranslate"><span class="pre">Insulin</span></code> shows that most values fall in the normal reference range of 6-166 mIU/L, but a considerable number of subjects have insulin values that are higher than the healthy reference range. There is a very high value of 846, which might be an error in the data, but there is no information available about this large value. Also, the variability of this variable is very high compared to the other variables in the data set, given the standard deviation equal to 115.</p>
<p>The distribution of <code class="docutils literal notranslate"><span class="pre">Pregnancies</span></code> shows a Poisson-like distribution with some high values of 14, 15 and 17 pregnancies.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">SkinThickness</span></code> the normal values for women are around 18.0mm which corresponds to 30% fat. The distribution in this sample shows that median is 23 mm, which is higher than the mean value of 18 mm. There are also outliers (or data errors?) around 60 and 99.</p>
</div>
</div>
<div class="section" id="crisp-dm-phase-3-prepare-the-data">
<h2>CRISP-DM Phase 3: Prepare the data<a class="headerlink" href="#crisp-dm-phase-3-prepare-the-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="dealing-with-outliers">
<h3>Dealing with outliers<a class="headerlink" href="#dealing-with-outliers" title="Permalink to this headline">¶</a></h3>
<p>I will deal with the outliers before dividing the data set in training and a test set because these values might compromise the predictive properties of the model. For example when some of the outliers end up in the training set or in the test set, or in both.</p>
<p>In general one should be careful when removing observations from the data set. Removing outliers has consequences for the underlying distribution of the data generating principle. Removing all extreme values from the data set results in underestimating the variances. But also that the model does not properly generalize to other data because it is based on a data set without extreme values, which can occur in reality. With emphasis on “occurring in reality”. It goes without saying that extreme values that are the result of input errors (e.g. an age of 233 years for a human being) must of course be removed from the data.</p>
<p>In detecting outliers we therefore limit ourselves to outliers in the multidimensional predictor space which can influence the slope of the regression lines. Given that the outcome is a binary (0, 1) variable, it is not possible to observe outliers on the outcome variable.</p>
<p>In the histograms above we have seen that some variables have outliers. These are univariate outliers, which means that these values are extreme compared to the other values of the same variable. Also important is to check whether some participants have extreme values when the values on all variables are taken into account. These so called multivariate outliers can be detected using the Mahalanobis distance.  The Mahalanobis distance is particularily usefull to detect outliers in the predictor space because this distance measure also takes into account the correlation that the variables might have with each other.</p>
<p>The formula to compute the Mahalanobis distance can be found on <a class="reference external" href="https://en.wikipedia.org/wiki/Mahalanobis_distance">Wikipedia</a>  together with the following explanation:</p>
<blockquote>
<div><p>Mahalanobis distance and leverage are often used to detect outliers, especially in the development of linear regression models. A point that has a greater Mahalanobis distance from the rest of the sample population of points is said to have higher leverage since it has a greater influence on the slope or coefficients of the regression equation. Mahalanobis distance is also used to determine multivariate outliers. Regression techniques can be used to determine if a specific case within a sample population is an outlier via the combination of two or more variable scores. Even for normal distributions, a point can be a multivariate outlier even if it is not a univariate outlier for any variable, making Mahalanobis distance a more sensitive measure than checking dimensions individually.</p>
</div></blockquote>
<p>The formula to compute the Mahalanobis distance is:</p>
<p>$<span class="math notranslate nohighlight">\(d^2 = (x - m)^{T} \bullet C^{-1} \bullet (x-m)\)</span>$,</p>
<p>where <code class="docutils literal notranslate"><span class="pre">x</span></code> represents the variables and <code class="docutils literal notranslate"><span class="pre">m</span></code> is the mean of the variables.</p>
<p>$<span class="math notranslate nohighlight">\(C^{-1}\)</span>$ represents the inverse of the covariance matrix of the variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_mahalanobis_distance</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes Malahanobis distance for dataframe.</span>
<span class="sd">    </span>
<span class="sd">    Use Mahalanobis distance $d$ to detect outliers, with the formula</span>
<span class="sd">    </span>
<span class="sd">    $$d^2 = (x - m)^{T} \bullet C^{-1} \bullet (x-m)$$</span>
<span class="sd">    </span>
<span class="sd">    Arguments</span>
<span class="sd">    ---------</span>
<span class="sd">    df : pandas.DataFrame</span>
<span class="sd">         Dataframe containing features x in long format</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray: two-dimensional array</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x_minus_mu</span> <span class="o">=</span> <span class="n">df</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">invC</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
    <span class="n">x_minus_mu_dot_invC</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_minus_mu</span><span class="p">,</span> <span class="n">invC</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_minus_mu_dot_invC</span><span class="p">,</span> <span class="n">x_minus_mu</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prepare the data to compute the Mahalanobis distance for the explanatory</span>
<span class="c1"># variables (thus, without the outcome variable).</span>
<span class="c1"># Pima_diabetes[&quot;MahalDist&quot;] = </span>
<span class="n">Pima_diabetes</span><span class="p">[</span><span class="s2">&quot;MahalDist&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_mahalanobis_distance</span><span class="p">(</span><span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Outcome&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pima_diabetes</span><span class="p">[</span><span class="s2">&quot;MahalDist&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_31_0.png" src="../../_images/pima-indians-diabetes_31_0.png" />
</div>
</div>
<p>There are some observations with higher Mahalanobis distances. To detect outliers, you are looking for observations that are separated from the main cluster of the data. In this histogram you can see that the values larger than 50 are separated from the remaining observations. Let’s inspect the values of the explanatory variables for these subjects with higher Mahalanobis distances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;MahalDist&gt; 50&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pregnancies</th>
      <th>Glucose</th>
      <th>BloodPressure</th>
      <th>SkinThickness</th>
      <th>Insulin</th>
      <th>BMI</th>
      <th>DiabetesPedigreeFunction</th>
      <th>Age</th>
      <th>Outcome</th>
      <th>MahalDist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13</th>
      <td>1</td>
      <td>189</td>
      <td>60</td>
      <td>23</td>
      <td>846</td>
      <td>30.1</td>
      <td>0.398</td>
      <td>59</td>
      <td>1</td>
      <td>66.130467</td>
    </tr>
    <tr>
      <th>228</th>
      <td>4</td>
      <td>197</td>
      <td>70</td>
      <td>39</td>
      <td>744</td>
      <td>36.7</td>
      <td>2.329</td>
      <td>31</td>
      <td>0</td>
      <td>59.702052</td>
    </tr>
    <tr>
      <th>445</th>
      <td>0</td>
      <td>180</td>
      <td>78</td>
      <td>63</td>
      <td>14</td>
      <td>59.4</td>
      <td>2.420</td>
      <td>25</td>
      <td>1</td>
      <td>54.040477</td>
    </tr>
    <tr>
      <th>579</th>
      <td>2</td>
      <td>197</td>
      <td>70</td>
      <td>99</td>
      <td>0</td>
      <td>34.7</td>
      <td>0.575</td>
      <td>62</td>
      <td>1</td>
      <td>64.834739</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>These four subjects have extreme values on several explanatory variables. Subject 13 has a very high <code class="docutils literal notranslate"><span class="pre">Insuline</span></code> value of 846, combined with a high <code class="docutils literal notranslate"><span class="pre">Glucose</span></code> level. Subject 228 has als a high <code class="docutils literal notranslate"><span class="pre">Insulin</span></code> value combined with a <code class="docutils literal notranslate"><span class="pre">Glucose</span></code> value of 197, which is almost equal to the cut-off point of 200 for being diagnosed with diabetes Type-2. Subject number 445 has an extreme value for <code class="docutils literal notranslate"><span class="pre">BMI</span></code> equal to 59.4, combined with an extreme <code class="docutils literal notranslate"><span class="pre">SkinThickness</span></code> value of 63 and a high <code class="docutils literal notranslate"><span class="pre">Glucose</span></code> value of 180 and a high <code class="docutils literal notranslate"><span class="pre">DiabetesPedigreeFunction</span></code> combined with a relative young age (25 years). Subject 579 has an extreme value of 99 for <code class="docutils literal notranslate"><span class="pre">SkinThickness</span></code> combined with a high <code class="docutils literal notranslate"><span class="pre">Glucose</span></code> value. It is probable that some of these extreme values are data errors, but it is not possible to find out exactly what happened. Since these multivariate outliers might influence the fit of the model, these four subjects will be discarded from the analyses.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_no_outliers</span> <span class="o">=</span> <span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;MahalDist &lt;= 50&quot;</span><span class="p">)</span>
<span class="n">df_no_outliers</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Int64Index: 764 entries, 0 to 767
Data columns (total 10 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   Pregnancies               764 non-null    int64  
 1   Glucose                   764 non-null    int64  
 2   BloodPressure             764 non-null    int64  
 3   SkinThickness             764 non-null    int64  
 4   Insulin                   764 non-null    int64  
 5   BMI                       764 non-null    float64
 6   DiabetesPedigreeFunction  764 non-null    float64
 7   Age                       764 non-null    int64  
 8   Outcome                   764 non-null    int64  
 9   MahalDist                 764 non-null    float64
dtypes: float64(3), int64(7)
memory usage: 65.7 KB
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="create-training-set-and-test-set">
<h3>Create training set and test set<a class="headerlink" href="#create-training-set-and-test-set" title="Permalink to this headline">¶</a></h3>
<p>A training set and a test set is created using the <code class="docutils literal notranslate"><span class="pre">StratifiedShuffleSplit</span></code> module from <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection</span></code>. The stratified part is especially important to ensure that the training set and the test set contain approximately the same number of diabetes cases and non-diabetes cases.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">split</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">split</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">df_no_outliers</span><span class="p">,</span> <span class="n">df_no_outliers</span><span class="p">[</span><span class="s2">&quot;Outcome&quot;</span><span class="p">]):</span>
      <span class="n">PimaTrain</span> <span class="o">=</span> <span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
      <span class="n">PimaTest</span> <span class="o">=</span> <span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>The check below shows that the distribution of the outcome variable is the same in the training set and the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The distribution of Outcome in the training set is:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">PimaTrain</span><span class="p">[</span><span class="s2">&quot;Outcome&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The distribution of Outcome in the test set is: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">PimaTest</span><span class="p">[</span><span class="s2">&quot;Outcome&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The distribution of Outcome in the training set is:
 0    0.649755
1    0.350245
Name: Outcome, dtype: float64
The distribution of Outcome in the test set is: 
 0    0.653595
1    0.346405
Name: Outcome, dtype: float64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="descriptives-of-the-training-data-set">
<h3>Descriptives of the training data set<a class="headerlink" href="#descriptives-of-the-training-data-set" title="Permalink to this headline">¶</a></h3>
<p>Inspection of the distribution of the variables with descriptive statistics such as the mean, standard deviation and the quartiles, but also with histograms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PimaTrain</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pregnancies</th>
      <th>Glucose</th>
      <th>BloodPressure</th>
      <th>SkinThickness</th>
      <th>Insulin</th>
      <th>BMI</th>
      <th>DiabetesPedigreeFunction</th>
      <th>Age</th>
      <th>Outcome</th>
      <th>MahalDist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>611.000000</td>
      <td>611.000000</td>
      <td>611.000000</td>
      <td>611.000000</td>
      <td>611.000000</td>
      <td>611.000000</td>
      <td>611.000000</td>
      <td>611.000000</td>
      <td>611.000000</td>
      <td>611.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.774141</td>
      <td>120.425532</td>
      <td>69.201309</td>
      <td>19.867430</td>
      <td>77.549918</td>
      <td>32.001800</td>
      <td>0.473432</td>
      <td>33.299509</td>
      <td>0.350245</td>
      <td>7.949713</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.323249</td>
      <td>32.280923</td>
      <td>19.300566</td>
      <td>15.898049</td>
      <td>113.537466</td>
      <td>7.630934</td>
      <td>0.333276</td>
      <td>11.920790</td>
      <td>0.477438</td>
      <td>7.060284</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.078000</td>
      <td>21.000000</td>
      <td>0.000000</td>
      <td>0.785918</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.000000</td>
      <td>99.000000</td>
      <td>62.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>27.250000</td>
      <td>0.242000</td>
      <td>24.000000</td>
      <td>0.000000</td>
      <td>3.582841</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>116.000000</td>
      <td>72.000000</td>
      <td>22.000000</td>
      <td>25.000000</td>
      <td>32.000000</td>
      <td>0.374000</td>
      <td>29.000000</td>
      <td>0.000000</td>
      <td>5.623052</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.000000</td>
      <td>139.000000</td>
      <td>80.000000</td>
      <td>32.000000</td>
      <td>125.000000</td>
      <td>36.500000</td>
      <td>0.626500</td>
      <td>41.000000</td>
      <td>1.000000</td>
      <td>9.755857</td>
    </tr>
    <tr>
      <th>max</th>
      <td>17.000000</td>
      <td>199.000000</td>
      <td>122.000000</td>
      <td>60.000000</td>
      <td>846.000000</td>
      <td>67.100000</td>
      <td>2.329000</td>
      <td>81.000000</td>
      <td>1.000000</td>
      <td>66.130467</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pima_diabetes</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_42_0.png" src="../../_images/pima-indians-diabetes_42_0.png" />
</div>
</div>
</div>
<div class="section" id="dealing-with-missing-values">
<h3>Dealing with missing values<a class="headerlink" href="#dealing-with-missing-values" title="Permalink to this headline">¶</a></h3>
<p>For the moment the missing values that have been coded as zero will be replaced by the median value of the variable. There are much better ways to deal with missing values (for example multiple imputation). Also, more time should be spend to understand the pattern of missing values in this data set.</p>
<p>I will deal with the missing values in the training set only to avoid information from the test set to leak into the training data set. The median will be computed for the training set only. Furthermore, the median will computed for the two groups seperately: a median for the non-diabetes group and a median for the diabetes group.</p>
<p><strong>Dealing with the missing values coded as 0</strong></p>
<p>Assessing how many zero values there are for the variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cols_with_zeros</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Glucose&#39;</span><span class="p">,</span> <span class="s1">&#39;BloodPressure&#39;</span><span class="p">,</span> <span class="s1">&#39;Insulin&#39;</span><span class="p">,</span> <span class="s1">&#39;SkinThickness&#39;</span><span class="p">,</span> <span class="s1">&#39;BMI&#39;</span><span class="p">]</span>
<span class="n">cols_no_zeros</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">PimaTrain</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cols_with_zeros</span><span class="p">]</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols_with_zeros</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2"> values equal to zero: &quot;</span><span class="p">,</span> <span class="n">PimaTrain</span><span class="p">[</span><span class="n">PimaTrain</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total Glucose values equal to zero:  5
Total BloodPressure values equal to zero:  27
Total Insulin values equal to zero:  300
Total SkinThickness values equal to zero:  191
Total BMI values equal to zero:  6
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="conclusions-on-missing-values-sofar">
<h3>Conclusions on missing values sofar<a class="headerlink" href="#conclusions-on-missing-values-sofar" title="Permalink to this headline">¶</a></h3>
<p>It is clear that the variable <code class="docutils literal notranslate"><span class="pre">insulin</span></code> has the highest number of missing values. Probably this variable will not be useful in predicting Diabetes Type 2. The variable <code class="docutils literal notranslate"><span class="pre">skin</span> <span class="pre">thickness</span></code> also has a lot of missing values.</p>
</div>
<div class="section" id="replace-the-zero-values-with-the-median-for-the-training-set-and-the-test-set">
<h3>Replace the zero values with the median for the training set and the test set<a class="headerlink" href="#replace-the-zero-values-with-the-median-for-the-training-set-and-the-test-set" title="Permalink to this headline">¶</a></h3>
<p>Since we aim to train and compare different models, we will us sklearn pipelines throughout.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PimaTrain</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">cols_with_zeros</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;Age&#39;, &#39;DiabetesPedigreeFunction&#39;, &#39;MahalDist&#39;, &#39;Outcome&#39;,
       &#39;Pregnancies&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cols_with_zeros</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Glucose&#39;</span><span class="p">,</span> <span class="s1">&#39;BloodPressure&#39;</span><span class="p">,</span> <span class="s1">&#39;Insulin&#39;</span><span class="p">,</span> <span class="s1">&#39;SkinThickness&#39;</span><span class="p">,</span> <span class="s1">&#39;BMI&#39;</span><span class="p">]</span>
<span class="n">impute_zeros</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
<span class="p">(</span><span class="n">SimpleImputer</span><span class="p">(</span>
        <span class="n">missing_values</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">),</span> <span class="n">cols_with_zeros</span><span class="p">),</span> <span class="n">remainder</span><span class="o">=</span><span class="s1">&#39;passthrough&#39;</span><span class="p">)</span>
<span class="n">impute_zeros</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class="sk-top-container"><div class="sk-container"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="b16af4df-981e-4d36-a7b6-dcda371dfbcf" type="checkbox" ><label class="sk-toggleable__label" for="b16af4df-981e-4d36-a7b6-dcda371dfbcf">ColumnTransformer</label><div class="sk-toggleable__content"><pre>ColumnTransformer(remainder='passthrough',
                  transformers=[('simpleimputer',
                                 SimpleImputer(missing_values=0,
                                               strategy='median'),
                                 ['Glucose', 'BloodPressure', 'Insulin',
                                  'SkinThickness', 'BMI'])])</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="c7e7a4c8-7459-4eea-811c-5bd103d46194" type="checkbox" ><label class="sk-toggleable__label" for="c7e7a4c8-7459-4eea-811c-5bd103d46194">simpleimputer</label><div class="sk-toggleable__content"><pre>['Glucose', 'BloodPressure', 'Insulin', 'SkinThickness', 'BMI']</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="3ae19806-37e4-404f-b7dd-27097ec456d7" type="checkbox" ><label class="sk-toggleable__label" for="3ae19806-37e4-404f-b7dd-27097ec456d7">SimpleImputer</label><div class="sk-toggleable__content"><pre>SimpleImputer(missing_values=0, strategy='median')</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="67eec236-49a9-4fbb-a6a5-c1033b669fb1" type="checkbox" ><label class="sk-toggleable__label" for="67eec236-49a9-4fbb-a6a5-c1033b669fb1">remainder</label><div class="sk-toggleable__content"><pre></pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="6a60bea4-79a6-46a5-b783-49ad4fb95845" type="checkbox" ><label class="sk-toggleable__label" for="6a60bea4-79a6-46a5-b783-49ad4fb95845">passthrough</label><div class="sk-toggleable__content"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># note that column names are lost after transformation</span>
<span class="c1"># and that original order is not preserved</span>
<span class="n">new_columns</span> <span class="o">=</span> <span class="n">cols_with_zeros</span> <span class="o">+</span> <span class="n">cols_no_zeros</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">impute_zeros</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">PimaTrain</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">new_columns</span><span class="p">)</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_50_0.png" src="../../_images/pima-indians-diabetes_50_0.png" />
</div>
</div>
</div>
<div class="section" id="inspecting-the-distribution-of-the-predictors-after-imputation">
<h3>Inspecting the distribution of the predictors after imputation<a class="headerlink" href="#inspecting-the-distribution-of-the-predictors-after-imputation" title="Permalink to this headline">¶</a></h3>
<p>Conclusion:</p>
<p>The zero values have been replaced by the median.
But, of course, the distribution of some of the predictors are still very skewed, as discussed before. These deviant distributions are problematic when fitting linear models such as logistic regression. We will try several data transformations for positive skewness (see for an overview of possible data transformations, pp. 87-89 in: Tabachnick, B.C., Fidell, L.S. (2013). <em>Using Multivariate Statistics. Sixth Edition.</em> Boston: Pearson).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PimaTrain</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_52_0.png" src="../../_images/pima-indians-diabetes_52_0.png" />
</div>
</div>
</div>
<div class="section" id="explore-correlations-among-the-explanatory-variables-and-the-outcome">
<h3>Explore correlations among the explanatory variables and the outcome<a class="headerlink" href="#explore-correlations-among-the-explanatory-variables-and-the-outcome" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PimaTrain</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pregnancies</th>
      <th>Glucose</th>
      <th>BloodPressure</th>
      <th>SkinThickness</th>
      <th>Insulin</th>
      <th>BMI</th>
      <th>DiabetesPedigreeFunction</th>
      <th>Age</th>
      <th>Outcome</th>
      <th>MahalDist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Pregnancies</th>
      <td>1.000000</td>
      <td>0.107424</td>
      <td>0.117871</td>
      <td>-0.101969</td>
      <td>-0.078485</td>
      <td>0.031420</td>
      <td>-0.029042</td>
      <td>0.535279</td>
      <td>0.199755</td>
      <td>0.107622</td>
    </tr>
    <tr>
      <th>Glucose</th>
      <td>0.107424</td>
      <td>1.000000</td>
      <td>0.142900</td>
      <td>0.033456</td>
      <td>0.347792</td>
      <td>0.200497</td>
      <td>0.115344</td>
      <td>0.246234</td>
      <td>0.460244</td>
      <td>0.252196</td>
    </tr>
    <tr>
      <th>BloodPressure</th>
      <td>0.117871</td>
      <td>0.142900</td>
      <td>1.000000</td>
      <td>0.173541</td>
      <td>0.079353</td>
      <td>0.232895</td>
      <td>0.013557</td>
      <td>0.221202</td>
      <td>0.053712</td>
      <td>-0.209292</td>
    </tr>
    <tr>
      <th>SkinThickness</th>
      <td>-0.101969</td>
      <td>0.033456</td>
      <td>0.173541</td>
      <td>1.000000</td>
      <td>0.474631</td>
      <td>0.367907</td>
      <td>0.180081</td>
      <td>-0.129126</td>
      <td>0.044571</td>
      <td>-0.049138</td>
    </tr>
    <tr>
      <th>Insulin</th>
      <td>-0.078485</td>
      <td>0.347792</td>
      <td>0.079353</td>
      <td>0.474631</td>
      <td>1.000000</td>
      <td>0.191816</td>
      <td>0.216995</td>
      <td>-0.031267</td>
      <td>0.123549</td>
      <td>0.248269</td>
    </tr>
    <tr>
      <th>BMI</th>
      <td>0.031420</td>
      <td>0.200497</td>
      <td>0.232895</td>
      <td>0.367907</td>
      <td>0.191816</td>
      <td>1.000000</td>
      <td>0.091063</td>
      <td>0.037960</td>
      <td>0.333338</td>
      <td>0.094966</td>
    </tr>
    <tr>
      <th>DiabetesPedigreeFunction</th>
      <td>-0.029042</td>
      <td>0.115344</td>
      <td>0.013557</td>
      <td>0.180081</td>
      <td>0.216995</td>
      <td>0.091063</td>
      <td>1.000000</td>
      <td>0.044180</td>
      <td>0.149518</td>
      <td>0.327932</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>0.535279</td>
      <td>0.246234</td>
      <td>0.221202</td>
      <td>-0.129126</td>
      <td>-0.031267</td>
      <td>0.037960</td>
      <td>0.044180</td>
      <td>1.000000</td>
      <td>0.213408</td>
      <td>0.322192</td>
    </tr>
    <tr>
      <th>Outcome</th>
      <td>0.199755</td>
      <td>0.460244</td>
      <td>0.053712</td>
      <td>0.044571</td>
      <td>0.123549</td>
      <td>0.333338</td>
      <td>0.149518</td>
      <td>0.213408</td>
      <td>1.000000</td>
      <td>0.211848</td>
    </tr>
    <tr>
      <th>MahalDist</th>
      <td>0.107622</td>
      <td>0.252196</td>
      <td>-0.209292</td>
      <td>-0.049138</td>
      <td>0.248269</td>
      <td>0.094966</td>
      <td>0.327932</td>
      <td>0.322192</td>
      <td>0.211848</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PimaTrain</span><span class="o">.</span><span class="n">corr</span><span class="p">()[</span><span class="s2">&quot;Outcome&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Outcome                     1.000000
Glucose                     0.460244
BMI                         0.333338
Age                         0.213408
MahalDist                   0.211848
Pregnancies                 0.199755
DiabetesPedigreeFunction    0.149518
Insulin                     0.123549
BloodPressure               0.053712
SkinThickness               0.044571
Name: Outcome, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Thanks to Jan Deknatel (https://github.com/knaat) for suggesting this configuration of the correlation matrix</span>
<span class="c1"># plot with white squares on the diagonal and shades of green for the positive</span>
<span class="c1"># correlations and shades of pink for the negative correlations.</span>
<span class="n">heat_cmap</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s2">&quot;PiYG&quot;</span><span class="p">))</span>
<span class="n">heat_cmap</span><span class="o">.</span><span class="n">set_over</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">)</span>  <span class="c1"># make the diagonal white</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
    <span class="n">PimaTrain</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span>
    <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="n">heat_cmap</span><span class="p">,</span>
    <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">robust</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_56_0.png" src="../../_images/pima-indians-diabetes_56_0.png" />
</div>
</div>
<p><strong>Conclusions correlation matrix</strong></p>
<p>The correlations between the explanatory variables and the outcome variable are moderate. The explanatory variable that has the highest correlation with <code class="docutils literal notranslate"><span class="pre">Outcome</span></code> is <code class="docutils literal notranslate"><span class="pre">Glucose</span></code> (corr = 0.49). The second highest correlation with <code class="docutils literal notranslate"><span class="pre">Outcome</span></code> is <code class="docutils literal notranslate"><span class="pre">BMI</span></code> (corr = 0.34).</p>
<p>The correlation measures the <em><strong>linear</strong></em> relation between two variables. Given the skewed distributions of for example <code class="docutils literal notranslate"><span class="pre">Insulin</span></code> and <code class="docutils literal notranslate"><span class="pre">Age</span></code>, it is not surprising that these variables show a moderate correlation with the outcome variable.</p>
<p>The explanatory variables are moderately correlated among themselves. The highest correlation between explanatory variables is for the pair <code class="docutils literal notranslate"><span class="pre">BMI</span></code> and <code class="docutils literal notranslate"><span class="pre">SkinThickness</span></code> with a correlation equal to 0.57.</p>
</div>
<div class="section" id="explore-bivariate-relations-between-the-predictor-variables">
<h3>Explore bivariate relations between the predictor variables<a class="headerlink" href="#explore-bivariate-relations-between-the-predictor-variables" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span>
    <span class="n">PimaTrain</span><span class="p">[</span>
        <span class="p">[</span>
            <span class="s2">&quot;Pregnancies&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Glucose&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Insulin&quot;</span><span class="p">,</span>
            <span class="s2">&quot;BloodPressure&quot;</span><span class="p">,</span>
            <span class="s2">&quot;BMI&quot;</span><span class="p">,</span>
            <span class="s2">&quot;SkinThickness&quot;</span><span class="p">,</span>
            <span class="s2">&quot;DiabetesPedigreeFunction&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Age&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">],</span>
    <span class="n">diag_kind</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_59_0.png" src="../../_images/pima-indians-diabetes_59_0.png" />
</div>
</div>
</div>
<div class="section" id="explore-bivariate-relations-between-the-predictor-variables-with-color-coding-for-the-outcome-variable">
<h3>Explore bivariate relations between the predictor variables with color coding for the outcome variable<a class="headerlink" href="#explore-bivariate-relations-between-the-predictor-variables-with-color-coding-for-the-outcome-variable" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span>
    <span class="n">PimaTrain</span><span class="p">[</span>
        <span class="p">[</span>
            <span class="s2">&quot;Pregnancies&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Glucose&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Insulin&quot;</span><span class="p">,</span>
            <span class="s2">&quot;BloodPressure&quot;</span><span class="p">,</span>
            <span class="s2">&quot;BMI&quot;</span><span class="p">,</span>
            <span class="s2">&quot;SkinThickness&quot;</span><span class="p">,</span>
            <span class="s2">&quot;DiabetesPedigreeFunction&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Age&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Outcome&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">],</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Outcome&quot;</span><span class="p">,</span>
    <span class="n">diag_kind</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_61_0.png" src="../../_images/pima-indians-diabetes_61_0.png" />
</div>
</div>
</div>
<div class="section" id="conclusions-from-the-bivariate-distributions">
<h3>Conclusions from the bivariate distributions<a class="headerlink" href="#conclusions-from-the-bivariate-distributions" title="Permalink to this headline">¶</a></h3>
<p>For most pairs of predictors there is no clear distinction between the diabetes group and the non-diabetes group. Only for the following pairs one can distinguish the shape of two clusters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Glucose</span></code> and <code class="docutils literal notranslate"><span class="pre">BMI</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Glucose</span></code> and <code class="docutils literal notranslate"><span class="pre">Age</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Glucose</span></code> and <code class="docutils literal notranslate"><span class="pre">DiabetesPedigreeFunction</span></code></p></li>
<li><p>and maybe <code class="docutils literal notranslate"><span class="pre">Glucose</span></code> and <code class="docutils literal notranslate"><span class="pre">Pregnancies</span></code></p></li>
</ul>
</div>
<div class="section" id="explore-distribution-of-explanatory-variables-for-each-group-diabetes-type-2-versus-healthy">
<h3>Explore distribution of explanatory variables for each group (diabetes type-2 versus healthy)<a class="headerlink" href="#explore-distribution-of-explanatory-variables-for-each-group-diabetes-type-2-versus-healthy" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PimaTrain</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">difference</span><span class="p">([</span><span class="s1">&#39;Outcome&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;Age&#39;, &#39;BMI&#39;, &#39;BloodPressure&#39;, &#39;DiabetesPedigreeFunction&#39;, &#39;Glucose&#39;,
       &#39;Insulin&#39;, &#39;MahalDist&#39;, &#39;Pregnancies&#39;, &#39;SkinThickness&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html </span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span> <span class="n">gridspec_kw</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;hspace&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">})</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">PimaTrain</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">difference</span><span class="p">([</span><span class="s1">&#39;Outcome&#39;</span><span class="p">])):</span>
    <span class="n">_ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">3</span><span class="p">]</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">col</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Outcome&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">PimaTrain</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;h&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">_ax</span><span class="p">)</span>
    <span class="n">_ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
    <span class="n">_ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_65_0.png" src="../../_images/pima-indians-diabetes_65_0.png" />
</div>
</div>
<p>From this we can see that for the diabetes group:</p>
<ul class="simple">
<li><p>Glucose levels are in general higher</p></li>
<li><p>blood pressure values seem to be slightly higher</p></li>
<li><p>BMI values are higher</p></li>
<li><p>skin thickness values are higher</p></li>
<li><p>higher values for the Diabetes Pedigree function.</p></li>
<li><p>has a higher median age, but the healthy group has quite a number of outliers with high ages.</p></li>
<li><p>There are more pregnancies</p></li>
</ul>
</div>
<div class="section" id="separate-the-predictor-variables-from-the-outcome-variable">
<h3>Separate the predictor variables from the outcome variable<a class="headerlink" href="#separate-the-predictor-variables-from-the-outcome-variable" title="Permalink to this headline">¶</a></h3>
<p>Divide the data frame in a matrix (dataframe) <code class="docutils literal notranslate"><span class="pre">X</span></code> with the predictor variables and a vector <code class="docutils literal notranslate"><span class="pre">y</span></code> for the outcome variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span> <span class="o">=</span> <span class="n">PimaTrain</span><span class="p">[</span><span class="s2">&quot;Outcome&quot;</span><span class="p">]</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">PimaTrain</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;Outcome&quot;</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">cols_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
<span class="n">index_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">index</span>

<span class="n">y_test</span> <span class="o">=</span> <span class="n">PimaTest</span><span class="p">[</span><span class="s2">&quot;Outcome&quot;</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">PimaTest</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;Outcome&quot;</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">cols_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">columns</span>
<span class="n">index_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">index</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="scale-the-data">
<h3>Scale the data<a class="headerlink" href="#scale-the-data" title="Permalink to this headline">¶</a></h3>
<p>The variables that will be used as predictor variables (= all, except <code class="docutils literal notranslate"><span class="pre">Outcome</span></code>) will be scaled (standardized) because some machine learning algorithms (in particular K-Nearest Neighbors) are sensitive to the magnitude of the scale of the variables. In addition, the variable <code class="docutils literal notranslate"><span class="pre">Insulin</span></code> has a very high standard deviation.</p>
<p>Standardization is done separately for the training set and test set to avoid information leeking from the test set into the training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># same as before, but now with RobustScaler()</span>
<span class="n">cols_no_imputation</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols_no_zeros</span> <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="s1">&#39;Outcome&#39;</span><span class="p">]</span>
<span class="n">impute_and_scale</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">SimpleImputer</span><span class="p">(</span>
        <span class="n">missing_values</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">),</span> <span class="n">RobustScaler</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">preproces</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">((</span><span class="n">impute_and_scale</span><span class="p">,</span> <span class="n">cols_with_zeros</span><span class="p">),</span> <span class="p">(</span><span class="n">RobustScaler</span><span class="p">(),</span> <span class="n">cols_no_imputation</span><span class="p">))</span>

<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">preproces</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">cols_train</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">index_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">preproces</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">cols_test</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">index_test</span><span class="p">)</span>

<span class="c1"># Create a data frame with X_train_scaled and y_train together, which is necessary </span>
<span class="c1"># to be able to use the module statsmodels</span>
<span class="n">PimaTrain_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">PimaTest_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">y_test</span><span class="p">,</span> <span class="n">X_test_scaled</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="crisp-dm-phase-4-modeling">
<h2>CRISP-DM Phase 4: Modeling<a class="headerlink" href="#crisp-dm-phase-4-modeling" title="Permalink to this headline">¶</a></h2>
<p>The following data analyses will be done:</p>
<p><strong>Logistic regression</strong></p>
<p>I will start with a logistic regression on the original, unscaled data, to provide a baseline model. Given the skewed distribution of some of the predictor variables, logistic regression models will be fitted with transformed predictor variables as well.</p>
<p><strong>Lasso</strong></p>
<p>I’m also going to fit a Lasso, but I don’t expect spectacular results because there are few predictors in the model and there is little to gain with variable selection. I don’t expect the Lasso to perform any better than logistic regression.</p>
<p><strong>KNN</strong></p>
<p>I will also try a simple K-Nearest Neighbor analysis, but I do not expect interesting results.</p>
<p><strong>Naive Bayes classification</strong></p>
<p>Naive Bayes is a simple classifier that might give good results and will serve as a baseline model here.</p>
<p><strong>Random Forests and Gradient Boosting</strong></p>
<p>Given the skewed distributions of some predictor variables, I expect better results from machine learning algorithms that can model nonlinear relationships, such as Random Forests and Gradient Boosting.</p>
<div class="section" id="model-evaluation">
<h3>Model evaluation<a class="headerlink" href="#model-evaluation" title="Permalink to this headline">¶</a></h3>
<p>All models will be trained on a training set and the performance of the model will be evaluated on the test set using the following performance measures:</p>
<ul class="simple">
<li><p>A confusion matrix showing the True Positives, the True Negatives, the False Positives and False Negatives.</p></li>
<li><p>Accuracy: an overall measure of model performance based on both the true positives and the true negatives.</p></li>
<li><p>Sensitivity: the proportion of correctly predicted Diabetes Type-2 cases.</p></li>
<li><p>Specificity: the proportion of correctly predicted healthy cases.</p></li>
</ul>
<p>Since data are imbalanced (the Diabetes cases represent only 35% of the total sample), it is quite possible that the majority class is better predicted by the machine learning algorithms than the minority class (the diabetes cases). Computing the sensitivity and the specificity will give more insight in how the machine learning algoritms perform for the Diabetes cases and for the healthy cases.</p>
</div>
<div class="section" id="logistic-regression">
<h3>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h3>
<p>Logistic regression will be performed to test the association of all the predictor variables with the outcome variable. To obtain a clear overview of the model fit and the parameter estimates, the module <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> will be used.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># To use the statsmodels module the logistic regression model is defined with </span>
<span class="c1"># the tilde notation that is used in R for (generalized) linear models.</span>
<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">logreg_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">PimaTrain</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Binomial</span><span class="p">())</span>
<span class="n">logreg_result</span> <span class="o">=</span> <span class="n">logreg_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">logreg_result</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                Outcome   No. Observations:                  611
Model:                            GLM   Df Residuals:                      602
Model Family:                Binomial   Df Model:                            8
Link Function:                  logit   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -282.86
Date:                Sat, 09 Jan 2021   Deviance:                       565.72
Time:                        17:19:09   Pearson chi2:                     641.
No. Iterations:                     5                                         
Covariance Type:            nonrobust                                         
============================================================================================
                               coef    std err          z      P&gt;|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------
Intercept                   -9.0239      0.837    -10.776      0.000     -10.665      -7.383
Pregnancies                  0.1183      0.037      3.202      0.001       0.046       0.191
Glucose                      0.0360      0.004      8.501      0.000       0.028       0.044
BloodPressure               -0.0132      0.006     -2.238      0.025      -0.025      -0.002
SkinThickness               -0.0049      0.008     -0.619      0.536      -0.020       0.011
Insulin                     -0.0016      0.001     -1.471      0.141      -0.004       0.001
BMI                          0.1178      0.018      6.557      0.000       0.083       0.153
DiabetesPedigreeFunction     0.8424      0.336      2.503      0.012       0.183       1.502
Age                          0.0100      0.010      0.973      0.331      -0.010       0.030
============================================================================================
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="results-logistic-regression-analysis">
<h3>Results logistic regression analysis<a class="headerlink" href="#results-logistic-regression-analysis" title="Permalink to this headline">¶</a></h3>
<p>The results of the logistic regression analysis in the table above show that the intercept has a large coefficient and a large associated z-value, compared to the other variables. This means that a lot of the variability in the data is not explained by the predictors.</p>
<p>The following predictors show a statistically significant postive association with the diagnosis of diabetes at least five years later in descending order of magnitude of the regression coefficients and associated <code class="docutils literal notranslate"><span class="pre">z</span></code>-values:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Glucose</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BMI</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DiabetesPedigreeFunction</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Pregnancies</span></code></p></li>
</ul>
<p>These predictors all have positive associations with the presence of diabetes, meaning that higher values on these predictors are associated with diagnosis of diabetes type 2.</p>
<p>The predictor <code class="docutils literal notranslate"><span class="pre">Insulin</span></code> has a negative coefficient which means that higher values of <code class="docutils literal notranslate"><span class="pre">Insulin</span></code> are associated with a lower probability of Diabetes Type 2. This makes sense because persons with Diabetes Type 2 have problems in making enough insulin to deal with the glucose levels in the blood.</p>
<p>The predictor <code class="docutils literal notranslate"><span class="pre">SkinThickness</span></code> does not seem to contribute to the prediction of Diabetes Type 2. This lack of association might be due to the problematic distribution of <code class="docutils literal notranslate"><span class="pre">SkinThickness</span></code>: the distribution is skewed and it has a very high peak at the value 23, which is due to imputing the median value (= 23) for all zero values. We also have seen that <code class="docutils literal notranslate"><span class="pre">SkinThickness</span></code> is positively associated with <code class="docutils literal notranslate"><span class="pre">BMI</span></code>.</p>
<p><strong>Influential observations and large residuals</strong>
The plot below shows the leverage values against the normalized residuals of the logistic regression model. There are some observations with relatively high leverage values (observations with index equal to 124 and 380), which means that they might have an influence on the regression slope. Looking at the values of these subjects (see below for the output) reveals that subject with index = 124 has a very high weight give the BMI value equal to 55 and skin thickness equal to 42 mm. Subject with index 380 has an insulin value higher than 166 wich corresponds to a “at risk” level for diabetes type 2. Given these values, one would expect that these subjects would have been diagnosed with diabetes type 2, but this is not the case.</p>
<p>Two observations have high residuals, which means that they are not well predicted by the model: the observations with index=740 and 6. Subject with index = 6 has high values for BMI and skin thickness, but low glucose and insulin values. This low (healthy) glucose value combined with high body weight and the diagnosis of diabetes type 2, might be the reason for this observation to have a high residual. For subject with index = 740 we see that this person has unhealthy values for BMI, skin thickness, glucose and insulin, but has not been diagnosed with diabetes type 2.</p>
<p>It is clear why these observations have high leverage or residual values. For the moment I decide to keep these observations in the training model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.graphics.regressionplots</span> <span class="kn">import</span> <span class="n">plot_leverage_resid2</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plot_leverage_resid2</span><span class="p">(</span><span class="n">logreg_result</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_76_0.png" src="../../_images/pima-indians-diabetes_76_0.png" />
<img alt="../../_images/pima-indians-diabetes_76_1.png" src="../../_images/pima-indians-diabetes_76_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># evaluate outliers from leverage plot</span>
<span class="n">PimaTrain</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">349</span><span class="p">,</span> <span class="mi">502</span><span class="p">],:]</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>13</th>
      <th>349</th>
      <th>502</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Pregnancies</th>
      <td>1.00</td>
      <td>5.00</td>
      <td>6.00</td>
    </tr>
    <tr>
      <th>Glucose</th>
      <td>189.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>BloodPressure</th>
      <td>60.00</td>
      <td>80.00</td>
      <td>68.00</td>
    </tr>
    <tr>
      <th>SkinThickness</th>
      <td>23.00</td>
      <td>32.00</td>
      <td>41.00</td>
    </tr>
    <tr>
      <th>Insulin</th>
      <td>846.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>BMI</th>
      <td>30.10</td>
      <td>41.00</td>
      <td>39.00</td>
    </tr>
    <tr>
      <th>DiabetesPedigreeFunction</th>
      <td>0.40</td>
      <td>0.35</td>
      <td>0.73</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>59.00</td>
      <td>37.00</td>
      <td>41.00</td>
    </tr>
    <tr>
      <th>Outcome</th>
      <td>1.00</td>
      <td>1.00</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>MahalDist</th>
      <td>66.13</td>
      <td>20.85</td>
      <td>23.05</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Confusion matrix and classification metrics</p>
<p>From the ouput of the logistic regression model, we know wich predictors are significantly associated with the diagnosis of diabetes type 2 five or more years later. But, how relevant are these results and how does the model perform in terms of predicting the diagnosis of diabetes type 2?</p>
<p>The confusion matrix shows how relevant the model is in terms of classifying the observations in the correct class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat_logreg</span> <span class="o">=</span> <span class="n">logreg_result</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> 
<span class="n">prediction_logreg</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">round</span><span class="p">,</span> <span class="n">yhat_logreg</span><span class="p">))</span> 
<span class="n">cm_logreg</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction_logreg</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Confusion matrix : </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cm_logreg</span><span class="p">)</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion matrix : 
 [[83 17]
 [19 34]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction_logreg</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.81      0.83      0.82       100
           1       0.67      0.64      0.65        53

    accuracy                           0.76       153
   macro avg       0.74      0.74      0.74       153
weighted avg       0.76      0.76      0.76       153
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="accuracy-sensitivity-and-specificity">
<h3>Accuracy, Sensitivity and Specificity<a class="headerlink" href="#accuracy-sensitivity-and-specificity" title="Permalink to this headline">¶</a></h3>
<p>Since <code class="docutils literal notranslate"><span class="pre">scikit</span></code> does not have specificity as metric, I make a customized function to calculate the specificity from the output of the <code class="docutils literal notranslate"><span class="pre">confusion_matrix</span></code> module. With the True Negatives, True Positives, False Negatives and True Positives, I calculate the accuracy, sensitivity and specificity.</p>
<p>The results below show that the logistic regression model has a sensitivity equal to 0.55, which means that the model does a poor job in correctly predicting the Diabetes cases in the test set. For the non-diabetes cases, the model does a much better job with a specificity equal to 0.86.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_acc_sens_spec</span><span class="p">(</span><span class="n">output_confusion_matrix</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the accuracy, sensitivity and specificity.</span>
<span class="sd">    </span>
<span class="sd">    Input is de output (object) of the module confusion_matrix.&quot;&quot;&quot;</span>
    <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">TP</span> <span class="o">=</span> <span class="n">output_confusion_matrix</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">Accuracy</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(((</span><span class="n">TP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">TN</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)),</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">Sensitivity</span> <span class="o">=</span> <span class="nb">round</span><span class="p">((</span><span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)),</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">Specificity</span> <span class="o">=</span> <span class="nb">round</span><span class="p">((</span><span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)),</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Accuracy</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">,</span> <span class="n">Specificity</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Accuracy</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">,</span> <span class="n">Specificity</span> <span class="o">=</span> <span class="n">compute_acc_sens_spec</span><span class="p">(</span><span class="n">cm_logreg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy =&quot;</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sensitivity =&quot;</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Specificity =&quot;</span><span class="p">,</span> <span class="n">Specificity</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy = 0.76
Sensitivity = 0.64
Specificity = 0.83
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="lasso">
<h3>Lasso<a class="headerlink" href="#lasso" title="Permalink to this headline">¶</a></h3>
<p>As expected, the lasso does not provide any new insights and the results largely correspond to the results of the logistic regression. The non-zero coefficients of the Lasso solution correspond to the statistically significant coefficients in the logistic regression model. The sensitivity of the Lasso model is the same as the logistic regression model (0.55).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lassocv</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">lassocv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred_lassocv</span> <span class="o">=</span> <span class="n">lassocv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">Coefcv</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">lassocv</span><span class="o">.</span><span class="n">coef_</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train_scaled</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Coefcv</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pregnancies                 0.257557
Insulin                     0.138475
BMI                         0.091263
DiabetesPedigreeFunction    0.035476
Age                         0.012729
BloodPressure               0.000423
Glucose                     0.000000
SkinThickness               0.000000
MahalDist                   0.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred_lasso_bin</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pred_lassocv</span><span class="p">]</span>
<span class="n">cm_lasso</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_lasso_bin</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm_lasso</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[85 15]
 [23 30]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_lasso_bin</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.79      0.85      0.82       100
           1       0.67      0.57      0.61        53

    accuracy                           0.75       153
   macro avg       0.73      0.71      0.71       153
weighted avg       0.75      0.75      0.75       153
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Accuracy</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">,</span> <span class="n">Specificity</span> <span class="o">=</span> <span class="n">compute_acc_sens_spec</span><span class="p">(</span><span class="n">cm_lasso</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy =&quot;</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sensitivity =&quot;</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Specificity =&quot;</span><span class="p">,</span> <span class="n">Specificity</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy = 0.75
Sensitivity = 0.57
Specificity = 0.85
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="k-nearest-neighbors">
<h3>K-nearest neighbors<a class="headerlink" href="#k-nearest-neighbors" title="Permalink to this headline">¶</a></h3>
<p>The results of the K-nearest neighbors model do not show any improvement with a senstitivity equal to 0.53 and a specificity equalt to 0.77</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">KNN_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">pred_KNN</span> <span class="o">=</span> <span class="n">KNN_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm_KNN</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_KNN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm_KNN</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[86 14]
 [25 28]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">KNN_model</span><span class="p">,</span> <span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>   
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_92_0.png" src="../../_images/pima-indians-diabetes_92_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_KNN</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.77      0.86      0.82       100
           1       0.67      0.53      0.59        53

    accuracy                           0.75       153
   macro avg       0.72      0.69      0.70       153
weighted avg       0.74      0.75      0.74       153
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Accuracy</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">,</span> <span class="n">Specificity</span> <span class="o">=</span> <span class="n">compute_acc_sens_spec</span><span class="p">(</span><span class="n">cm_KNN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy =&quot;</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sensitivity =&quot;</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Specificity =&quot;</span><span class="p">,</span> <span class="n">Specificity</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy = 0.75
Sensitivity = 0.53
Specificity = 0.86
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="naive-bayes-classifier">
<h3>Naive Bayes classifier<a class="headerlink" href="#naive-bayes-classifier" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">NB_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">pred_NB</span> <span class="o">=</span> <span class="n">NB_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm_NB</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_NB</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm_NB</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[83 17]
 [21 32]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">NB_model</span><span class="p">,</span> <span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>   
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_98_0.png" src="../../_images/pima-indians-diabetes_98_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_NB</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.80      0.83      0.81       100
           1       0.65      0.60      0.63        53

    accuracy                           0.75       153
   macro avg       0.73      0.72      0.72       153
weighted avg       0.75      0.75      0.75       153
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Accuracy</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">,</span> <span class="n">Specificity</span> <span class="o">=</span> <span class="n">compute_acc_sens_spec</span><span class="p">(</span><span class="n">cm_NB</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy =&quot;</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sensitivity =&quot;</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Specificity =&quot;</span><span class="p">,</span> <span class="n">Specificity</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy = 0.75
Sensitivity = 0.6
Specificity = 0.83
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="random-forest-classifier">
<h3>Random Forest Classifier<a class="headerlink" href="#random-forest-classifier" title="Permalink to this headline">¶</a></h3>
<p>The Random Forrest classifier shows some improvement in correctly predicting the diabetes cases in the test set with a sensitivity equal to 0.60. The non-cases are correctly predicted with a specificity value equal to 0.82.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">RFmodel</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span> 
<span class="n">RFmodel_fit</span> <span class="o">=</span> <span class="n">RFmodel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">RFmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm_RF</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">RFmodel</span><span class="p">,</span> <span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_104_0.png" src="../../_images/pima-indians-diabetes_104_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.78      0.84      0.81       100
           1       0.64      0.55      0.59        53

    accuracy                           0.74       153
   macro avg       0.71      0.69      0.70       153
weighted avg       0.73      0.74      0.73       153
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Accuracy</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">,</span> <span class="n">Specificity</span> <span class="o">=</span> <span class="n">compute_acc_sens_spec</span><span class="p">(</span><span class="n">cm_RF</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy =&quot;</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sensitivity =&quot;</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Specificity =&quot;</span><span class="p">,</span> <span class="n">Specificity</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy = 0.74
Sensitivity = 0.55
Specificity = 0.84
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="gradient-boosting-classifier">
<h3>Gradient Boosting Classifier<a class="headerlink" href="#gradient-boosting-classifier" title="Permalink to this headline">¶</a></h3>
<p>The results of Gradient Boosting show that the sensitivity improves to a value of 0.70, but still not enough to be of any practical use. The specificity is 0.76, which is lower than the specificity attained by the random forrest classifier.</p>
<p>Sofar Gradient Boosting provides the best results. With the use of the <code class="docutils literal notranslate"><span class="pre">Shap</span></code> module (see results below), we get insight in which variables play the most important role. The three most important variables are <code class="docutils literal notranslate"><span class="pre">Glucose</span></code>, <code class="docutils literal notranslate"><span class="pre">BMI</span></code> and <code class="docutils literal notranslate"><span class="pre">Age</span></code>. Higher values on these variables are related to a higher risk of being diagnosed with Diabetes-Type 2.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GBmodel</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span> 
<span class="n">GBmodel_fit</span> <span class="o">=</span> <span class="n">GBmodel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">GBmodel_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm_GB</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm_GB</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[78 22]
 [19 34]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">GBmodel</span><span class="p">,</span> <span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_110_0.png" src="../../_images/pima-indians-diabetes_110_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.80      0.78      0.79       100
           1       0.61      0.64      0.62        53

    accuracy                           0.73       153
   macro avg       0.71      0.71      0.71       153
weighted avg       0.74      0.73      0.73       153
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Accuracy</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">,</span> <span class="n">Specificity</span> <span class="o">=</span> <span class="n">compute_acc_sens_spec</span><span class="p">(</span><span class="n">cm_GB</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy =&quot;</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sensitivity =&quot;</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Specificity =&quot;</span><span class="p">,</span> <span class="n">Specificity</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy = 0.73
Sensitivity = 0.64
Specificity = 0.78
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create object that can calculate shap values</span>
<span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">RFmodel</span><span class="p">)</span>

<span class="c1"># Calculate shap_values for all of val_X rather than a single row, to have more data for plot.</span>
<span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_test_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/pima-indians-diabetes_113_0.png" src="../../_images/pima-indians-diabetes_113_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="summary-of-the-results">
<h2>Summary of the results<a class="headerlink" href="#summary-of-the-results" title="Permalink to this headline">¶</a></h2>
<p>The results of the models in terms of <em>accuracy</em> and <em>precision</em> will be summarized in a data frame. To obtain this overview we construct a loop to fit all the models at once. To evaluate the models, a data frame is constructed with the values for Accuracy, Senstitivity and Specificity for each model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># prepare empty lists for the metrics. These lists will be the columns in a dataframe presenting the results.</span>
<span class="n">Accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Sensitivity</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Specificity</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># prepare a list of machine learning models.</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">),</span> <span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">GaussianNB</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e6</span><span class="p">),</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">),</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">)]</span>

<span class="c1"># prepare a list with the names of the machine learning models for the dataframe with the results</span>
<span class="n">classifiers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Logistic Regression&#39;</span><span class="p">,</span> <span class="s1">&#39;KNN&#39;</span><span class="p">,</span> <span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span><span class="s1">&#39;Lasso&#39;</span><span class="p">,</span> <span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient Boosting&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># A for loop to fit all the models defined in the previous step and to present the results in a dataframe.</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">CM</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">compute_acc_sens_spec</span><span class="p">(</span><span class="n">CM</span><span class="p">)</span>
    <span class="n">Accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">Sensitivity</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">Specificity</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># new code suggested by Jan Deknatel (https://github.com/knaat): much better, thanks!!</span>
<span class="n">dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
<span class="p">{</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">,</span>
<span class="s1">&#39;Sensitivity&#39;</span><span class="p">:</span> <span class="n">Sensitivity</span><span class="p">,</span>
<span class="s1">&#39;Specificity&#39;</span><span class="p">:</span> <span class="n">Specificity</span><span class="p">},</span> 
<span class="n">index</span><span class="o">=</span><span class="n">classifiers</span><span class="p">)</span>

<span class="n">dataframe</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Accuracy</th>
      <th>Sensitivity</th>
      <th>Specificity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Logistic Regression</th>
      <td>0.74</td>
      <td>0.57</td>
      <td>0.83</td>
    </tr>
    <tr>
      <th>KNN</th>
      <td>0.75</td>
      <td>0.53</td>
      <td>0.87</td>
    </tr>
    <tr>
      <th>Naive Bayes</th>
      <td>0.75</td>
      <td>0.60</td>
      <td>0.83</td>
    </tr>
    <tr>
      <th>Lasso</th>
      <td>0.75</td>
      <td>0.58</td>
      <td>0.83</td>
    </tr>
    <tr>
      <th>Random Forest</th>
      <td>0.74</td>
      <td>0.55</td>
      <td>0.84</td>
    </tr>
    <tr>
      <th>Gradient Boosting</th>
      <td>0.73</td>
      <td>0.64</td>
      <td>0.78</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="interpretation-of-the-results">
<h2>Interpretation of the results<a class="headerlink" href="#interpretation-of-the-results" title="Permalink to this headline">¶</a></h2>
<p>The overview of the results of the different machine learning models shows that none of the models achieves good results. Especially the sensitivity, the ability to predict the Diabetes Type-2 correctly, is lower than the other performance measures for all models. All models achieve better results in correctly predicting the healthy cases, compared to the Diabetes Type-2 cases (the minority class). Logistic regression, KNN and the Lasso all have sensitivity values equal to 0.57, which is quite low. The best result in terms of sensitivity was achieved by Gradient Boosting, with a sensitivity value of 0.70.</p>
<div class="section" id="comment-from-daniel">
<h3>Comment from Daniel<a class="headerlink" href="#comment-from-daniel" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Given that you haven’t used gridsearch and cross-validation yet, I think the results are pretty OK</p></li>
<li><p>What I like is that you have taken a more statistical approach, carefully looking at the descriptive statistics</p></li>
<li><p>To compare have a look at <a class="reference external" href="https://www.openml.org/t/37">https://www.openml.org/t/37</a> for best performing models</p>
<ul>
<li><p>Accuracy: 0.775</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="crisp-dm-phase-5-evaluation">
<h2>CRISP-DM Phase 5: Evaluation<a class="headerlink" href="#crisp-dm-phase-5-evaluation" title="Permalink to this headline">¶</a></h2>
<p>In general the results so far are not very good. The models fitted do not achieve satisfying results in predicting the Diabetes Type-2 cases. The following strategies might improve the prediction properties of the models.</p>
<p><strong>Transformation of predictor variables</strong></p>
<p>The distributions of some of the predictors are very skewed. Maybe categorizing the predictors in a clever way might improve the prediction properties of the models. For example the predictor <code class="docutils literal notranslate"><span class="pre">Insulin</span></code> has a very deviant distribution and could be transformed in a binary (0,1) variable for healthy versus unhealthy insulin values. Howver, in general, categorizing continuous variables is not a good idea,see for example this reference:
<a class="reference external" href="https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-12-21">https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-12-21</a></p>
<blockquote>
<div><p>Categorization of continuously distributed exposure variables is associated with three problems: first, it involves multiple hypothesis testing with pairwise comparisons of quantiles; second, it requires an unrealistic step-function of risk that assumes homogeneity of risk within groups, leading to both a loss of power and inaccurate estimation; and third, it leads to difficulty comparing results across studies due to the data-driven cut points used to define categories.</p>
</div></blockquote>
<p><strong>SMOTE sampling</strong></p>
<p>Since the models appear to have more difficulty predicting the minority class (the diabetes type-2 cases), SMOTE sampling could be helpful.</p>
<p><strong>Model tuning, grid search</strong></p>
<p>Perhaps better results can be achieved with better model tuning and grid search.</p>
</div>
<div class="section" id="back-to-modeling-phase-4-transform-some-predictor-variables">
<h2>Back to Modeling Phase 4: Transform some predictor variables<a class="headerlink" href="#back-to-modeling-phase-4-transform-some-predictor-variables" title="Permalink to this headline">¶</a></h2>
<p>The following predictors have skewed distributions and will be transformed depending on the degree of skewness:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Pregnancies</span></code>: square root transformation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Insulin</span></code>: inverse transformation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DiabetesPedigreeFunction</span></code>: square root transformation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Age</span></code>: log10 transformation.</p></li>
</ul>
<div class="section" id="logistic-regression-with-transformed-predictors">
<h3>Logistic regression with transformed predictors<a class="headerlink" href="#logistic-regression-with-transformed-predictors" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_T</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;T_Pregnancies&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;Pregnancies&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;T_Insulin&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;Insulin&quot;</span><span class="p">])</span>
<span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;T_DiabetesPedigreeFunction&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;DiabetesPedigreeFunction&quot;</span><span class="p">])</span>
<span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;T_Age&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;Age&quot;</span><span class="p">])</span>
<span class="c1">#X_train_T[&quot;T_Age&quot;] = 1/(X_train_T[&quot;Age&quot;])</span>

<span class="c1"># Included the scaled predictors in the data set.</span>
<span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;Glucose&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train_scale</span><span class="p">[</span><span class="s2">&quot;Glucose&quot;</span><span class="p">]</span>
<span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;BloodPressure&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train_scale</span><span class="p">[</span><span class="s2">&quot;BloodPressure&quot;</span><span class="p">]</span>
<span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;SkinThickness&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train_scale</span><span class="p">[</span><span class="s2">&quot;SkinThickness&quot;</span><span class="p">]</span>
<span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;BMI&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train_scale</span><span class="p">[</span><span class="s2">&quot;BMI&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">colstodrop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Pregnancies&quot;</span><span class="p">,</span> <span class="s2">&quot;Insulin&quot;</span><span class="p">,</span> <span class="s2">&quot;DiabetesPedigreeFunction&quot;</span><span class="p">,</span> <span class="s2">&quot;Age&quot;</span><span class="p">]</span>
<span class="n">X_train_T</span> <span class="o">=</span> <span class="n">X_train_T</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">colstodrop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cols_train</span> <span class="o">=</span> <span class="n">X_train_T</span><span class="o">.</span><span class="n">columns</span>
<span class="n">index_train</span> <span class="o">=</span> <span class="n">X_train_T</span><span class="o">.</span><span class="n">index</span>
<span class="c1">#X_train_T.head()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;T_Pregnancies&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;T_Insulin&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;T_DiabetesPedigreeFunction&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_T</span><span class="p">[</span><span class="s2">&quot;T_Age&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="conclusions-transformation-plots">
<h3>Conclusions transformation plots<a class="headerlink" href="#conclusions-transformation-plots" title="Permalink to this headline">¶</a></h3>
<p>The distributions improved slightly after transformation. The <code class="docutils literal notranslate"><span class="pre">DiabetesPedigreeFunction</span></code> improved a bit and <code class="docutils literal notranslate"><span class="pre">Pregnancies</span></code> as well, but <code class="docutils literal notranslate"><span class="pre">Insulin</span></code> is still problematic.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Train_T</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train_T</span><span class="p">,</span> <span class="n">y_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#Train_T.head()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test_T</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;T_Pregnancies&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;Pregnancies&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;T_Insulin&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;Insulin&quot;</span><span class="p">])</span>
<span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;T_DiabetesPedigreeFunction&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;DiabetesPedigreeFunction&quot;</span><span class="p">])</span>
<span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;T_Age&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;Age&quot;</span><span class="p">])</span>
<span class="c1">#X_train_T[&quot;T_Age&quot;] = 1/(X_train_T[&quot;Age&quot;])</span>
<span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;Glucose&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_test_scale</span><span class="p">[</span><span class="s2">&quot;Glucose&quot;</span><span class="p">]</span>
<span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;BloodPressure&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_test_scale</span><span class="p">[</span><span class="s2">&quot;BloodPressure&quot;</span><span class="p">]</span>
<span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;SkinThickness&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_test_scale</span><span class="p">[</span><span class="s2">&quot;SkinThickness&quot;</span><span class="p">]</span>
<span class="n">X_test_T</span><span class="p">[</span><span class="s2">&quot;BMI&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_test_scale</span><span class="p">[</span><span class="s2">&quot;BMI&quot;</span><span class="p">]</span>

<span class="c1">#X_test_T.info()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">colstodrop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Pregnancies&quot;</span><span class="p">,</span> <span class="s2">&quot;Insulin&quot;</span><span class="p">,</span> <span class="s2">&quot;DiabetesPedigreeFunction&quot;</span><span class="p">,</span> <span class="s2">&quot;Age&quot;</span><span class="p">]</span>
<span class="n">X_test_T</span> <span class="o">=</span> <span class="n">X_test_T</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">colstodrop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#X_test_T.head()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Test_T</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test_T</span><span class="p">,</span> <span class="n">y_test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#Test_T.head()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># To use the statsmodels module the logistic regression model is defined with </span>
<span class="c1"># the tilde notation that is used in R for (generalized) linear models.</span>

<span class="n">formula_t</span> <span class="o">=</span> <span class="s1">&#39;Outcome ~ T_Pregnancies + Glucose + BloodPressure + SkinThickness + T_Insulin + BMI + T_DiabetesPedigreeFunction + T_Age&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_t</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula_t</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">Train_T</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Binomial</span><span class="p">())</span>
<span class="n">result_t</span> <span class="o">=</span> <span class="n">model_t</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_t</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat_logreg_t</span> <span class="o">=</span> <span class="n">result_t</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_T</span><span class="p">)</span> 
<span class="n">prediction_logreg_t</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">round</span><span class="p">,</span> <span class="n">yhat_logreg_t</span><span class="p">))</span> 
<span class="n">cm_logreg_t</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction_logreg_t</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Confusion matrix : </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cm_logreg_t</span><span class="p">)</span>  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction_logreg_t</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Accuracy</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">,</span> <span class="n">Specificity</span> <span class="o">=</span> <span class="n">Compute_Acc_Sens_Spec</span><span class="p">(</span><span class="n">cm_logreg_t</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy =&quot;</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sensitivity =&quot;</span><span class="p">,</span> <span class="n">Sensitivity</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Specificity =&quot;</span><span class="p">,</span> <span class="n">Specificity</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="run-all-models-on-transformed-predictor-variables">
<h3>Run all models on transformed predictor variables<a class="headerlink" href="#run-all-models-on-transformed-predictor-variables" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># prepare empty lists for the metrics. These lists will be the columns in a dataframe presenting the results.</span>
<span class="n">Accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Sensitivity</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Specificity</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># prepare a list of machine learning models.</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">),</span> <span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">GaussianNB</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e6</span><span class="p">),</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">),</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">SEED</span><span class="p">)]</span>

<span class="c1"># prepare a list with the names of the machine learning models for the dataframe with the results</span>
<span class="n">classifiers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Logistic Regression&#39;</span><span class="p">,</span> <span class="s1">&#39;KNN&#39;</span><span class="p">,</span> <span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span> <span class="s1">&#39;Lasso&#39;</span><span class="p">,</span> <span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient Boosting&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># A for loop to fit all the models defined in the previous step and to present the results in a dataframe.</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_T</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_T</span><span class="p">)</span>
    <span class="n">CM</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">Compute_Acc_Sens_Spec</span><span class="p">(</span><span class="n">CM</span><span class="p">)</span>
    <span class="n">Accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">Sensitivity</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">Specificity</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="c1"># the following lines of code are not very efficient, but they work. I am sure</span>
    <span class="c1"># this can be done in a much more clever and efficient way, but I do not know how.</span>

<span class="n">dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
<span class="p">{</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">,</span>
<span class="s1">&#39;Sensitivity&#39;</span><span class="p">:</span> <span class="n">Sensitivity</span><span class="p">,</span>
<span class="s1">&#39;Specificity&#39;</span><span class="p">:</span> <span class="n">Specificity</span><span class="p">},</span> 
<span class="n">index</span><span class="o">=</span><span class="n">classifiers</span><span class="p">)</span>

<span class="n">dataframe</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="conclusions-transformed-variables">
<h3>Conclusions transformed variables<a class="headerlink" href="#conclusions-transformed-variables" title="Permalink to this headline">¶</a></h3>
<p>The results of the logistic regression with the transformed variables show that the sensitivity does not improve. Maybe try categorizing some of the predictor variables, work in progress.</p>
</div>
<div class="section" id="work-in-progress-smote-sampling">
<h3>Work in progress: SMOTE sampling<a class="headerlink" href="#work-in-progress-smote-sampling" title="Permalink to this headline">¶</a></h3>
<p>Somehow, the SMOTE module does not work.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">imblearn</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">os</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">columns</span> <span class="o">=</span> <span class="n">X_train_scale</span><span class="o">.</span><span class="n">columns</span>
<span class="n">os_data_X</span><span class="p">,</span> <span class="n">os_data_y</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X_train_scale</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">os_data_X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">os_data_X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span> <span class="p">)</span>
<span class="n">os_data_y</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">os_data_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="work-in-progress-explanation-of-the-models">
<h3>Work in progress: explanation of the models<a class="headerlink" href="#work-in-progress-explanation-of-the-models" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">eli5</span></code> module does not work …</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ik krijg de eli5 module niet aan de praat. Ik heb de module geïnstalleerd met</span>
<span class="c1"># pip en met anaconda, maar het werkt nog steeds niet.</span>

<span class="c1">#import eli5</span>
<span class="c1">#from eli5.sklearn import PermutationImportance</span>

<span class="c1">#perm = PermutationImportance(lasso, random_state=1).fit(X_test_scale, y_test)</span>
<span class="c1">#eli5.show_weights(perm, feature_names = X_test_scale.columns.tolist())</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./handson-ml2/extra"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="ames-housing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Ames Housing case - examples of possible solutions</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../visualization/introduction-to-interactive-data-visualization.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction to data visualization with Python</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Daniel Kapitan<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>