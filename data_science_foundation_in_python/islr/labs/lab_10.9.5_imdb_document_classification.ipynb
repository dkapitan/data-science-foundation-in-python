{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-c3d2649b-a67f-44be-a87d-e61b8abaa9d6",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 10.9.5: IMDb Document Classification\n",
    "\n",
    "## Attribution\n",
    "This notebook follows lab 10.9.5 from ISLRv2. The R-code has been ported to Python by Daniel Kapitan (23-01-2022).\n",
    "\n",
    "\n",
    "## Data preparation\n",
    "We perform document classification on the IMDb dataset, which is available as part of the `tensorflow.keras` package. We limit the dictionary size to the 10,000 most frequently-used words and tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00006-9cef16a3-6c4c-45de-bac9-98e8dcad8a7a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13744,
    "execution_start": 1641642487437,
    "nextjournal": {
     "id": "775267f3-e650-4a2c-88f0-f1bf548dc1bf",
     "kind": "code",
     "language": "python"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "3bd01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 15:50:57.967465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-30 15:50:57.967504: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "# let's keep our keras backend tensorflow quiet\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# load the data\n",
    "MAX_FEATURES = 10_000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The last line is a shortcut for unpacking the list of lists. Each element of `X_train` is a vector of numbers between 0 and 9999 (the document), referring to the words found in the dictionary. For example, the first training document is the positive review on page 419 of ISLRv2. The indices of the first 12 words are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00006-9cef16a3-6c4c-45de-bac9-98e8dcad8a7a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13744,
    "execution_start": 1641642487437,
    "nextjournal": {
     "id": "775267f3-e650-4a2c-88f0-f1bf548dc1bf",
     "kind": "code",
     "language": "python"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "3bd01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1][:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-eac006c5-bbe3-467c-8452-e22e6a77aac4",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To see the words, we create a function, `decode_review()`, that provides a simple interface to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def decode_review(text, word_index=word_index, start_char=1, oov_char=2, index_from=3):\n",
    "    \"\"\"Decodes one-hot encoded reviews from IMDb.\n",
    "    \n",
    "    Note default values for `imdb.load_data`, see https://keras.io/api/datasets/imdb/\n",
    "    \"\"\"\n",
    "    reverse_word_index = {v + index_from: k for k, v in word_index.items()}\n",
    "\n",
    "    # add special tags\n",
    "    tags = {0: \"<PAD>\", start_char: \"<START>\", oov_char: \"<UNK>\"}\n",
    "    reverse_word_index = {**tags, **reverse_word_index}\n",
    "\n",
    "    return \" \".join([reverse_word_index.get(i, \"<index not found>\") for i in text])\n",
    "\n",
    "\n",
    "decode_review(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using spare binary matrices\n",
    "\n",
    "Next we write a function to \"one-hot\" encode each document in a list of documents, and return a binary matrix in sparse-matrix format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00010-981ee8f4-902b-48f4-a828-56b3931a8894",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     269,
     269
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2713,
    "execution_start": 1641642501212,
    "nextjournal": {
     "id": "1bd5b5a5-b173-486f-afb2-cc6236d1bc25",
     "kind": "code",
     "language": "python"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "b2d52342"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(sequences, dimension=MAX_FEATURES):\n",
    "    \"\"\" One-hot encodes IMDb reviews as SciPy sparse matrix.\n",
    "    \n",
    "    Using csr_matrix, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix\n",
    "    For more on sparse matrices, see https://machinelearningmastery.com/sparse-matrices-for-machine-learning/\n",
    "    \"\"\"\n",
    "    seqlen = [len(sequence) for sequence in sequences]\n",
    "    n = len(seqlen)\n",
    "    row_index = np.repeat(range(n), seqlen)\n",
    "    col_index = list(itertools.chain(*sequences))\n",
    "    data = np.ones(len(row_index), dtype=\"int\")\n",
    "    return csr_matrix((data, (row_index, col_index)), shape=(n, dimension))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To construct the matrix, one supplies just the entries that are nonzero. In the last line we call [`csr_matrix()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) and supply the row indices corresponding to each document and the column indices corresponding to the words in each document. `data` is literally a list of ones. Words that appear more than once in any given document still get recorded as one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00010-981ee8f4-902b-48f4-a828-56b3931a8894",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     269,
     269
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2713,
    "execution_start": 1641642501212,
    "nextjournal": {
     "id": "1bd5b5a5-b173-486f-afb2-cc6236d1bc25",
     "kind": "code",
     "language": "python"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "b2d52342"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1h = one_hot_encode(X_train)\n",
    "X_test_1h = one_hot_encode(X_test)\n",
    "y_train = np.array(y_train).astype(\"float32\")\n",
    "y_test = np.array(y_test).astype(\"float32\")\n",
    "\n",
    "X_train_1h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023871364"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: don't understand why we get 2.3% non zeros\n",
    "X_train_1h.sum().sum() / (25_000 * 10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-96f7d338-65cd-4119-9125-d65050a1bb10",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Only 1.3% of the entries are nonzero, so this amounts to considerable savings in memory. We create a validation set of size 2,000, leaving 23,000 for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fit Lasso Logistic Regression\n",
    "\n",
    "First we fit a lasso logistic regression model using `sklearn.linear_model.LogisticRegression()` on the training data, and evaluate its performance on the validation data. In order to plot the accuracy as a function of the shrinkage parameter $\\lambda$, we iterate over different values of $-log \\lambda = [1, 2, .. 20]$. Note that `sklearn` uses `C` as the regularization parameter, which is the inverse of lambda. Similar espressions compute the performance on the test data, and were used to produce the left plot in Figure 10.11. The code takes advantage of the sparse-matrix format of `x_train_1h`and runs in about two minutes; in the usual dense format it would take about over orders of magnitude longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "ival = sorted(np.random.choice(range(len(y_train)), 2000))\n",
    "mask = np.ones_like(y_train, dtype=bool)\n",
    "mask[ival] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting LogisticRegression with C = 0.707\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.500\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.354\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.250\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.177\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.125\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.088\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.062\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.044\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.031\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.022\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.016\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.011\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.008\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.006\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.004\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.003\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.002\n",
      "... done\n",
      "fitting LogisticRegression with C = 0.001\n",
      "... done\n",
      "CPU times: user 7min 7s, sys: 10.7 s, total: 7min 18s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = {}\n",
    "for log_lambda in range(1, 20):\n",
    "    C = 1 / (2 ** ((log_lambda / 2)))\n",
    "    print(f\"fitting LogisticRegression with C = {C:.3f}\")\n",
    "    models[C] = LogisticRegression(C=C, max_iter=1000, random_state=0).fit(\n",
    "        X_train_1h[mask, :], y_train[mask]\n",
    "    )\n",
    "    print(\"... done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f0162d82b84e4a0287c566645d0d6156\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f0162d82b84e4a0287c566645d0d6156\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f0162d82b84e4a0287c566645d0d6156\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-1985962adc524fc237519aae4aa7972a\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"fold\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"log_C\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"accuracy\"}}, \"transform\": [{\"calculate\": \"log(datum.C)\", \"as\": \"log_C\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-1985962adc524fc237519aae4aa7972a\": [{\"C\": 0.7071067811865475, \"fold\": \"train\", \"accuracy\": 0.9907732293697206}, {\"C\": 0.7071067811865475, \"fold\": \"validation\", \"accuracy\": 0.8745}, {\"C\": 0.5, \"fold\": \"train\", \"accuracy\": 0.9873944119558155}, {\"C\": 0.5, \"fold\": \"validation\", \"accuracy\": 0.877}, {\"C\": 0.35355339059327373, \"fold\": \"train\", \"accuracy\": 0.9829759584145549}, {\"C\": 0.35355339059327373, \"fold\": \"validation\", \"accuracy\": 0.8775}, {\"C\": 0.25, \"fold\": \"train\", \"accuracy\": 0.9776911414338315}, {\"C\": 0.25, \"fold\": \"validation\", \"accuracy\": 0.8805}, {\"C\": 0.17677669529663687, \"fold\": \"train\", \"accuracy\": 0.972666233484947}, {\"C\": 0.17677669529663687, \"fold\": \"validation\", \"accuracy\": 0.884}, {\"C\": 0.125, \"fold\": \"train\", \"accuracy\": 0.9672514619883041}, {\"C\": 0.125, \"fold\": \"validation\", \"accuracy\": 0.885}, {\"C\": 0.08838834764831843, \"fold\": \"train\", \"accuracy\": 0.9611869179120641}, {\"C\": 0.08838834764831843, \"fold\": \"validation\", \"accuracy\": 0.8865}, {\"C\": 0.0625, \"fold\": \"train\", \"accuracy\": 0.9548191466320122}, {\"C\": 0.0625, \"fold\": \"validation\", \"accuracy\": 0.8845}, {\"C\": 0.044194173824159216, \"fold\": \"train\", \"accuracy\": 0.948104829976175}, {\"C\": 0.044194173824159216, \"fold\": \"validation\", \"accuracy\": 0.887}, {\"C\": 0.03125, \"fold\": \"train\", \"accuracy\": 0.9415637860082304}, {\"C\": 0.03125, \"fold\": \"validation\", \"accuracy\": 0.8875}, {\"C\": 0.022097086912079608, \"fold\": \"train\", \"accuracy\": 0.9346761966645007}, {\"C\": 0.022097086912079608, \"fold\": \"validation\", \"accuracy\": 0.889}, {\"C\": 0.015625, \"fold\": \"train\", \"accuracy\": 0.927745289148798}, {\"C\": 0.015625, \"fold\": \"validation\", \"accuracy\": 0.8865}, {\"C\": 0.011048543456039804, \"fold\": \"train\", \"accuracy\": 0.9199913363656054}, {\"C\": 0.011048543456039804, \"fold\": \"validation\", \"accuracy\": 0.884}, {\"C\": 0.0078125, \"fold\": \"train\", \"accuracy\": 0.9127138834741174}, {\"C\": 0.0078125, \"fold\": \"validation\", \"accuracy\": 0.879}, {\"C\": 0.005524271728019902, \"fold\": \"train\", \"accuracy\": 0.9050898852068443}, {\"C\": 0.005524271728019902, \"fold\": \"validation\", \"accuracy\": 0.871}, {\"C\": 0.00390625, \"fold\": \"train\", \"accuracy\": 0.8972926142516786}, {\"C\": 0.00390625, \"fold\": \"validation\", \"accuracy\": 0.866}, {\"C\": 0.002762135864009951, \"fold\": \"train\", \"accuracy\": 0.8887589343729695}, {\"C\": 0.002762135864009951, \"fold\": \"validation\", \"accuracy\": 0.8585}, {\"C\": 0.001953125, \"fold\": \"train\", \"accuracy\": 0.8815681178254278}, {\"C\": 0.001953125, \"fold\": \"validation\", \"accuracy\": 0.8535}, {\"C\": 0.0013810679320049755, \"fold\": \"train\", \"accuracy\": 0.8726878925709335}, {\"C\": 0.0013810679320049755, \"fold\": \"validation\", \"accuracy\": 0.849}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = [\n",
    "    (\n",
    "        (k, \"train\", accuracy_score(y_train[mask], v.predict(X_train_1h[mask, :]))),\n",
    "        (\n",
    "            k,\n",
    "            \"validation\",\n",
    "            accuracy_score(y_train[ival], v.predict(X_train_1h[ival, :])),\n",
    "        ),\n",
    "    )\n",
    "    for k, v in models.items()\n",
    "]\n",
    "df_lr = pd.DataFrame(itertools.chain(*accuracy), columns=[\"C\", \"fold\", \"accuracy\"])\n",
    "plot_lr = (\n",
    "    alt.Chart(df_lr)\n",
    "    .mark_line(point=True)\n",
    "    .encode(x=\"log_C:Q\", y=\"accuracy\", color=\"fold\")\n",
    "    .transform_calculate(log_C=\"log(datum.C)\")\n",
    ")\n",
    "plot_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Build a two-layer feedforward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00020-a4001ec9-212a-4861-a332-a9b4ec57c15d",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     606.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1610,
    "execution_start": 1641642505414,
    "nextjournal": {
     "id": "abbee50a-1c94-4887-bc63-cdcaa813c385",
     "kind": "code",
     "language": "python"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "c6b1ee87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                160016    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,305\n",
      "Trainable params: 160,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 15:52:30.954388: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-30 15:52:30.954466: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-30 15:52:30.954484: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (xps): /proc/driver/nvidia/version does not exist\n",
      "2022-01-30 15:52:30.954748: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(10_000,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dkapitan/.pyenv/versions/anaconda3-2021.11/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 - 1s - loss: 0.4849 - accuracy: 0.7867 - val_loss: 0.3485 - val_accuracy: 0.8660 - 1s/epoch - 23ms/step\n",
      "Epoch 2/20\n",
      "46/46 - 1s - loss: 0.2904 - accuracy: 0.8960 - val_loss: 0.3154 - val_accuracy: 0.8820 - 510ms/epoch - 11ms/step\n",
      "Epoch 3/20\n",
      "46/46 - 1s - loss: 0.2308 - accuracy: 0.9173 - val_loss: 0.2743 - val_accuracy: 0.8960 - 505ms/epoch - 11ms/step\n",
      "Epoch 4/20\n",
      "46/46 - 0s - loss: 0.1845 - accuracy: 0.9356 - val_loss: 0.3411 - val_accuracy: 0.8770 - 468ms/epoch - 10ms/step\n",
      "Epoch 5/20\n",
      "46/46 - 0s - loss: 0.1631 - accuracy: 0.9430 - val_loss: 0.3482 - val_accuracy: 0.8775 - 466ms/epoch - 10ms/step\n",
      "Epoch 6/20\n",
      "46/46 - 0s - loss: 0.1378 - accuracy: 0.9535 - val_loss: 0.3105 - val_accuracy: 0.8855 - 466ms/epoch - 10ms/step\n",
      "Epoch 7/20\n",
      "46/46 - 1s - loss: 0.1241 - accuracy: 0.9572 - val_loss: 0.4187 - val_accuracy: 0.8695 - 505ms/epoch - 11ms/step\n",
      "Epoch 8/20\n",
      "46/46 - 1s - loss: 0.1054 - accuracy: 0.9640 - val_loss: 0.3438 - val_accuracy: 0.8825 - 508ms/epoch - 11ms/step\n",
      "Epoch 9/20\n",
      "46/46 - 0s - loss: 0.0923 - accuracy: 0.9691 - val_loss: 0.3786 - val_accuracy: 0.8775 - 461ms/epoch - 10ms/step\n",
      "Epoch 10/20\n",
      "46/46 - 0s - loss: 0.0794 - accuracy: 0.9742 - val_loss: 0.3914 - val_accuracy: 0.8760 - 470ms/epoch - 10ms/step\n",
      "Epoch 11/20\n",
      "46/46 - 0s - loss: 0.0714 - accuracy: 0.9764 - val_loss: 0.4115 - val_accuracy: 0.8725 - 465ms/epoch - 10ms/step\n",
      "Epoch 12/20\n",
      "46/46 - 0s - loss: 0.0575 - accuracy: 0.9831 - val_loss: 0.4581 - val_accuracy: 0.8755 - 473ms/epoch - 10ms/step\n",
      "Epoch 13/20\n",
      "46/46 - 0s - loss: 0.0508 - accuracy: 0.9851 - val_loss: 0.6080 - val_accuracy: 0.8600 - 465ms/epoch - 10ms/step\n",
      "Epoch 14/20\n",
      "46/46 - 0s - loss: 0.0407 - accuracy: 0.9893 - val_loss: 0.4907 - val_accuracy: 0.8700 - 478ms/epoch - 10ms/step\n",
      "Epoch 15/20\n",
      "46/46 - 0s - loss: 0.0358 - accuracy: 0.9907 - val_loss: 0.7291 - val_accuracy: 0.8510 - 463ms/epoch - 10ms/step\n",
      "Epoch 16/20\n",
      "46/46 - 0s - loss: 0.0429 - accuracy: 0.9876 - val_loss: 0.5482 - val_accuracy: 0.8745 - 469ms/epoch - 10ms/step\n",
      "Epoch 17/20\n",
      "46/46 - 1s - loss: 0.0286 - accuracy: 0.9931 - val_loss: 0.5913 - val_accuracy: 0.8750 - 509ms/epoch - 11ms/step\n",
      "Epoch 18/20\n",
      "46/46 - 0s - loss: 0.0267 - accuracy: 0.9934 - val_loss: 0.6367 - val_accuracy: 0.8710 - 484ms/epoch - 11ms/step\n",
      "Epoch 19/20\n",
      "46/46 - 0s - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.6932 - val_accuracy: 0.8665 - 469ms/epoch - 10ms/step\n",
      "Epoch 20/20\n",
      "46/46 - 0s - loss: 0.0234 - accuracy: 0.9948 - val_loss: 0.6724 - val_accuracy: 0.8710 - 473ms/epoch - 10ms/step\n",
      "CPU times: user 24.8 s, sys: 4.15 s, total: 28.9 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
    "history = model.fit(X_train_1h[mask,:], y_train[mask],\n",
    "          batch_size=512, epochs=20,\n",
    "          verbose=2,\n",
    "          validation_data=(X_train_1h[ival,:], y_train[ival]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `history` object has a `metrics` attribute that records both the training and validation accuracy at each epoch. We'll wrangle it into long-format for plotting with Altair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-e0253786429647ecb757cb1663e72073\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e0253786429647ecb757cb1663e72073\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e0253786429647ecb757cb1663e72073\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0f14b0af5bf7891a19f022af906b818e\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"fold\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"epoch\"}, {\"type\": \"quantitative\", \"field\": \"accuracy\", \"format\": \",.2f\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"accuracy\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-0f14b0af5bf7891a19f022af906b818e\": [{\"epoch\": 1, \"loss\": 0.4848951995372772, \"accuracy\": 0.7867013216018677, \"fold\": \"training\"}, {\"epoch\": 2, \"loss\": 0.29044657945632935, \"accuracy\": 0.8960363864898682, \"fold\": \"training\"}, {\"epoch\": 3, \"loss\": 0.23076847195625305, \"accuracy\": 0.917305588722229, \"fold\": \"training\"}, {\"epoch\": 4, \"loss\": 0.18447108566761017, \"accuracy\": 0.9355858564376831, \"fold\": \"training\"}, {\"epoch\": 5, \"loss\": 0.16307680308818817, \"accuracy\": 0.9430366158485413, \"fold\": \"training\"}, {\"epoch\": 6, \"loss\": 0.1378049999475479, \"accuracy\": 0.9535195827484131, \"fold\": \"training\"}, {\"epoch\": 7, \"loss\": 0.12408917397260666, \"accuracy\": 0.9572449922561646, \"fold\": \"training\"}, {\"epoch\": 8, \"loss\": 0.10544993728399277, \"accuracy\": 0.9640459418296814, \"fold\": \"training\"}, {\"epoch\": 9, \"loss\": 0.09234718233346939, \"accuracy\": 0.9691141247749329, \"fold\": \"training\"}, {\"epoch\": 10, \"loss\": 0.07939594238996506, \"accuracy\": 0.9741823673248291, \"fold\": \"training\"}, {\"epoch\": 11, \"loss\": 0.07137364894151688, \"accuracy\": 0.976391613483429, \"fold\": \"training\"}, {\"epoch\": 12, \"loss\": 0.057459644973278046, \"accuracy\": 0.9831492304801941, \"fold\": \"training\"}, {\"epoch\": 13, \"loss\": 0.05080906301736832, \"accuracy\": 0.9850552082061768, \"fold\": \"training\"}, {\"epoch\": 14, \"loss\": 0.04069129750132561, \"accuracy\": 0.9892570972442627, \"fold\": \"training\"}, {\"epoch\": 15, \"loss\": 0.03580798953771591, \"accuracy\": 0.9907299280166626, \"fold\": \"training\"}, {\"epoch\": 16, \"loss\": 0.04289882257580757, \"accuracy\": 0.987567663192749, \"fold\": \"training\"}, {\"epoch\": 17, \"loss\": 0.028591733425855637, \"accuracy\": 0.9931123852729797, \"fold\": \"training\"}, {\"epoch\": 18, \"loss\": 0.02666834369301796, \"accuracy\": 0.9933723211288452, \"fold\": \"training\"}, {\"epoch\": 19, \"loss\": 0.02214832231402397, \"accuracy\": 0.9948884844779968, \"fold\": \"training\"}, {\"epoch\": 20, \"loss\": 0.02341160736978054, \"accuracy\": 0.9948018193244934, \"fold\": \"training\"}, {\"epoch\": 1, \"loss\": 0.34848225116729736, \"accuracy\": 0.8659999966621399, \"fold\": \"validation\"}, {\"epoch\": 2, \"loss\": 0.3153661787509918, \"accuracy\": 0.8820000290870667, \"fold\": \"validation\"}, {\"epoch\": 3, \"loss\": 0.2742522060871124, \"accuracy\": 0.8960000276565552, \"fold\": \"validation\"}, {\"epoch\": 4, \"loss\": 0.34109172224998474, \"accuracy\": 0.8769999742507935, \"fold\": \"validation\"}, {\"epoch\": 5, \"loss\": 0.3481748700141907, \"accuracy\": 0.8774999976158142, \"fold\": \"validation\"}, {\"epoch\": 6, \"loss\": 0.3105112910270691, \"accuracy\": 0.8855000138282776, \"fold\": \"validation\"}, {\"epoch\": 7, \"loss\": 0.41865622997283936, \"accuracy\": 0.8694999814033508, \"fold\": \"validation\"}, {\"epoch\": 8, \"loss\": 0.34381112456321716, \"accuracy\": 0.8824999928474426, \"fold\": \"validation\"}, {\"epoch\": 9, \"loss\": 0.37857797741889954, \"accuracy\": 0.8774999976158142, \"fold\": \"validation\"}, {\"epoch\": 10, \"loss\": 0.3913820683956146, \"accuracy\": 0.8759999871253967, \"fold\": \"validation\"}, {\"epoch\": 11, \"loss\": 0.4115362763404846, \"accuracy\": 0.8725000023841858, \"fold\": \"validation\"}, {\"epoch\": 12, \"loss\": 0.45809975266456604, \"accuracy\": 0.8755000233650208, \"fold\": \"validation\"}, {\"epoch\": 13, \"loss\": 0.6080499887466431, \"accuracy\": 0.8600000143051147, \"fold\": \"validation\"}, {\"epoch\": 14, \"loss\": 0.4906980097293854, \"accuracy\": 0.8700000047683716, \"fold\": \"validation\"}, {\"epoch\": 15, \"loss\": 0.7291172742843628, \"accuracy\": 0.8510000109672546, \"fold\": \"validation\"}, {\"epoch\": 16, \"loss\": 0.548196017742157, \"accuracy\": 0.8744999766349792, \"fold\": \"validation\"}, {\"epoch\": 17, \"loss\": 0.5913026332855225, \"accuracy\": 0.875, \"fold\": \"validation\"}, {\"epoch\": 18, \"loss\": 0.6366854310035706, \"accuracy\": 0.8709999918937683, \"fold\": \"validation\"}, {\"epoch\": 19, \"loss\": 0.6931976079940796, \"accuracy\": 0.8665000200271606, \"fold\": \"validation\"}, {\"epoch\": 20, \"loss\": 0.6724100112915039, \"accuracy\": 0.8709999918937683, \"fold\": \"validation\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = (\n",
    "    pd.DataFrame(history.history)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"epoch\"})\n",
    "    .assign(epoch=lambda df: df.epoch + 1)\n",
    ")\n",
    "df_mlp = pd.concat(\n",
    "    [\n",
    "        _.iloc[:, 0:3].assign(fold=\"training\"),\n",
    "        _.iloc[:, [0, -2, -1]]\n",
    "        .rename(columns={\"val_accuracy\": \"accuracy\", \"val_loss\": \"loss\"})\n",
    "        .assign(fold=\"validation\"),\n",
    "    ],\n",
    "    axis=0,\n",
    ").reset_index(drop=True)\n",
    "plot_mlp = (\n",
    "    alt.Chart(df_mlp)\n",
    "    .mark_line(point=True)\n",
    "    .encode(\n",
    "        x=\"epoch:Q\",\n",
    "        y=\"accuracy\",\n",
    "        color=\"fold\",\n",
    "        tooltip=[\"epoch\", alt.Tooltip(\"accuracy\", format=\",.2f\")],\n",
    "    )\n",
    ")\n",
    "plot_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To compute the test accuracy, we rerun the entire sequence above, replacing the last line with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "46/46 - 1s - loss: 0.0223 - accuracy: 0.9948 - val_loss: 0.7094 - val_accuracy: 0.8551 - 806ms/epoch - 18ms/step\n",
      "Epoch 2/20\n",
      "46/46 - 1s - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.7450 - val_accuracy: 0.8534 - 730ms/epoch - 16ms/step\n",
      "Epoch 3/20\n",
      "46/46 - 1s - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.7840 - val_accuracy: 0.8543 - 699ms/epoch - 15ms/step\n",
      "Epoch 4/20\n",
      "46/46 - 1s - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.8140 - val_accuracy: 0.8531 - 694ms/epoch - 15ms/step\n",
      "Epoch 5/20\n",
      "46/46 - 1s - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.8322 - val_accuracy: 0.8528 - 739ms/epoch - 16ms/step\n",
      "Epoch 6/20\n",
      "46/46 - 1s - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.8511 - val_accuracy: 0.8516 - 726ms/epoch - 16ms/step\n",
      "Epoch 7/20\n",
      "46/46 - 1s - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.9198 - val_accuracy: 0.8513 - 693ms/epoch - 15ms/step\n",
      "Epoch 8/20\n",
      "46/46 - 1s - loss: 0.0176 - accuracy: 0.9966 - val_loss: 0.9492 - val_accuracy: 0.8508 - 691ms/epoch - 15ms/step\n",
      "Epoch 9/20\n",
      "46/46 - 1s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 1.0007 - val_accuracy: 0.8497 - 689ms/epoch - 15ms/step\n",
      "Epoch 10/20\n",
      "46/46 - 1s - loss: 0.0104 - accuracy: 0.9971 - val_loss: 1.0171 - val_accuracy: 0.8485 - 694ms/epoch - 15ms/step\n",
      "Epoch 11/20\n",
      "46/46 - 1s - loss: 9.7650e-04 - accuracy: 1.0000 - val_loss: 1.0783 - val_accuracy: 0.8476 - 682ms/epoch - 15ms/step\n",
      "Epoch 12/20\n",
      "46/46 - 1s - loss: 0.0162 - accuracy: 0.9968 - val_loss: 1.0776 - val_accuracy: 0.8490 - 695ms/epoch - 15ms/step\n",
      "Epoch 13/20\n",
      "46/46 - 1s - loss: 6.2847e-04 - accuracy: 1.0000 - val_loss: 1.1371 - val_accuracy: 0.8470 - 688ms/epoch - 15ms/step\n",
      "Epoch 14/20\n",
      "46/46 - 1s - loss: 0.0158 - accuracy: 0.9965 - val_loss: 1.1458 - val_accuracy: 0.8478 - 741ms/epoch - 16ms/step\n",
      "Epoch 15/20\n",
      "46/46 - 1s - loss: 4.3286e-04 - accuracy: 1.0000 - val_loss: 1.1946 - val_accuracy: 0.8471 - 702ms/epoch - 15ms/step\n",
      "Epoch 16/20\n",
      "46/46 - 1s - loss: 0.0019 - accuracy: 0.9997 - val_loss: 1.2538 - val_accuracy: 0.8441 - 716ms/epoch - 16ms/step\n",
      "Epoch 17/20\n",
      "46/46 - 1s - loss: 3.5998e-04 - accuracy: 1.0000 - val_loss: 1.2791 - val_accuracy: 0.8461 - 735ms/epoch - 16ms/step\n",
      "Epoch 18/20\n",
      "46/46 - 1s - loss: 2.8227e-04 - accuracy: 1.0000 - val_loss: 1.3168 - val_accuracy: 0.8453 - 688ms/epoch - 15ms/step\n",
      "Epoch 19/20\n",
      "46/46 - 1s - loss: 0.0125 - accuracy: 0.9973 - val_loss: 1.3309 - val_accuracy: 0.8452 - 696ms/epoch - 15ms/step\n",
      "Epoch 20/20\n",
      "46/46 - 1s - loss: 1.6931e-04 - accuracy: 1.0000 - val_loss: 1.3688 - val_accuracy: 0.8457 - 686ms/epoch - 15ms/step\n"
     ]
    }
   ],
   "source": [
    "history_test = model.fit(X_train_1h[mask,:], y_train[mask],\n",
    "          batch_size=512, epochs=20,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test_1h, y_test))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e954c2bd-f002-4769-9beb-3d5e2ae14166",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nextjournal": {
   "nodes-edn": "{\"1bd5b5a5-b173-486f-afb2-cc6236d1bc25\" {:content \"fig = plt.figure()\\nfor i in range(9):\\n  plt.subplot(3,3,i+1)\\n  plt.tight_layout()\\n  plt.imshow(X_train[i], cmap='gray', interpolation='none')\\n  plt.title(\\\"Digit: {}\\\".format(y_train[i]))\\n  plt.xticks([])\\n  plt.yticks([])\\nfig\", :execution-hash 46961376, :name \"plot-examples\", :output-log-lines {}, :scope nil, :language \"python\", :id \"1bd5b5a5-b173-486f-afb2-cc6236d1bc25\", :compute-ref #uuid \"cd1adb58-2e89-4c29-b5de-e26e6052f992\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:6ffddb689c90d90e22d7f5b349122816\", :error nil, :exec-duration 1184, :criu-checkpoint \"6ffddb689c90d90e22d7f5b349122816\"}, \"c491dfcd-a313-4095-a993-38d39e1d17cc\" {:id \"c491dfcd-a313-4095-a993-38d39e1d17cc\", :kind \"signup\"}, \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\" {:content \"# training the model and saving metrics in history\\nhistory = model.fit(X_train, Y_train,\\n          batch_size=128, epochs=20,\\n          verbose=2,\\n          validation_data=(X_test, Y_test))\\n\\n# saving the model\\nsave_dir = \\\"/results/\\\"\\nmodel_name = 'keras_mnist.h5'\\nmodel_path = os.path.join(save_dir, model_name)\\nmodel.save(model_path)\\nprint('Saved trained model at %s ' % model_path)\\n\\n# plotting the metrics\\nfig = plt.figure()\\nplt.subplot(2,1,1)\\nplt.plot(history.history['acc'])\\nplt.plot(history.history['val_acc'])\\nplt.title('model accuracy')\\nplt.ylabel('accuracy')\\nplt.xlabel('epoch')\\nplt.legend(['train', 'test'], loc='lower right')\\n\\nplt.subplot(2,1,2)\\nplt.plot(history.history['loss'])\\nplt.plot(history.history['val_loss'])\\nplt.title('model loss')\\nplt.ylabel('loss')\\nplt.xlabel('epoch')\\nplt.legend(['train', 'test'], loc='upper right')\\n\\nplt.tight_layout()\\n\\nfig\", :execution-hash 121686107, :name \"train-model\", :output-log-lines {:stdout 43}, :scope nil, :language \"python\", :id \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\", :compute-ref #uuid \"11bbdca2-124e-4acb-8945-a4ea3486ccc8\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:40c6f986206ba36f39f6d4d9cc9d1b6c\", :error nil, :exec-duration 55633, :criu-checkpoint nil}, \"abbee50a-1c94-4887-bc63-cdcaa813c385\" {:content \"# building a linear stack of layers with the sequential model\\nmodel = Sequential()\\nmodel.add(Dense(512, input_shape=(784,)))\\nmodel.add(Activation('relu'))                            \\nmodel.add(Dropout(0.2))\\n\\nmodel.add(Dense(512))\\nmodel.add(Activation('relu'))\\nmodel.add(Dropout(0.2))\\n\\nmodel.add(Dense(10))\\nmodel.add(Activation('softmax'))\", :execution-hash 24093536, :name \"nn-setup\", :output-log-lines {}, :scope nil, :language \"python\", :id \"abbee50a-1c94-4887-bc63-cdcaa813c385\", :compute-ref #uuid \"bafcb581-ab42-4835-ab08-f84ce63f381a\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:df79881c640fa7d54f6204ee5966e7fe\", :error nil, :exec-duration 278, :criu-checkpoint \"df79881c640fa7d54f6204ee5966e7fe\"}, \"0faf4592-e228-41e5-b0df-084183540673\" {:content \"conda install -y -c anaconda \\\\\\n  tensorflow-gpu h5py cudatoolkit=8\\n  \\npip install keras\", :execution-hash 117855988, :name nil, :output-log-lines {:stdout 125}, :scope nil, :language \"bash\", :id \"0faf4592-e228-41e5-b0df-084183540673\", :compute-ref #uuid \"60fdac30-6b60-11e8-b7ce-8ab3fb67dad5\", :runtime [:runtime \"cf8e6214-03e3-4662-9f39-b40673a6c19c\"], :kind \"code\", :locked? false, :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:c52a73142e0ce65c2fea84a113deb3b6\", :error nil, :exec-duration 250893, :criu-checkpoint nil}, \"e120298c-9524-42ba-8332-f861a95db7fb\" {:id \"e120298c-9524-42ba-8332-f861a95db7fb\", :kind \"signup\"}, \"01002b11-4266-49b2-a07b-2e80165d2d1f\" {:content \"python -c 'from keras.datasets import mnist\\nmnist.load_data()'\", :output-log-lines {:stdout 130}, :language \"bash\", :id \"01002b11-4266-49b2-a07b-2e80165d2d1f\", :compute-ref #uuid \"f68ba720-6b60-11e8-b7ce-8ab3fb67dad5\", :runtime [:runtime \"cf8e6214-03e3-4662-9f39-b40673a6c19c\"], :kind \"code\", :error nil, :exec-duration 12565}, \"cf8e6214-03e3-4662-9f39-b40673a6c19c\" {:runtime/inherited-environment-variables ({:name \"PATH\", :value \"/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"} {:name \"MPLBACKEND\", :value \"svg\"} {:name \"LC_ALL\", :value \"en_US.UTF-8\"} {:name \"LANGUAGE\", :value \"en_US.en\"} {:name \"LANG\", :value \"en_US.UTF-8\"} {:name \"DEBIAN_FRONTEND\", :value \"noninteractive\"} {:name \"BASH_ENV\", :value \"/.bash_profile\"} {:name \"LD_LIBRARY_PATH\", :value \"/usr/local/nvidia/lib64/:/usr/local/cuda/lib64/\"}), :name \"Install\", :docker/environment-image \"eu.gcr.io/nextjournal-com/environment@sha256:b53e86c89d41a9e5dac4d01ede3c3152a29047a6544d3fed9169a8d3c497bfd4\", :type :nextjournal, :environment? true, :language \"bash\", :id \"cf8e6214-03e3-4662-9f39-b40673a6c19c\", :kind \"runtime\", :changed? false, :error nil, :environment [:environment {:node/id \"2d7db078-e0cf-483e-a118-89ddc1d4adab\", :article/nextjournal.id #uuid \"5accb601-b16a-4637-ae55-5fd73544a52f\", :change/nextjournal.id #uuid \"5b101a6e-8be7-4492-97da-65ef13c070a6\"}], :environment/name \"Install\", :diff \"\"}, \"03b8ac9b-d073-41c8-840b-7bc5475ef23d\" {:content \"# compiling the sequential model\\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\", :execution-hash 11359234, :name \"compile-model\", :output-log-lines {}, :scope nil, :language \"python\", :id \"03b8ac9b-d073-41c8-840b-7bc5475ef23d\", :compute-ref #uuid \"84c6272a-3205-47d3-8f20-30616ed60417\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:eb5a4df264a6f56d5c91a2cff39d2f4b\", :error nil, :exec-duration 258, :criu-checkpoint \"eb5a4df264a6f56d5c91a2cff39d2f4b\"}, \"e4c5b9d3-efa9-4e2a-9f39-6324378d9014\" {:content \"# one-hot encoding using keras' numpy-related utilities\\nn_classes = 10\\nprint(\\\"Shape before one-hot encoding: \\\", y_train.shape)\\nY_train = np_utils.to_categorical(y_train, n_classes)\\nY_test = np_utils.to_categorical(y_test, n_classes)\\nprint(\\\"Shape after one-hot encoding: \\\", Y_train.shape)\", :execution-hash 83412525, :name \"one-hot-encoding\", :output-log-lines {:stdout 3}, :scope nil, :language \"python\", :id \"e4c5b9d3-efa9-4e2a-9f39-6324378d9014\", :compute-ref #uuid \"eec373e3-f4c9-48ab-b1d7-a17e338ffb10\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:3638b6d5592ba387f913cbafc2a65a59\", :error nil, :exec-duration 322, :criu-checkpoint \"3638b6d5592ba387f913cbafc2a65a59\"}, \"60048064-31b8-4c49-9839-65f8c75d1baf\" {:content \"# let's print the shape before we reshape and normalize\\nprint(\\\"X_train shape\\\", X_train.shape)\\nprint(\\\"y_train shape\\\", y_train.shape)\\nprint(\\\"X_test shape\\\", X_test.shape)\\nprint(\\\"y_test shape\\\", y_test.shape)\\n\\n# building the input vector from the 28x28 pixels\\nX_train = X_train.reshape(60000, 784)\\nX_test = X_test.reshape(10000, 784)\\nX_train = X_train.astype('float32')\\nX_test = X_test.astype('float32')\\n\\n# normalizing the data to help with the training\\nX_train /= 255\\nX_test /= 255\\n\\n# print the final input shape ready for training\\nprint(\\\"Train matrix shape\\\", X_train.shape)\\nprint(\\\"Test matrix shape\\\", X_test.shape)\", :execution-hash 121062391, :name \"input-formatting\", :output-log-lines {:stdout 7}, :scope nil, :language \"python\", :id \"60048064-31b8-4c49-9839-65f8c75d1baf\", :compute-ref #uuid \"1cec6897-f39d-4b98-95ee-e2ba4611dc99\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:637fe341d6dfb96cc340f88038ff00f3\", :error nil, :exec-duration 345, :criu-checkpoint \"637fe341d6dfb96cc340f88038ff00f3\"}, \"7f917151-b364-4f7d-9ea7-5ed43dfdb925\" {:content \"mnist_model = load_model($$ref{{[\\\"~:output\\\",\\\"03ba7143-0469-4ab8-8850-a2a8fa3cb299\\\",\\\"keras_mnist.h5\\\"]}})\\nloss_and_metrics = mnist_model.evaluate(X_test, Y_test, verbose=2)\\n\\nprint(\\\"Test Loss\\\", loss_and_metrics[0])\\nprint(\\\"Test Accuracy\\\", loss_and_metrics[1])\", :execution-hash 78018430, :name \"evaluate\", :output-log-lines {:stdout 3}, :scope nil, :language \"python\", :id \"7f917151-b364-4f7d-9ea7-5ed43dfdb925\", :compute-ref #uuid \"a96c0fce-7a3e-4afa-9f2c-0379894056ac\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:0285ec86c76c748e096287b9eab23a65\", :error nil, :exec-duration 1998, :criu-checkpoint nil}, \"775267f3-e650-4a2c-88f0-f1bf548dc1bf\" {:content \"# imports for array-handling and plotting\\nimport numpy as np\\nimport matplotlib\\nmatplotlib.use('agg')\\nimport matplotlib.pyplot as plt\\n\\n# let's keep our keras backend tensorflow quiet\\nimport os\\nos.environ['TF_CPP_MIN_LOG_LEVEL']='3'\\n# for testing on CPU\\n#os.environ['CUDA_VISIBLE_DEVICES'] = ''\\n\\n# keras imports for the dataset and building our neural network\\nfrom keras.datasets import mnist\\nfrom keras.models import Sequential, load_model\\nfrom keras.layers.core import Dense, Dropout, Activation\\nfrom keras.utils import np_utils\", :execution-hash 51134437, :name \"imports\", :output-log-lines {:stdout 2}, :scope nil, :language \"python\", :id \"775267f3-e650-4a2c-88f0-f1bf548dc1bf\", :compute-ref #uuid \"bdbbdf3e-ce80-4c7b-9928-14e92f736a1b\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:17d09541a19f4f5064a8cedbf42a9d25\", :error nil, :exec-duration 1425, :criu-checkpoint \"17d09541a19f4f5064a8cedbf42a9d25\"}, \"21c96142-63bd-4195-a4bb-81c791175fcc\" {:content \"# load the model and create predictions on the test set\\nmnist_model = load_model($$ref{{[\\\"~:output\\\",\\\"03ba7143-0469-4ab8-8850-a2a8fa3cb299\\\",\\\"keras_mnist.h5\\\"]}})\\npredicted_classes = mnist_model.predict_classes(X_test)\\n\\n# see which we predicted correctly and which not\\ncorrect_indices = np.nonzero(predicted_classes == y_test)[0]\\nincorrect_indices = np.nonzero(predicted_classes != y_test)[0]\\nprint()\\nprint(len(correct_indices),\\\" classified correctly\\\")\\nprint(len(incorrect_indices),\\\" classified incorrectly\\\")\\n\\n# adapt figure size to accomodate 18 subplots\\nplt.rcParams['figure.figsize'] = (7,14)\\n\\nfigure_evaluation = plt.figure()\\n\\n# plot 9 correct predictions\\nfor i, correct in enumerate(correct_indices[:9]):\\n    plt.subplot(6,3,i+1)\\n    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\\n    plt.title(\\n      \\\"Predicted: {}, Truth: {}\\\".format(predicted_classes[correct],\\n                                        y_test[correct]))\\n    plt.xticks([])\\n    plt.yticks([])\\n\\n# plot 9 incorrect predictions\\nfor i, incorrect in enumerate(incorrect_indices[:9]):\\n    plt.subplot(6,3,i+10)\\n    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\\n    plt.title(\\n      \\\"Predicted {}, Truth: {}\\\".format(predicted_classes[incorrect], \\n                                       y_test[incorrect]))\\n    plt.xticks([])\\n    plt.yticks([])\\n\\nfigure_evaluation\", :execution-hash 112246374, :name \"evaluate-examples\", :output-log-lines {:stdout 4}, :scope nil, :language \"python\", :id \"21c96142-63bd-4195-a4bb-81c791175fcc\", :compute-ref #uuid \"5deec13f-9de4-41f9-8604-6555b50090b8\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:5858e1475f53af6f4fd00616de1b85fd\", :error nil, :exec-duration 2366, :criu-checkpoint nil}, \"941d6d2b-7fec-420f-bd09-ca79ce5a63f3\" {:content \"nvidia-smi\", :output-log-lines {:stdout 17}, :language \"bash\", :id \"941d6d2b-7fec-420f-bd09-ca79ce5a63f3\", :compute-ref #uuid \"9dce70cf-ec27-4c57-b18b-f4f4fe625f4a\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :error nil, :exec-duration 372}, \"6f3a733f-53eb-402d-86be-db838828a0b8\" {:runtime/inherited-environment-variables ({:name \"PATH\", :value \"/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"} {:name \"MPLBACKEND\", :value \"svg\"} {:name \"LC_ALL\", :value \"en_US.UTF-8\"} {:name \"LANGUAGE\", :value \"en_US.en\"} {:name \"LANG\", :value \"en_US.UTF-8\"} {:name \"DEBIAN_FRONTEND\", :value \"noninteractive\"} {:name \"BASH_ENV\", :value \"/.bash_profile\"} {:name \"LD_LIBRARY_PATH\", :value \"/usr/local/nvidia/lib64/:/usr/local/cuda/lib64/\"}), :name \"Main\", :output-log-lines nil, :type :nextjournal, :language \"python\", :id \"6f3a733f-53eb-402d-86be-db838828a0b8\", :compute-ref #uuid \"e2e60bf5-1e14-46af-b7ec-91fcdfcc3c97\", :kind \"runtime\", :error nil, :environment [:environment \"cf8e6214-03e3-4662-9f39-b40673a6c19c\"], :resources {:machine-type \"n1-standard-4\", :accelerator-type \"nvidia-tesla-k80\", :accelerator-count 1}}, \"a67d25ef-4ca3-438d-a558-331d91579e54\" {:content \"(X_train, y_train), (X_test, y_test) = mnist.load_data()\", :execution-hash 11114680, :name \"train-test-split\", :output-log-lines {}, :scope nil, :language \"python\", :id \"a67d25ef-4ca3-438d-a558-331d91579e54\", :compute-ref #uuid \"70b3132b-2982-44f8-ab7d-89bfce4f5a9a\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:b905b975133ee8dd76a019ab51b5f1ea\", :error nil, :exec-duration 472, :criu-checkpoint \"b905b975133ee8dd76a019ab51b5f1ea\"}, \"9ed29e16-0934-4ecd-a00c-2a2b69314a80\" {:content \"fig = plt.figure()\\nplt.subplot(2,1,1)\\nplt.imshow(X_train[0], cmap='gray', interpolation='none')\\nplt.title(\\\"Digit: {}\\\".format(y_train[0]))\\nplt.xticks([])\\nplt.yticks([])\\nplt.subplot(2,1,2)\\nplt.hist(X_train[0].reshape(784))\\nplt.title(\\\"Pixel Value Distribution\\\")\\nfig\", :execution-hash 109300958, :popover false, :name \"pixel-distribution\", :line-results \"None\\nAxes(0.125,0.53;0.775x0.35)\\nAxesImage(87.5,371;542.5x245)\\nText(0.5,1,u'Class 5')\\n([], <a list of 0 Text xtickla...\\n([], <a list of 0 Text ytickla...\\nAxes(0.125,0.11;0.775x0.35)\\n(array([ 639.,   11.,    6.,  ...\\nText(0.5,1,u'Pixel Value Distr...\\nFigure(700x700)\\n\", :active-requests [], :output-log-lines {}, :scope nil, :commands {}, :language \"python\", :id \"9ed29e16-0934-4ecd-a00c-2a2b69314a80\", :compute-ref #uuid \"3f78a8e8-c31a-46c1-980f-79f722a34716\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:b9c5102545883d7241b33a5ec01a6475\", :resolved-content \"\", :error nil, :exec-duration 661, :criu-checkpoint \"b9c5102545883d7241b33a5ec01a6475\", :stdout \"\"}, \"2851a44b-af0c-46ef-9e08-36877348901e\" {:content \"print(np.unique(y_train, return_counts=True))\", :execution-hash 118322401, :name \"y-value-counts\", :output-log-lines {:stdout 2}, :scope nil, :language \"python\", :id \"2851a44b-af0c-46ef-9e08-36877348901e\", :compute-ref #uuid \"acf64dbb-8270-4ca9-9d9c-dd12f9348d67\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:a6d4fe001c7557d8b098c03d7fa7a8a5\", :error nil, :exec-duration 353, :criu-checkpoint \"a6d4fe001c7557d8b098c03d7fa7a8a5\"}, \"7181e0a8-1b04-49fd-a703-eee3b044ddfa\" {:id \"7181e0a8-1b04-49fd-a703-eee3b044ddfa\", :kind \"reference\", :link [:output \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\" \"keras_mnist.h5\"]}, \"ac0a2d99-d702-480e-80ae-c9498cf04abe\" {:id \"ac0a2d99-d702-480e-80ae-c9498cf04abe\", :kind \"reference\", :link [:output \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\" \"keras_mnist.h5\"]}}",
   "runtime-id": "6f3a733f-53eb-402d-86be-db838828a0b8",
   "url": "https://nextjournal.com/gkoehler/digit-recognition-with-keras"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
