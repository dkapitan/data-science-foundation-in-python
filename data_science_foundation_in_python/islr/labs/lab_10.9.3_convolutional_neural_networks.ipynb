{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-c3d2649b-a67f-44be-a87d-e61b8abaa9d6",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 10.9.3: Convolutional Neural Networks\n",
    "\n",
    "## Attribution\n",
    "This notebook follows lab 10.9.3 from ISLRv2. The R-code has been ported to Python by Daniel Kapitan (08-01-2022).\n",
    "\n",
    "\n",
    "## Data preparation\n",
    "In this section we fit a CNN to the [CIFAR100 data](https://keras.io/api/datasets/cifar100/), which is available in the [Keras](https://keras.io) package. It is arranged in a similar fashion as the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00006-9cef16a3-6c4c-45de-bac9-98e8dcad8a7a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13744,
    "execution_start": 1641642487437,
    "nextjournal": {
     "id": "775267f3-e650-4a2c-88f0-f1bf548dc1bf",
     "kind": "code",
     "language": "python"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "3bd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix shape (50000, 32, 32, 3)\n",
      "Test matrix shape (10000, 32, 32, 3)\n",
      "Range of values train matrix: 0 ... 255\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# load the data\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "print(\"Train matrix shape\", X_train.shape)\n",
    "print(\"Test matrix shape\", X_test.shape)\n",
    "print(f\"Range of values train matrix: {X_train.min()} ... {X_train.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-eac006c5-bbe3-467c-8452-e22e6a77aac4",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The array of 50,000 training images has four dimesnions: each three-color image is represented as a set of three channels, each of which consists of $32 \\times 32$ eight-bit pixels. We standardize as we dit for the digits, but keep the array structure. We one-hot encode the response factors to produce a 100-column binary matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (50000, 1)\n",
      "Shape after one-hot encoding:  (50000, 100)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 100\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = to_categorical(y_train, n_classes)\n",
    "Y_test = to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before we start, we look at some of the training images. The file `cifar100_meta` contains the label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(f\"{labels['fine_label_names'][y_train[i][0]]}\")\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-96f7d338-65cd-4119-9125-d65050a1bb10",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the network\n",
    "\n",
    "Here we specify a moderately-sized CNN for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00020-a4001ec9-212a-4861-a332-a9b4ec57c15d",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     606.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1610,
    "execution_start": 1641642505414,
    "nextjournal": {
     "id": "abbee50a-1c94-4887-bc63-cdcaa813c385",
     "kind": "code",
     "language": "python"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "c6b1ee87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 964,516\n",
      "Trainable params: 964,516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape= (32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that we used the `padding = same` argument to `Conv2D()`, which ensures that the output channels have the same dimension as the input channels. There are 32 channels in the first hidden layer, in contrast to the three channels in the input layer. We use a $3 \\times 3$ convolution filter for each channel in all the layers. Each convolution is followed by a max-pooling layer over $2 \\times 2$ blocks. By studying the summary, we can see that the channels halve in both dimensions after each of the max-pooling operations. After the last of these we have a layer with 256 channels of dimension $2 \\times 2$. These are then flattened to a dense layer of size 1,024: in other words, each of the $2 \\times 2$ matrics is turned into a 4-vector, and put side-by-side in one layer. This is followed by a dropout regularization layer, then another dense layers of size 512, which finally reaches the softmax output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-aa38e9e5-a4b3-4650-afad-fb8191a4e012",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compiling and training the Model\n",
    "\n",
    "Finally, we specify the fitting algorithm, and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00023-012a7b48-930b-4e65-a60d-a66c4834e82e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 68,
    "execution_start": 1641642507036,
    "nextjournal": {
     "id": "03b8ac9b-d073-41c8-840b-7bc5475ef23d",
     "kind": "code",
     "language": "python"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "84568d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 4.1307 - accuracy: 0.0610 - val_loss: 3.7441 - val_accuracy: 0.1196\n",
      "Epoch 2/30\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 3.4793 - accuracy: 0.1650 - val_loss: 3.2364 - val_accuracy: 0.2169\n",
      "Epoch 3/30\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 3.1171 - accuracy: 0.2275 - val_loss: 3.0188 - val_accuracy: 0.2521\n",
      "Epoch 4/30\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 2.8494 - accuracy: 0.2817 - val_loss: 2.7353 - val_accuracy: 0.3050\n",
      "Epoch 5/30\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 2.6497 - accuracy: 0.3214 - val_loss: 2.6284 - val_accuracy: 0.3348\n",
      "Epoch 6/30\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 2.4713 - accuracy: 0.3557 - val_loss: 2.4881 - val_accuracy: 0.3620\n",
      "Epoch 7/30\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 2.3206 - accuracy: 0.3883 - val_loss: 2.4010 - val_accuracy: 0.3814\n",
      "Epoch 8/30\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 2.1844 - accuracy: 0.4150 - val_loss: 2.3158 - val_accuracy: 0.4022\n",
      "Epoch 9/30\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 2.0668 - accuracy: 0.4445 - val_loss: 2.3066 - val_accuracy: 0.4057\n",
      "Epoch 10/30\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 1.9617 - accuracy: 0.4652 - val_loss: 2.2419 - val_accuracy: 0.4229\n",
      "Epoch 11/30\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.8601 - accuracy: 0.4896 - val_loss: 2.2236 - val_accuracy: 0.4295\n",
      "Epoch 12/30\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.7683 - accuracy: 0.5102 - val_loss: 2.2144 - val_accuracy: 0.4325\n",
      "Epoch 13/30\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.6757 - accuracy: 0.5304 - val_loss: 2.1977 - val_accuracy: 0.4343\n",
      "Epoch 14/30\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.5943 - accuracy: 0.5497 - val_loss: 2.1885 - val_accuracy: 0.4421\n",
      "Epoch 15/30\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.5233 - accuracy: 0.5652 - val_loss: 2.2067 - val_accuracy: 0.4390\n",
      "Epoch 16/30\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.4562 - accuracy: 0.5817 - val_loss: 2.2007 - val_accuracy: 0.4414\n",
      "Epoch 17/30\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 1.3785 - accuracy: 0.5982 - val_loss: 2.2191 - val_accuracy: 0.4365\n",
      "Epoch 18/30\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.3202 - accuracy: 0.6142 - val_loss: 2.2120 - val_accuracy: 0.4504\n",
      "Epoch 19/30\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.2651 - accuracy: 0.6258 - val_loss: 2.2463 - val_accuracy: 0.4430\n",
      "Epoch 20/30\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.2096 - accuracy: 0.6450 - val_loss: 2.2703 - val_accuracy: 0.4475\n",
      "Epoch 21/30\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.1486 - accuracy: 0.6587 - val_loss: 2.2933 - val_accuracy: 0.4419\n",
      "Epoch 22/30\n",
      "313/313 [==============================] - 21s 69ms/step - loss: 1.1234 - accuracy: 0.6643 - val_loss: 2.3067 - val_accuracy: 0.4417\n",
      "Epoch 23/30\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.0704 - accuracy: 0.6761 - val_loss: 2.3614 - val_accuracy: 0.4503\n",
      "Epoch 24/30\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.0311 - accuracy: 0.6895 - val_loss: 2.3665 - val_accuracy: 0.4394\n",
      "Epoch 25/30\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.0013 - accuracy: 0.6975 - val_loss: 2.3657 - val_accuracy: 0.4483\n",
      "Epoch 26/30\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.9566 - accuracy: 0.7077 - val_loss: 2.3976 - val_accuracy: 0.4483\n",
      "Epoch 27/30\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.9309 - accuracy: 0.7140 - val_loss: 2.4040 - val_accuracy: 0.4428\n",
      "Epoch 28/30\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.8874 - accuracy: 0.7283 - val_loss: 2.4349 - val_accuracy: 0.4463\n",
      "Epoch 29/30\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.8727 - accuracy: 0.7287 - val_loss: 2.4372 - val_accuracy: 0.4440\n",
      "Epoch 30/30\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.8455 - accuracy: 0.7376 - val_loss: 2.4941 - val_accuracy: 0.4446\n",
      "Saved trained model at keras_cifar100.h5\n",
      "CPU times: user 1h 46min 4s, sys: 2min 51s, total: 1h 48min 55s\n",
      "Wall time: 10min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model and saving metrics in history\n",
    "history = model.fit(X_train, Y_train,\n",
    "          batch_size=128, epochs=30, validation_split=0.2)\n",
    "\n",
    "# save the model\n",
    "model_name = 'keras_cifar100.h5'\n",
    "model.save(model_name)\n",
    "print(f'Saved trained model at {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00021-b40bac60-cf33-4647-908d-be5eb3851b00",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     282,
     282
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1132,
    "execution_start": 1641642670118,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "cc300b5e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-363732c71d5c4e0283be21d4fd5b98b5\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-363732c71d5c4e0283be21d4fd5b98b5\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-363732c71d5c4e0283be21d4fd5b98b5\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"fold\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"epoch\"}, {\"type\": \"quantitative\", \"field\": \"loss\", \"format\": \",.2f\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}}, {\"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"fold\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"epoch\"}, {\"type\": \"quantitative\", \"field\": \"accuracy\", \"format\": \",.2f\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"accuracy\"}}}], \"data\": {\"name\": \"data-faea37cd230777d8c10fbae2922d3856\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-faea37cd230777d8c10fbae2922d3856\": [{\"epoch\": 1, \"loss\": 4.1307148933410645, \"accuracy\": 0.061000000685453415, \"fold\": \"training\"}, {\"epoch\": 2, \"loss\": 3.4793343544006348, \"accuracy\": 0.16504999995231628, \"fold\": \"training\"}, {\"epoch\": 3, \"loss\": 3.1170527935028076, \"accuracy\": 0.22754999995231628, \"fold\": \"training\"}, {\"epoch\": 4, \"loss\": 2.8494207859039307, \"accuracy\": 0.2816750109195709, \"fold\": \"training\"}, {\"epoch\": 5, \"loss\": 2.6497232913970947, \"accuracy\": 0.321399986743927, \"fold\": \"training\"}, {\"epoch\": 6, \"loss\": 2.4712986946105957, \"accuracy\": 0.3557249903678894, \"fold\": \"training\"}, {\"epoch\": 7, \"loss\": 2.320563316345215, \"accuracy\": 0.3883250057697296, \"fold\": \"training\"}, {\"epoch\": 8, \"loss\": 2.1843905448913574, \"accuracy\": 0.41495001316070557, \"fold\": \"training\"}, {\"epoch\": 9, \"loss\": 2.0668091773986816, \"accuracy\": 0.444474995136261, \"fold\": \"training\"}, {\"epoch\": 10, \"loss\": 1.9617271423339844, \"accuracy\": 0.4652250111103058, \"fold\": \"training\"}, {\"epoch\": 11, \"loss\": 1.8601402044296265, \"accuracy\": 0.48957499861717224, \"fold\": \"training\"}, {\"epoch\": 12, \"loss\": 1.7683037519454956, \"accuracy\": 0.5101500153541565, \"fold\": \"training\"}, {\"epoch\": 13, \"loss\": 1.6757193803787231, \"accuracy\": 0.5304250121116638, \"fold\": \"training\"}, {\"epoch\": 14, \"loss\": 1.5942999124526978, \"accuracy\": 0.5496500134468079, \"fold\": \"training\"}, {\"epoch\": 15, \"loss\": 1.523347020149231, \"accuracy\": 0.5652250051498413, \"fold\": \"training\"}, {\"epoch\": 16, \"loss\": 1.4561598300933838, \"accuracy\": 0.5816500186920166, \"fold\": \"training\"}, {\"epoch\": 17, \"loss\": 1.3785043954849243, \"accuracy\": 0.5982000231742859, \"fold\": \"training\"}, {\"epoch\": 18, \"loss\": 1.320160984992981, \"accuracy\": 0.614175021648407, \"fold\": \"training\"}, {\"epoch\": 19, \"loss\": 1.2650883197784424, \"accuracy\": 0.6257500052452087, \"fold\": \"training\"}, {\"epoch\": 20, \"loss\": 1.2095528841018677, \"accuracy\": 0.6449750065803528, \"fold\": \"training\"}, {\"epoch\": 21, \"loss\": 1.1486376523971558, \"accuracy\": 0.6587250232696533, \"fold\": \"training\"}, {\"epoch\": 22, \"loss\": 1.1234098672866821, \"accuracy\": 0.6643000245094299, \"fold\": \"training\"}, {\"epoch\": 23, \"loss\": 1.070427417755127, \"accuracy\": 0.6761249899864197, \"fold\": \"training\"}, {\"epoch\": 24, \"loss\": 1.0311206579208374, \"accuracy\": 0.6894500255584717, \"fold\": \"training\"}, {\"epoch\": 25, \"loss\": 1.0012807846069336, \"accuracy\": 0.697475016117096, \"fold\": \"training\"}, {\"epoch\": 26, \"loss\": 0.9566457867622375, \"accuracy\": 0.7077249884605408, \"fold\": \"training\"}, {\"epoch\": 27, \"loss\": 0.9309296607971191, \"accuracy\": 0.7140499949455261, \"fold\": \"training\"}, {\"epoch\": 28, \"loss\": 0.8873628973960876, \"accuracy\": 0.7282999753952026, \"fold\": \"training\"}, {\"epoch\": 29, \"loss\": 0.872673749923706, \"accuracy\": 0.728725016117096, \"fold\": \"training\"}, {\"epoch\": 30, \"loss\": 0.8454855680465698, \"accuracy\": 0.7375500202178955, \"fold\": \"training\"}, {\"epoch\": 1, \"loss\": 3.744094133377075, \"accuracy\": 0.11959999799728394, \"fold\": \"validation\"}, {\"epoch\": 2, \"loss\": 3.236351490020752, \"accuracy\": 0.21690000593662262, \"fold\": \"validation\"}, {\"epoch\": 3, \"loss\": 3.018782138824463, \"accuracy\": 0.25209999084472656, \"fold\": \"validation\"}, {\"epoch\": 4, \"loss\": 2.735325813293457, \"accuracy\": 0.3050000071525574, \"fold\": \"validation\"}, {\"epoch\": 5, \"loss\": 2.628425121307373, \"accuracy\": 0.33480000495910645, \"fold\": \"validation\"}, {\"epoch\": 6, \"loss\": 2.4880599975585938, \"accuracy\": 0.3619999885559082, \"fold\": \"validation\"}, {\"epoch\": 7, \"loss\": 2.4009907245635986, \"accuracy\": 0.3813999891281128, \"fold\": \"validation\"}, {\"epoch\": 8, \"loss\": 2.3158366680145264, \"accuracy\": 0.40220001339912415, \"fold\": \"validation\"}, {\"epoch\": 9, \"loss\": 2.306555986404419, \"accuracy\": 0.4056999981403351, \"fold\": \"validation\"}, {\"epoch\": 10, \"loss\": 2.241865634918213, \"accuracy\": 0.42289999127388, \"fold\": \"validation\"}, {\"epoch\": 11, \"loss\": 2.223642110824585, \"accuracy\": 0.429500013589859, \"fold\": \"validation\"}, {\"epoch\": 12, \"loss\": 2.214426279067993, \"accuracy\": 0.4325000047683716, \"fold\": \"validation\"}, {\"epoch\": 13, \"loss\": 2.1977365016937256, \"accuracy\": 0.4343000054359436, \"fold\": \"validation\"}, {\"epoch\": 14, \"loss\": 2.1884708404541016, \"accuracy\": 0.44209998846054077, \"fold\": \"validation\"}, {\"epoch\": 15, \"loss\": 2.2066986560821533, \"accuracy\": 0.4390000104904175, \"fold\": \"validation\"}, {\"epoch\": 16, \"loss\": 2.200692892074585, \"accuracy\": 0.4413999915122986, \"fold\": \"validation\"}, {\"epoch\": 17, \"loss\": 2.219095230102539, \"accuracy\": 0.43650001287460327, \"fold\": \"validation\"}, {\"epoch\": 18, \"loss\": 2.211961030960083, \"accuracy\": 0.4503999948501587, \"fold\": \"validation\"}, {\"epoch\": 19, \"loss\": 2.2462642192840576, \"accuracy\": 0.4429999887943268, \"fold\": \"validation\"}, {\"epoch\": 20, \"loss\": 2.2703185081481934, \"accuracy\": 0.44749999046325684, \"fold\": \"validation\"}, {\"epoch\": 21, \"loss\": 2.2933261394500732, \"accuracy\": 0.44190001487731934, \"fold\": \"validation\"}, {\"epoch\": 22, \"loss\": 2.306680917739868, \"accuracy\": 0.4417000114917755, \"fold\": \"validation\"}, {\"epoch\": 23, \"loss\": 2.3614492416381836, \"accuracy\": 0.450300008058548, \"fold\": \"validation\"}, {\"epoch\": 24, \"loss\": 2.366464853286743, \"accuracy\": 0.43939998745918274, \"fold\": \"validation\"}, {\"epoch\": 25, \"loss\": 2.3656980991363525, \"accuracy\": 0.44830000400543213, \"fold\": \"validation\"}, {\"epoch\": 26, \"loss\": 2.3975698947906494, \"accuracy\": 0.44830000400543213, \"fold\": \"validation\"}, {\"epoch\": 27, \"loss\": 2.4040303230285645, \"accuracy\": 0.44279998540878296, \"fold\": \"validation\"}, {\"epoch\": 28, \"loss\": 2.434857130050659, \"accuracy\": 0.4462999999523163, \"fold\": \"validation\"}, {\"epoch\": 29, \"loss\": 2.4371566772460938, \"accuracy\": 0.4440000057220459, \"fold\": \"validation\"}, {\"epoch\": 30, \"loss\": 2.494108200073242, \"accuracy\": 0.444599986076355, \"fold\": \"validation\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting the metrics\n",
    "_ = (\n",
    "    pd.DataFrame(history.history)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"epoch\"})\n",
    "    .assign(epoch=lambda df: df.epoch + 1)\n",
    ")\n",
    "df = pd.concat(\n",
    "    [\n",
    "        _.iloc[:, 0:3].assign(fold=\"training\"),\n",
    "        _.iloc[:, [0, -2, -1]]\n",
    "        .rename(columns={\"val_accuracy\": \"accuracy\", \"val_loss\": \"loss\"})\n",
    "        .assign(fold=\"validation\"),\n",
    "    ],\n",
    "    axis=0,\n",
    ").reset_index(drop=True)\n",
    "base = alt.Chart(df).mark_line(point=True)\n",
    "loss = base.encode(x=\"epoch:Q\", y=\"loss\", color=\"fold\", tooltip=[\"epoch\", alt.Tooltip(\"loss\", format=\",.2f\")])\n",
    "accuracy = base.encode(x=\"epoch:Q\", y=\"accuracy\", color=\"fold\", tooltip=[\"epoch\", alt.Tooltip(\"accuracy\", format=\",.2f\")] )\n",
    "loss | accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-61210eb1-2882-4635-a1c4-c25c7f4ca537",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This model takes 10 minutes to run and achieves 46% accuracy on the test data. Although this is not terrible for 100-class data (a random classifier gets 1% accuracy), searching the web we see results around 75%. Typically, it takes a lot of architecture carpentry, fiddling with regularization, and time to achieve such results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "00027-5578222d-5c77-43b2-837f-bb39960892eb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1395,
    "execution_start": 1641642671254,
    "nextjournal": {
     "id": "7f917151-b364-4f7d-9ea7-5ed43dfdb925",
     "kind": "code",
     "language": "python"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "446c3a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 2.4390 - accuracy: 0.4524 - 2s/epoch - 6ms/step\n",
      "Test Loss: 2.439\n",
      "Test Accuracy: 0.452\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(f\"Test Loss: {loss_and_metrics[0]:.3f}\")\n",
    "print(f\"Test Accuracy: {loss_and_metrics[1]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e954c2bd-f002-4769-9beb-3d5e2ae14166",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nextjournal": {
   "nodes-edn": "{\"1bd5b5a5-b173-486f-afb2-cc6236d1bc25\" {:content \"fig = plt.figure()\\nfor i in range(9):\\n  plt.subplot(3,3,i+1)\\n  plt.tight_layout()\\n  plt.imshow(X_train[i], cmap='gray', interpolation='none')\\n  plt.title(\\\"Digit: {}\\\".format(y_train[i]))\\n  plt.xticks([])\\n  plt.yticks([])\\nfig\", :execution-hash 46961376, :name \"plot-examples\", :output-log-lines {}, :scope nil, :language \"python\", :id \"1bd5b5a5-b173-486f-afb2-cc6236d1bc25\", :compute-ref #uuid \"cd1adb58-2e89-4c29-b5de-e26e6052f992\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:6ffddb689c90d90e22d7f5b349122816\", :error nil, :exec-duration 1184, :criu-checkpoint \"6ffddb689c90d90e22d7f5b349122816\"}, \"c491dfcd-a313-4095-a993-38d39e1d17cc\" {:id \"c491dfcd-a313-4095-a993-38d39e1d17cc\", :kind \"signup\"}, \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\" {:content \"# training the model and saving metrics in history\\nhistory = model.fit(X_train, Y_train,\\n          batch_size=128, epochs=20,\\n          verbose=2,\\n          validation_data=(X_test, Y_test))\\n\\n# saving the model\\nsave_dir = \\\"/results/\\\"\\nmodel_name = 'keras_mnist.h5'\\nmodel_path = os.path.join(save_dir, model_name)\\nmodel.save(model_path)\\nprint('Saved trained model at %s ' % model_path)\\n\\n# plotting the metrics\\nfig = plt.figure()\\nplt.subplot(2,1,1)\\nplt.plot(history.history['acc'])\\nplt.plot(history.history['val_acc'])\\nplt.title('model accuracy')\\nplt.ylabel('accuracy')\\nplt.xlabel('epoch')\\nplt.legend(['train', 'test'], loc='lower right')\\n\\nplt.subplot(2,1,2)\\nplt.plot(history.history['loss'])\\nplt.plot(history.history['val_loss'])\\nplt.title('model loss')\\nplt.ylabel('loss')\\nplt.xlabel('epoch')\\nplt.legend(['train', 'test'], loc='upper right')\\n\\nplt.tight_layout()\\n\\nfig\", :execution-hash 121686107, :name \"train-model\", :output-log-lines {:stdout 43}, :scope nil, :language \"python\", :id \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\", :compute-ref #uuid \"11bbdca2-124e-4acb-8945-a4ea3486ccc8\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:40c6f986206ba36f39f6d4d9cc9d1b6c\", :error nil, :exec-duration 55633, :criu-checkpoint nil}, \"abbee50a-1c94-4887-bc63-cdcaa813c385\" {:content \"# building a linear stack of layers with the sequential model\\nmodel = Sequential()\\nmodel.add(Dense(512, input_shape=(784,)))\\nmodel.add(Activation('relu'))                            \\nmodel.add(Dropout(0.2))\\n\\nmodel.add(Dense(512))\\nmodel.add(Activation('relu'))\\nmodel.add(Dropout(0.2))\\n\\nmodel.add(Dense(10))\\nmodel.add(Activation('softmax'))\", :execution-hash 24093536, :name \"nn-setup\", :output-log-lines {}, :scope nil, :language \"python\", :id \"abbee50a-1c94-4887-bc63-cdcaa813c385\", :compute-ref #uuid \"bafcb581-ab42-4835-ab08-f84ce63f381a\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:df79881c640fa7d54f6204ee5966e7fe\", :error nil, :exec-duration 278, :criu-checkpoint \"df79881c640fa7d54f6204ee5966e7fe\"}, \"0faf4592-e228-41e5-b0df-084183540673\" {:content \"conda install -y -c anaconda \\\\\\n  tensorflow-gpu h5py cudatoolkit=8\\n  \\npip install keras\", :execution-hash 117855988, :name nil, :output-log-lines {:stdout 125}, :scope nil, :language \"bash\", :id \"0faf4592-e228-41e5-b0df-084183540673\", :compute-ref #uuid \"60fdac30-6b60-11e8-b7ce-8ab3fb67dad5\", :runtime [:runtime \"cf8e6214-03e3-4662-9f39-b40673a6c19c\"], :kind \"code\", :locked? false, :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:c52a73142e0ce65c2fea84a113deb3b6\", :error nil, :exec-duration 250893, :criu-checkpoint nil}, \"e120298c-9524-42ba-8332-f861a95db7fb\" {:id \"e120298c-9524-42ba-8332-f861a95db7fb\", :kind \"signup\"}, \"01002b11-4266-49b2-a07b-2e80165d2d1f\" {:content \"python -c 'from keras.datasets import mnist\\nmnist.load_data()'\", :output-log-lines {:stdout 130}, :language \"bash\", :id \"01002b11-4266-49b2-a07b-2e80165d2d1f\", :compute-ref #uuid \"f68ba720-6b60-11e8-b7ce-8ab3fb67dad5\", :runtime [:runtime \"cf8e6214-03e3-4662-9f39-b40673a6c19c\"], :kind \"code\", :error nil, :exec-duration 12565}, \"cf8e6214-03e3-4662-9f39-b40673a6c19c\" {:runtime/inherited-environment-variables ({:name \"PATH\", :value \"/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"} {:name \"MPLBACKEND\", :value \"svg\"} {:name \"LC_ALL\", :value \"en_US.UTF-8\"} {:name \"LANGUAGE\", :value \"en_US.en\"} {:name \"LANG\", :value \"en_US.UTF-8\"} {:name \"DEBIAN_FRONTEND\", :value \"noninteractive\"} {:name \"BASH_ENV\", :value \"/.bash_profile\"} {:name \"LD_LIBRARY_PATH\", :value \"/usr/local/nvidia/lib64/:/usr/local/cuda/lib64/\"}), :name \"Install\", :docker/environment-image \"eu.gcr.io/nextjournal-com/environment@sha256:b53e86c89d41a9e5dac4d01ede3c3152a29047a6544d3fed9169a8d3c497bfd4\", :type :nextjournal, :environment? true, :language \"bash\", :id \"cf8e6214-03e3-4662-9f39-b40673a6c19c\", :kind \"runtime\", :changed? false, :error nil, :environment [:environment {:node/id \"2d7db078-e0cf-483e-a118-89ddc1d4adab\", :article/nextjournal.id #uuid \"5accb601-b16a-4637-ae55-5fd73544a52f\", :change/nextjournal.id #uuid \"5b101a6e-8be7-4492-97da-65ef13c070a6\"}], :environment/name \"Install\", :diff \"\"}, \"03b8ac9b-d073-41c8-840b-7bc5475ef23d\" {:content \"# compiling the sequential model\\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\", :execution-hash 11359234, :name \"compile-model\", :output-log-lines {}, :scope nil, :language \"python\", :id \"03b8ac9b-d073-41c8-840b-7bc5475ef23d\", :compute-ref #uuid \"84c6272a-3205-47d3-8f20-30616ed60417\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:eb5a4df264a6f56d5c91a2cff39d2f4b\", :error nil, :exec-duration 258, :criu-checkpoint \"eb5a4df264a6f56d5c91a2cff39d2f4b\"}, \"e4c5b9d3-efa9-4e2a-9f39-6324378d9014\" {:content \"# one-hot encoding using keras' numpy-related utilities\\nn_classes = 10\\nprint(\\\"Shape before one-hot encoding: \\\", y_train.shape)\\nY_train = np_utils.to_categorical(y_train, n_classes)\\nY_test = np_utils.to_categorical(y_test, n_classes)\\nprint(\\\"Shape after one-hot encoding: \\\", Y_train.shape)\", :execution-hash 83412525, :name \"one-hot-encoding\", :output-log-lines {:stdout 3}, :scope nil, :language \"python\", :id \"e4c5b9d3-efa9-4e2a-9f39-6324378d9014\", :compute-ref #uuid \"eec373e3-f4c9-48ab-b1d7-a17e338ffb10\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:3638b6d5592ba387f913cbafc2a65a59\", :error nil, :exec-duration 322, :criu-checkpoint \"3638b6d5592ba387f913cbafc2a65a59\"}, \"60048064-31b8-4c49-9839-65f8c75d1baf\" {:content \"# let's print the shape before we reshape and normalize\\nprint(\\\"X_train shape\\\", X_train.shape)\\nprint(\\\"y_train shape\\\", y_train.shape)\\nprint(\\\"X_test shape\\\", X_test.shape)\\nprint(\\\"y_test shape\\\", y_test.shape)\\n\\n# building the input vector from the 28x28 pixels\\nX_train = X_train.reshape(60000, 784)\\nX_test = X_test.reshape(10000, 784)\\nX_train = X_train.astype('float32')\\nX_test = X_test.astype('float32')\\n\\n# normalizing the data to help with the training\\nX_train /= 255\\nX_test /= 255\\n\\n# print the final input shape ready for training\\nprint(\\\"Train matrix shape\\\", X_train.shape)\\nprint(\\\"Test matrix shape\\\", X_test.shape)\", :execution-hash 121062391, :name \"input-formatting\", :output-log-lines {:stdout 7}, :scope nil, :language \"python\", :id \"60048064-31b8-4c49-9839-65f8c75d1baf\", :compute-ref #uuid \"1cec6897-f39d-4b98-95ee-e2ba4611dc99\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:637fe341d6dfb96cc340f88038ff00f3\", :error nil, :exec-duration 345, :criu-checkpoint \"637fe341d6dfb96cc340f88038ff00f3\"}, \"7f917151-b364-4f7d-9ea7-5ed43dfdb925\" {:content \"mnist_model = load_model($$ref{{[\\\"~:output\\\",\\\"03ba7143-0469-4ab8-8850-a2a8fa3cb299\\\",\\\"keras_mnist.h5\\\"]}})\\nloss_and_metrics = mnist_model.evaluate(X_test, Y_test, verbose=2)\\n\\nprint(\\\"Test Loss\\\", loss_and_metrics[0])\\nprint(\\\"Test Accuracy\\\", loss_and_metrics[1])\", :execution-hash 78018430, :name \"evaluate\", :output-log-lines {:stdout 3}, :scope nil, :language \"python\", :id \"7f917151-b364-4f7d-9ea7-5ed43dfdb925\", :compute-ref #uuid \"a96c0fce-7a3e-4afa-9f2c-0379894056ac\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:0285ec86c76c748e096287b9eab23a65\", :error nil, :exec-duration 1998, :criu-checkpoint nil}, \"775267f3-e650-4a2c-88f0-f1bf548dc1bf\" {:content \"# imports for array-handling and plotting\\nimport numpy as np\\nimport matplotlib\\nmatplotlib.use('agg')\\nimport matplotlib.pyplot as plt\\n\\n# let's keep our keras backend tensorflow quiet\\nimport os\\nos.environ['TF_CPP_MIN_LOG_LEVEL']='3'\\n# for testing on CPU\\n#os.environ['CUDA_VISIBLE_DEVICES'] = ''\\n\\n# keras imports for the dataset and building our neural network\\nfrom keras.datasets import mnist\\nfrom keras.models import Sequential, load_model\\nfrom keras.layers.core import Dense, Dropout, Activation\\nfrom keras.utils import np_utils\", :execution-hash 51134437, :name \"imports\", :output-log-lines {:stdout 2}, :scope nil, :language \"python\", :id \"775267f3-e650-4a2c-88f0-f1bf548dc1bf\", :compute-ref #uuid \"bdbbdf3e-ce80-4c7b-9928-14e92f736a1b\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:17d09541a19f4f5064a8cedbf42a9d25\", :error nil, :exec-duration 1425, :criu-checkpoint \"17d09541a19f4f5064a8cedbf42a9d25\"}, \"21c96142-63bd-4195-a4bb-81c791175fcc\" {:content \"# load the model and create predictions on the test set\\nmnist_model = load_model($$ref{{[\\\"~:output\\\",\\\"03ba7143-0469-4ab8-8850-a2a8fa3cb299\\\",\\\"keras_mnist.h5\\\"]}})\\npredicted_classes = mnist_model.predict_classes(X_test)\\n\\n# see which we predicted correctly and which not\\ncorrect_indices = np.nonzero(predicted_classes == y_test)[0]\\nincorrect_indices = np.nonzero(predicted_classes != y_test)[0]\\nprint()\\nprint(len(correct_indices),\\\" classified correctly\\\")\\nprint(len(incorrect_indices),\\\" classified incorrectly\\\")\\n\\n# adapt figure size to accomodate 18 subplots\\nplt.rcParams['figure.figsize'] = (7,14)\\n\\nfigure_evaluation = plt.figure()\\n\\n# plot 9 correct predictions\\nfor i, correct in enumerate(correct_indices[:9]):\\n    plt.subplot(6,3,i+1)\\n    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\\n    plt.title(\\n      \\\"Predicted: {}, Truth: {}\\\".format(predicted_classes[correct],\\n                                        y_test[correct]))\\n    plt.xticks([])\\n    plt.yticks([])\\n\\n# plot 9 incorrect predictions\\nfor i, incorrect in enumerate(incorrect_indices[:9]):\\n    plt.subplot(6,3,i+10)\\n    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\\n    plt.title(\\n      \\\"Predicted {}, Truth: {}\\\".format(predicted_classes[incorrect], \\n                                       y_test[incorrect]))\\n    plt.xticks([])\\n    plt.yticks([])\\n\\nfigure_evaluation\", :execution-hash 112246374, :name \"evaluate-examples\", :output-log-lines {:stdout 4}, :scope nil, :language \"python\", :id \"21c96142-63bd-4195-a4bb-81c791175fcc\", :compute-ref #uuid \"5deec13f-9de4-41f9-8604-6555b50090b8\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:5858e1475f53af6f4fd00616de1b85fd\", :error nil, :exec-duration 2366, :criu-checkpoint nil}, \"941d6d2b-7fec-420f-bd09-ca79ce5a63f3\" {:content \"nvidia-smi\", :output-log-lines {:stdout 17}, :language \"bash\", :id \"941d6d2b-7fec-420f-bd09-ca79ce5a63f3\", :compute-ref #uuid \"9dce70cf-ec27-4c57-b18b-f4f4fe625f4a\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :error nil, :exec-duration 372}, \"6f3a733f-53eb-402d-86be-db838828a0b8\" {:runtime/inherited-environment-variables ({:name \"PATH\", :value \"/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"} {:name \"MPLBACKEND\", :value \"svg\"} {:name \"LC_ALL\", :value \"en_US.UTF-8\"} {:name \"LANGUAGE\", :value \"en_US.en\"} {:name \"LANG\", :value \"en_US.UTF-8\"} {:name \"DEBIAN_FRONTEND\", :value \"noninteractive\"} {:name \"BASH_ENV\", :value \"/.bash_profile\"} {:name \"LD_LIBRARY_PATH\", :value \"/usr/local/nvidia/lib64/:/usr/local/cuda/lib64/\"}), :name \"Main\", :output-log-lines nil, :type :nextjournal, :language \"python\", :id \"6f3a733f-53eb-402d-86be-db838828a0b8\", :compute-ref #uuid \"e2e60bf5-1e14-46af-b7ec-91fcdfcc3c97\", :kind \"runtime\", :error nil, :environment [:environment \"cf8e6214-03e3-4662-9f39-b40673a6c19c\"], :resources {:machine-type \"n1-standard-4\", :accelerator-type \"nvidia-tesla-k80\", :accelerator-count 1}}, \"a67d25ef-4ca3-438d-a558-331d91579e54\" {:content \"(X_train, y_train), (X_test, y_test) = mnist.load_data()\", :execution-hash 11114680, :name \"train-test-split\", :output-log-lines {}, :scope nil, :language \"python\", :id \"a67d25ef-4ca3-438d-a558-331d91579e54\", :compute-ref #uuid \"70b3132b-2982-44f8-ab7d-89bfce4f5a9a\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:b905b975133ee8dd76a019ab51b5f1ea\", :error nil, :exec-duration 472, :criu-checkpoint \"b905b975133ee8dd76a019ab51b5f1ea\"}, \"9ed29e16-0934-4ecd-a00c-2a2b69314a80\" {:content \"fig = plt.figure()\\nplt.subplot(2,1,1)\\nplt.imshow(X_train[0], cmap='gray', interpolation='none')\\nplt.title(\\\"Digit: {}\\\".format(y_train[0]))\\nplt.xticks([])\\nplt.yticks([])\\nplt.subplot(2,1,2)\\nplt.hist(X_train[0].reshape(784))\\nplt.title(\\\"Pixel Value Distribution\\\")\\nfig\", :execution-hash 109300958, :popover false, :name \"pixel-distribution\", :line-results \"None\\nAxes(0.125,0.53;0.775x0.35)\\nAxesImage(87.5,371;542.5x245)\\nText(0.5,1,u'Class 5')\\n([], <a list of 0 Text xtickla...\\n([], <a list of 0 Text ytickla...\\nAxes(0.125,0.11;0.775x0.35)\\n(array([ 639.,   11.,    6.,  ...\\nText(0.5,1,u'Pixel Value Distr...\\nFigure(700x700)\\n\", :active-requests [], :output-log-lines {}, :scope nil, :commands {}, :language \"python\", :id \"9ed29e16-0934-4ecd-a00c-2a2b69314a80\", :compute-ref #uuid \"3f78a8e8-c31a-46c1-980f-79f722a34716\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:b9c5102545883d7241b33a5ec01a6475\", :resolved-content \"\", :error nil, :exec-duration 661, :criu-checkpoint \"b9c5102545883d7241b33a5ec01a6475\", :stdout \"\"}, \"2851a44b-af0c-46ef-9e08-36877348901e\" {:content \"print(np.unique(y_train, return_counts=True))\", :execution-hash 118322401, :name \"y-value-counts\", :output-log-lines {:stdout 2}, :scope nil, :language \"python\", :id \"2851a44b-af0c-46ef-9e08-36877348901e\", :compute-ref #uuid \"acf64dbb-8270-4ca9-9d9c-dd12f9348d67\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:a6d4fe001c7557d8b098c03d7fa7a8a5\", :error nil, :exec-duration 353, :criu-checkpoint \"a6d4fe001c7557d8b098c03d7fa7a8a5\"}, \"7181e0a8-1b04-49fd-a703-eee3b044ddfa\" {:id \"7181e0a8-1b04-49fd-a703-eee3b044ddfa\", :kind \"reference\", :link [:output \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\" \"keras_mnist.h5\"]}, \"ac0a2d99-d702-480e-80ae-c9498cf04abe\" {:id \"ac0a2d99-d702-480e-80ae-c9498cf04abe\", :kind \"reference\", :link [:output \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\" \"keras_mnist.h5\"]}}",
   "runtime-id": "6f3a733f-53eb-402d-86be-db838828a0b8",
   "url": "https://nextjournal.com/gkoehler/digit-recognition-with-keras"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
