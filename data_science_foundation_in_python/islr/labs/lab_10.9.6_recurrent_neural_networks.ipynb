{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-c3d2649b-a67f-44be-a87d-e61b8abaa9d6",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 10.9.6: Recurrent Neural Networks\n",
    "\n",
    "## Attribution\n",
    "This notebook follows lab 10.9.6 from ISLRv2. The R-code has been ported to Python by Daniel Kapitan (30-01-2022). In this lab we fit the models illustrated in Section 10.5.\n",
    "\n",
    "\n",
    "## Sequential Models for Document Classification\n",
    "Here we fit a simple LSTM RNN for sentiment analys with the `IMBd` move-review data, as discussed in section 10.5.1. We shoed hot to input the dat in Lab 10.9.5. We reproduce a shorter version of the code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "00006-9cef16a3-6c4c-45de-bac9-98e8dcad8a7a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13744,
    "execution_start": 1641642487437,
    "nextjournal": {
     "id": "775267f3-e650-4a2c-88f0-f1bf548dc1bf",
     "kind": "code",
     "language": "python"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "3bd01"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.sparse import SparseTensor, reorder\n",
    "\n",
    "\n",
    "# let's keep our keras backend tensorflow quiet\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# load the data\n",
    "MAX_FEATURES = 10_000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We first calculate the lenths of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median word-length of reviews: 178.0\n",
      "fraction of reviews that is 500 words or less: 0.91568\n"
     ]
    }
   ],
   "source": [
    "wc = [len(review) for review in X_train]\n",
    "print(f\"median word-length of reviews: {np.median(wc)}\")\n",
    "print(f\"fraction of reviews that is 500 words or less: {len([r for r in wc if r <= 500]) / len(wc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We see that over 91% of the documents have fewer than 500 words. Our RNN requires all the document sequences to have the same length. We hence restrict the document lengths to the last $L = 500$ words and padd the beginning of the shorter ones with blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X_train: (25000, 500)\n",
      "Dimension of X_train: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 500\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "for X in [X_train, X_test]:\n",
    "    print(f\"Dimension of X_train: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4472,  113,  103,   32,   15,   16, 5345,   19,  178,   32],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0, 490:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The last expression shows the last few words in the first document. t this stage, each of the 500 words in the document is represented using an integer corresponding to the location of that word in the 10,000-word dictionary. The first layer of the RNN is an embedding layer of size 32, which will be learned during training. This layer one-hot encodes each document as a matrix of dimension 500 $\\times$ 10,000, and then maps these 10,000 dimensions down to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          320000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,353\n",
      "Trainable params: 328,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 16:34:39.117161: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-30 16:34:39.117240: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-30 16:34:39.117257: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (xps): /proc/driver/nvidia/version does not exist\n",
      "2022-01-30 16:34:39.117512: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10_000, output_dim=32))\n",
    "model.add(LSTM(units=32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The second layer is an LSTM with 32 units, and the output layer is a single sigmoid for the binary classification task.\n",
    "\n",
    "The rest is now similar to other networks we have fit. We track the test performance as the network is fit, and see that it attains 87% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 75s 376ms/step - loss: 0.4817 - accuracy: 0.7746 - val_loss: 0.3218 - val_accuracy: 0.8680\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 73s 375ms/step - loss: 0.2845 - accuracy: 0.8916 - val_loss: 0.2826 - val_accuracy: 0.8819\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 73s 374ms/step - loss: 0.2299 - accuracy: 0.9127 - val_loss: 0.3234 - val_accuracy: 0.8606\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 73s 373ms/step - loss: 0.2025 - accuracy: 0.9249 - val_loss: 0.3534 - val_accuracy: 0.8583\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 73s 373ms/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.3239 - val_accuracy: 0.8593\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 73s 372ms/step - loss: 0.1629 - accuracy: 0.9416 - val_loss: 0.3592 - val_accuracy: 0.8580\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 73s 373ms/step - loss: 0.1484 - accuracy: 0.9472 - val_loss: 0.3535 - val_accuracy: 0.8756\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 73s 372ms/step - loss: 0.1411 - accuracy: 0.9508 - val_loss: 0.3219 - val_accuracy: 0.8726\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 74s 376ms/step - loss: 0.1306 - accuracy: 0.9532 - val_loss: 0.4069 - val_accuracy: 0.8381\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 73s 375ms/step - loss: 0.1219 - accuracy: 0.9574 - val_loss: 0.3946 - val_accuracy: 0.8495\n",
      "CPU times: user 40min 49s, sys: 17min 56s, total: 58min 46s\n",
      "Wall time: 12min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"rmsprop\")\n",
    "history = model.fit(\n",
    "    X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test), verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-ab65c592a9614569bd601503acc44236\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ab65c592a9614569bd601503acc44236\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ab65c592a9614569bd601503acc44236\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"fold\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"epoch\"}, {\"type\": \"quantitative\", \"field\": \"loss\", \"format\": \",.2f\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}}, {\"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"fold\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"epoch\"}, {\"type\": \"quantitative\", \"field\": \"accuracy\", \"format\": \",.2f\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"accuracy\"}}}], \"data\": {\"name\": \"data-67e4b41a53be9ddca5152b2fb7e3d352\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-67e4b41a53be9ddca5152b2fb7e3d352\": [{\"epoch\": 1, \"loss\": 0.48169928789138794, \"accuracy\": 0.7746000289916992, \"fold\": \"training\"}, {\"epoch\": 2, \"loss\": 0.2845304012298584, \"accuracy\": 0.8916000127792358, \"fold\": \"training\"}, {\"epoch\": 3, \"loss\": 0.22993528842926025, \"accuracy\": 0.9127200245857239, \"fold\": \"training\"}, {\"epoch\": 4, \"loss\": 0.20253878831863403, \"accuracy\": 0.9249200224876404, \"fold\": \"training\"}, {\"epoch\": 5, \"loss\": 0.18248070776462555, \"accuracy\": 0.9337999820709229, \"fold\": \"training\"}, {\"epoch\": 6, \"loss\": 0.1628604531288147, \"accuracy\": 0.9416400194168091, \"fold\": \"training\"}, {\"epoch\": 7, \"loss\": 0.14838670194149017, \"accuracy\": 0.9472399950027466, \"fold\": \"training\"}, {\"epoch\": 8, \"loss\": 0.14105142652988434, \"accuracy\": 0.9508000016212463, \"fold\": \"training\"}, {\"epoch\": 9, \"loss\": 0.13057024776935577, \"accuracy\": 0.9532399773597717, \"fold\": \"training\"}, {\"epoch\": 10, \"loss\": 0.12193720787763596, \"accuracy\": 0.9574400186538696, \"fold\": \"training\"}, {\"epoch\": 1, \"loss\": 0.32184529304504395, \"accuracy\": 0.8679599761962891, \"fold\": \"validation\"}, {\"epoch\": 2, \"loss\": 0.282569020986557, \"accuracy\": 0.8819199800491333, \"fold\": \"validation\"}, {\"epoch\": 3, \"loss\": 0.32343727350234985, \"accuracy\": 0.8605999946594238, \"fold\": \"validation\"}, {\"epoch\": 4, \"loss\": 0.35341426730155945, \"accuracy\": 0.8582800030708313, \"fold\": \"validation\"}, {\"epoch\": 5, \"loss\": 0.32387682795524597, \"accuracy\": 0.8593199849128723, \"fold\": \"validation\"}, {\"epoch\": 6, \"loss\": 0.35915789008140564, \"accuracy\": 0.8579599857330322, \"fold\": \"validation\"}, {\"epoch\": 7, \"loss\": 0.35346922278404236, \"accuracy\": 0.8756399750709534, \"fold\": \"validation\"}, {\"epoch\": 8, \"loss\": 0.32193154096603394, \"accuracy\": 0.8725600242614746, \"fold\": \"validation\"}, {\"epoch\": 9, \"loss\": 0.4069261848926544, \"accuracy\": 0.8380799889564514, \"fold\": \"validation\"}, {\"epoch\": 10, \"loss\": 0.3945770263671875, \"accuracy\": 0.8495200276374817, \"fold\": \"validation\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = (\n",
    "    pd.DataFrame(history.history)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"epoch\"})\n",
    "    .assign(epoch=lambda df: df.epoch + 1)\n",
    ")\n",
    "df = pd.concat(\n",
    "    [\n",
    "        _.iloc[:, 0:3].assign(fold=\"training\"),\n",
    "        _.iloc[:, [0, -2, -1]]\n",
    "        .rename(columns={\"val_accuracy\": \"accuracy\", \"val_loss\": \"loss\"})\n",
    "        .assign(fold=\"validation\"),\n",
    "    ],\n",
    "    axis=0,\n",
    ").reset_index(drop=True)\n",
    "base = alt.Chart(df).mark_line(point=True)\n",
    "loss = base.encode(x=\"epoch:Q\", y=\"loss\", color=\"fold\", tooltip=[\"epoch\", alt.Tooltip(\"loss\", format=\",.2f\")])\n",
    "accuracy = base.encode(x=\"epoch:Q\", y=\"accuracy\", color=\"fold\", tooltip=[\"epoch\", alt.Tooltip(\"accuracy\", format=\",.2f\")] )\n",
    "loss | accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Time Series Prediction\n",
    "\n",
    "We now show how to fit the models in section 10.5.2 for time series prediction. We first set up the data, and standardize each of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "NYSE = pd.read_csv(\"../datasets/NYSE.csv\")\n",
    "xdata = NYSE.loc[:, [\"DJ_return\", \"log_volume\", \"log_volatility\"]]\n",
    "istrain = NYSE.loc[:, \"train\"]\n",
    "xdata = StandardScaler().fit_transform(xdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The variable `istrain` contains a `True` for each year that is in the training set, and a `False` for each year in the test set.\n",
    "\n",
    "We first write functions to create lagged versions of the three time series. We start with a function that takes as input a data matrix and a lag $L$, and returns a lagged version of the matrix. It simply inserts $L$ rows of `NA` at the top, and truncates the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be continued"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e954c2bd-f002-4769-9beb-3d5e2ae14166",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nextjournal": {
   "nodes-edn": "{\"1bd5b5a5-b173-486f-afb2-cc6236d1bc25\" {:content \"fig = plt.figure()\\nfor i in range(9):\\n  plt.subplot(3,3,i+1)\\n  plt.tight_layout()\\n  plt.imshow(X_train[i], cmap='gray', interpolation='none')\\n  plt.title(\\\"Digit: {}\\\".format(y_train[i]))\\n  plt.xticks([])\\n  plt.yticks([])\\nfig\", :execution-hash 46961376, :name \"plot-examples\", :output-log-lines {}, :scope nil, :language \"python\", :id \"1bd5b5a5-b173-486f-afb2-cc6236d1bc25\", :compute-ref #uuid \"cd1adb58-2e89-4c29-b5de-e26e6052f992\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:6ffddb689c90d90e22d7f5b349122816\", :error nil, :exec-duration 1184, :criu-checkpoint \"6ffddb689c90d90e22d7f5b349122816\"}, \"c491dfcd-a313-4095-a993-38d39e1d17cc\" {:id \"c491dfcd-a313-4095-a993-38d39e1d17cc\", :kind \"signup\"}, \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\" {:content \"# training the model and saving metrics in history\\nhistory = model.fit(X_train, Y_train,\\n          batch_size=128, epochs=20,\\n          verbose=2,\\n          validation_data=(X_test, Y_test))\\n\\n# saving the model\\nsave_dir = \\\"/results/\\\"\\nmodel_name = 'keras_mnist.h5'\\nmodel_path = os.path.join(save_dir, model_name)\\nmodel.save(model_path)\\nprint('Saved trained model at %s ' % model_path)\\n\\n# plotting the metrics\\nfig = plt.figure()\\nplt.subplot(2,1,1)\\nplt.plot(history.history['acc'])\\nplt.plot(history.history['val_acc'])\\nplt.title('model accuracy')\\nplt.ylabel('accuracy')\\nplt.xlabel('epoch')\\nplt.legend(['train', 'test'], loc='lower right')\\n\\nplt.subplot(2,1,2)\\nplt.plot(history.history['loss'])\\nplt.plot(history.history['val_loss'])\\nplt.title('model loss')\\nplt.ylabel('loss')\\nplt.xlabel('epoch')\\nplt.legend(['train', 'test'], loc='upper right')\\n\\nplt.tight_layout()\\n\\nfig\", :execution-hash 121686107, :name \"train-model\", :output-log-lines {:stdout 43}, :scope nil, :language \"python\", :id \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\", :compute-ref #uuid \"11bbdca2-124e-4acb-8945-a4ea3486ccc8\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:40c6f986206ba36f39f6d4d9cc9d1b6c\", :error nil, :exec-duration 55633, :criu-checkpoint nil}, \"abbee50a-1c94-4887-bc63-cdcaa813c385\" {:content \"# building a linear stack of layers with the sequential model\\nmodel = Sequential()\\nmodel.add(Dense(512, input_shape=(784,)))\\nmodel.add(Activation('relu'))                            \\nmodel.add(Dropout(0.2))\\n\\nmodel.add(Dense(512))\\nmodel.add(Activation('relu'))\\nmodel.add(Dropout(0.2))\\n\\nmodel.add(Dense(10))\\nmodel.add(Activation('softmax'))\", :execution-hash 24093536, :name \"nn-setup\", :output-log-lines {}, :scope nil, :language \"python\", :id \"abbee50a-1c94-4887-bc63-cdcaa813c385\", :compute-ref #uuid \"bafcb581-ab42-4835-ab08-f84ce63f381a\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:df79881c640fa7d54f6204ee5966e7fe\", :error nil, :exec-duration 278, :criu-checkpoint \"df79881c640fa7d54f6204ee5966e7fe\"}, \"0faf4592-e228-41e5-b0df-084183540673\" {:content \"conda install -y -c anaconda \\\\\\n  tensorflow-gpu h5py cudatoolkit=8\\n  \\npip install keras\", :execution-hash 117855988, :name nil, :output-log-lines {:stdout 125}, :scope nil, :language \"bash\", :id \"0faf4592-e228-41e5-b0df-084183540673\", :compute-ref #uuid \"60fdac30-6b60-11e8-b7ce-8ab3fb67dad5\", :runtime [:runtime \"cf8e6214-03e3-4662-9f39-b40673a6c19c\"], :kind \"code\", :locked? false, :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:c52a73142e0ce65c2fea84a113deb3b6\", :error nil, :exec-duration 250893, :criu-checkpoint nil}, \"e120298c-9524-42ba-8332-f861a95db7fb\" {:id \"e120298c-9524-42ba-8332-f861a95db7fb\", :kind \"signup\"}, \"01002b11-4266-49b2-a07b-2e80165d2d1f\" {:content \"python -c 'from keras.datasets import mnist\\nmnist.load_data()'\", :output-log-lines {:stdout 130}, :language \"bash\", :id \"01002b11-4266-49b2-a07b-2e80165d2d1f\", :compute-ref #uuid \"f68ba720-6b60-11e8-b7ce-8ab3fb67dad5\", :runtime [:runtime \"cf8e6214-03e3-4662-9f39-b40673a6c19c\"], :kind \"code\", :error nil, :exec-duration 12565}, \"cf8e6214-03e3-4662-9f39-b40673a6c19c\" {:runtime/inherited-environment-variables ({:name \"PATH\", :value \"/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"} {:name \"MPLBACKEND\", :value \"svg\"} {:name \"LC_ALL\", :value \"en_US.UTF-8\"} {:name \"LANGUAGE\", :value \"en_US.en\"} {:name \"LANG\", :value \"en_US.UTF-8\"} {:name \"DEBIAN_FRONTEND\", :value \"noninteractive\"} {:name \"BASH_ENV\", :value \"/.bash_profile\"} {:name \"LD_LIBRARY_PATH\", :value \"/usr/local/nvidia/lib64/:/usr/local/cuda/lib64/\"}), :name \"Install\", :docker/environment-image \"eu.gcr.io/nextjournal-com/environment@sha256:b53e86c89d41a9e5dac4d01ede3c3152a29047a6544d3fed9169a8d3c497bfd4\", :type :nextjournal, :environment? true, :language \"bash\", :id \"cf8e6214-03e3-4662-9f39-b40673a6c19c\", :kind \"runtime\", :changed? false, :error nil, :environment [:environment {:node/id \"2d7db078-e0cf-483e-a118-89ddc1d4adab\", :article/nextjournal.id #uuid \"5accb601-b16a-4637-ae55-5fd73544a52f\", :change/nextjournal.id #uuid \"5b101a6e-8be7-4492-97da-65ef13c070a6\"}], :environment/name \"Install\", :diff \"\"}, \"03b8ac9b-d073-41c8-840b-7bc5475ef23d\" {:content \"# compiling the sequential model\\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\", :execution-hash 11359234, :name \"compile-model\", :output-log-lines {}, :scope nil, :language \"python\", :id \"03b8ac9b-d073-41c8-840b-7bc5475ef23d\", :compute-ref #uuid \"84c6272a-3205-47d3-8f20-30616ed60417\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:eb5a4df264a6f56d5c91a2cff39d2f4b\", :error nil, :exec-duration 258, :criu-checkpoint \"eb5a4df264a6f56d5c91a2cff39d2f4b\"}, \"e4c5b9d3-efa9-4e2a-9f39-6324378d9014\" {:content \"# one-hot encoding using keras' numpy-related utilities\\nn_classes = 10\\nprint(\\\"Shape before one-hot encoding: \\\", y_train.shape)\\nY_train = np_utils.to_categorical(y_train, n_classes)\\nY_test = np_utils.to_categorical(y_test, n_classes)\\nprint(\\\"Shape after one-hot encoding: \\\", Y_train.shape)\", :execution-hash 83412525, :name \"one-hot-encoding\", :output-log-lines {:stdout 3}, :scope nil, :language \"python\", :id \"e4c5b9d3-efa9-4e2a-9f39-6324378d9014\", :compute-ref #uuid \"eec373e3-f4c9-48ab-b1d7-a17e338ffb10\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:3638b6d5592ba387f913cbafc2a65a59\", :error nil, :exec-duration 322, :criu-checkpoint \"3638b6d5592ba387f913cbafc2a65a59\"}, \"60048064-31b8-4c49-9839-65f8c75d1baf\" {:content \"# let's print the shape before we reshape and normalize\\nprint(\\\"X_train shape\\\", X_train.shape)\\nprint(\\\"y_train shape\\\", y_train.shape)\\nprint(\\\"X_test shape\\\", X_test.shape)\\nprint(\\\"y_test shape\\\", y_test.shape)\\n\\n# building the input vector from the 28x28 pixels\\nX_train = X_train.reshape(60000, 784)\\nX_test = X_test.reshape(10000, 784)\\nX_train = X_train.astype('float32')\\nX_test = X_test.astype('float32')\\n\\n# normalizing the data to help with the training\\nX_train /= 255\\nX_test /= 255\\n\\n# print the final input shape ready for training\\nprint(\\\"Train matrix shape\\\", X_train.shape)\\nprint(\\\"Test matrix shape\\\", X_test.shape)\", :execution-hash 121062391, :name \"input-formatting\", :output-log-lines {:stdout 7}, :scope nil, :language \"python\", :id \"60048064-31b8-4c49-9839-65f8c75d1baf\", :compute-ref #uuid \"1cec6897-f39d-4b98-95ee-e2ba4611dc99\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:637fe341d6dfb96cc340f88038ff00f3\", :error nil, :exec-duration 345, :criu-checkpoint \"637fe341d6dfb96cc340f88038ff00f3\"}, \"7f917151-b364-4f7d-9ea7-5ed43dfdb925\" {:content \"mnist_model = load_model($$ref{{[\\\"~:output\\\",\\\"03ba7143-0469-4ab8-8850-a2a8fa3cb299\\\",\\\"keras_mnist.h5\\\"]}})\\nloss_and_metrics = mnist_model.evaluate(X_test, Y_test, verbose=2)\\n\\nprint(\\\"Test Loss\\\", loss_and_metrics[0])\\nprint(\\\"Test Accuracy\\\", loss_and_metrics[1])\", :execution-hash 78018430, :name \"evaluate\", :output-log-lines {:stdout 3}, :scope nil, :language \"python\", :id \"7f917151-b364-4f7d-9ea7-5ed43dfdb925\", :compute-ref #uuid \"a96c0fce-7a3e-4afa-9f2c-0379894056ac\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:0285ec86c76c748e096287b9eab23a65\", :error nil, :exec-duration 1998, :criu-checkpoint nil}, \"775267f3-e650-4a2c-88f0-f1bf548dc1bf\" {:content \"# imports for array-handling and plotting\\nimport numpy as np\\nimport matplotlib\\nmatplotlib.use('agg')\\nimport matplotlib.pyplot as plt\\n\\n# let's keep our keras backend tensorflow quiet\\nimport os\\nos.environ['TF_CPP_MIN_LOG_LEVEL']='3'\\n# for testing on CPU\\n#os.environ['CUDA_VISIBLE_DEVICES'] = ''\\n\\n# keras imports for the dataset and building our neural network\\nfrom keras.datasets import mnist\\nfrom keras.models import Sequential, load_model\\nfrom keras.layers.core import Dense, Dropout, Activation\\nfrom keras.utils import np_utils\", :execution-hash 51134437, :name \"imports\", :output-log-lines {:stdout 2}, :scope nil, :language \"python\", :id \"775267f3-e650-4a2c-88f0-f1bf548dc1bf\", :compute-ref #uuid \"bdbbdf3e-ce80-4c7b-9928-14e92f736a1b\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:17d09541a19f4f5064a8cedbf42a9d25\", :error nil, :exec-duration 1425, :criu-checkpoint \"17d09541a19f4f5064a8cedbf42a9d25\"}, \"21c96142-63bd-4195-a4bb-81c791175fcc\" {:content \"# load the model and create predictions on the test set\\nmnist_model = load_model($$ref{{[\\\"~:output\\\",\\\"03ba7143-0469-4ab8-8850-a2a8fa3cb299\\\",\\\"keras_mnist.h5\\\"]}})\\npredicted_classes = mnist_model.predict_classes(X_test)\\n\\n# see which we predicted correctly and which not\\ncorrect_indices = np.nonzero(predicted_classes == y_test)[0]\\nincorrect_indices = np.nonzero(predicted_classes != y_test)[0]\\nprint()\\nprint(len(correct_indices),\\\" classified correctly\\\")\\nprint(len(incorrect_indices),\\\" classified incorrectly\\\")\\n\\n# adapt figure size to accomodate 18 subplots\\nplt.rcParams['figure.figsize'] = (7,14)\\n\\nfigure_evaluation = plt.figure()\\n\\n# plot 9 correct predictions\\nfor i, correct in enumerate(correct_indices[:9]):\\n    plt.subplot(6,3,i+1)\\n    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\\n    plt.title(\\n      \\\"Predicted: {}, Truth: {}\\\".format(predicted_classes[correct],\\n                                        y_test[correct]))\\n    plt.xticks([])\\n    plt.yticks([])\\n\\n# plot 9 incorrect predictions\\nfor i, incorrect in enumerate(incorrect_indices[:9]):\\n    plt.subplot(6,3,i+10)\\n    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\\n    plt.title(\\n      \\\"Predicted {}, Truth: {}\\\".format(predicted_classes[incorrect], \\n                                       y_test[incorrect]))\\n    plt.xticks([])\\n    plt.yticks([])\\n\\nfigure_evaluation\", :execution-hash 112246374, :name \"evaluate-examples\", :output-log-lines {:stdout 4}, :scope nil, :language \"python\", :id \"21c96142-63bd-4195-a4bb-81c791175fcc\", :compute-ref #uuid \"5deec13f-9de4-41f9-8604-6555b50090b8\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:5858e1475f53af6f4fd00616de1b85fd\", :error nil, :exec-duration 2366, :criu-checkpoint nil}, \"941d6d2b-7fec-420f-bd09-ca79ce5a63f3\" {:content \"nvidia-smi\", :output-log-lines {:stdout 17}, :language \"bash\", :id \"941d6d2b-7fec-420f-bd09-ca79ce5a63f3\", :compute-ref #uuid \"9dce70cf-ec27-4c57-b18b-f4f4fe625f4a\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :error nil, :exec-duration 372}, \"6f3a733f-53eb-402d-86be-db838828a0b8\" {:runtime/inherited-environment-variables ({:name \"PATH\", :value \"/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"} {:name \"MPLBACKEND\", :value \"svg\"} {:name \"LC_ALL\", :value \"en_US.UTF-8\"} {:name \"LANGUAGE\", :value \"en_US.en\"} {:name \"LANG\", :value \"en_US.UTF-8\"} {:name \"DEBIAN_FRONTEND\", :value \"noninteractive\"} {:name \"BASH_ENV\", :value \"/.bash_profile\"} {:name \"LD_LIBRARY_PATH\", :value \"/usr/local/nvidia/lib64/:/usr/local/cuda/lib64/\"}), :name \"Main\", :output-log-lines nil, :type :nextjournal, :language \"python\", :id \"6f3a733f-53eb-402d-86be-db838828a0b8\", :compute-ref #uuid \"e2e60bf5-1e14-46af-b7ec-91fcdfcc3c97\", :kind \"runtime\", :error nil, :environment [:environment \"cf8e6214-03e3-4662-9f39-b40673a6c19c\"], :resources {:machine-type \"n1-standard-4\", :accelerator-type \"nvidia-tesla-k80\", :accelerator-count 1}}, \"a67d25ef-4ca3-438d-a558-331d91579e54\" {:content \"(X_train, y_train), (X_test, y_test) = mnist.load_data()\", :execution-hash 11114680, :name \"train-test-split\", :output-log-lines {}, :scope nil, :language \"python\", :id \"a67d25ef-4ca3-438d-a558-331d91579e54\", :compute-ref #uuid \"70b3132b-2982-44f8-ab7d-89bfce4f5a9a\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:b905b975133ee8dd76a019ab51b5f1ea\", :error nil, :exec-duration 472, :criu-checkpoint \"b905b975133ee8dd76a019ab51b5f1ea\"}, \"9ed29e16-0934-4ecd-a00c-2a2b69314a80\" {:content \"fig = plt.figure()\\nplt.subplot(2,1,1)\\nplt.imshow(X_train[0], cmap='gray', interpolation='none')\\nplt.title(\\\"Digit: {}\\\".format(y_train[0]))\\nplt.xticks([])\\nplt.yticks([])\\nplt.subplot(2,1,2)\\nplt.hist(X_train[0].reshape(784))\\nplt.title(\\\"Pixel Value Distribution\\\")\\nfig\", :execution-hash 109300958, :popover false, :name \"pixel-distribution\", :line-results \"None\\nAxes(0.125,0.53;0.775x0.35)\\nAxesImage(87.5,371;542.5x245)\\nText(0.5,1,u'Class 5')\\n([], <a list of 0 Text xtickla...\\n([], <a list of 0 Text ytickla...\\nAxes(0.125,0.11;0.775x0.35)\\n(array([ 639.,   11.,    6.,  ...\\nText(0.5,1,u'Pixel Value Distr...\\nFigure(700x700)\\n\", :active-requests [], :output-log-lines {}, :scope nil, :commands {}, :language \"python\", :id \"9ed29e16-0934-4ecd-a00c-2a2b69314a80\", :compute-ref #uuid \"3f78a8e8-c31a-46c1-980f-79f722a34716\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:b9c5102545883d7241b33a5ec01a6475\", :resolved-content \"\", :error nil, :exec-duration 661, :criu-checkpoint \"b9c5102545883d7241b33a5ec01a6475\", :stdout \"\"}, \"2851a44b-af0c-46ef-9e08-36877348901e\" {:content \"print(np.unique(y_train, return_counts=True))\", :execution-hash 118322401, :name \"y-value-counts\", :output-log-lines {:stdout 2}, :scope nil, :language \"python\", :id \"2851a44b-af0c-46ef-9e08-36877348901e\", :compute-ref #uuid \"acf64dbb-8270-4ca9-9d9c-dd12f9348d67\", :runtime [:runtime \"6f3a733f-53eb-402d-86be-db838828a0b8\"], :kind \"code\", :docker-image \"eu.gcr.io/nextjournal-com/checkpoints:a6d4fe001c7557d8b098c03d7fa7a8a5\", :error nil, :exec-duration 353, :criu-checkpoint \"a6d4fe001c7557d8b098c03d7fa7a8a5\"}, \"7181e0a8-1b04-49fd-a703-eee3b044ddfa\" {:id \"7181e0a8-1b04-49fd-a703-eee3b044ddfa\", :kind \"reference\", :link [:output \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\" \"keras_mnist.h5\"]}, \"ac0a2d99-d702-480e-80ae-c9498cf04abe\" {:id \"ac0a2d99-d702-480e-80ae-c9498cf04abe\", :kind \"reference\", :link [:output \"03ba7143-0469-4ab8-8850-a2a8fa3cb299\" \"keras_mnist.h5\"]}}",
   "runtime-id": "6f3a733f-53eb-402d-86be-db838828a0b8",
   "url": "https://nextjournal.com/gkoehler/digit-recognition-with-keras"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
