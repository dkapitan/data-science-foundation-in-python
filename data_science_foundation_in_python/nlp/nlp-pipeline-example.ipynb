{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "nlp-pipeline-example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNLFOgZKWZQGuRni5kSmwqD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predict detractors from reviews\n",
        "\n",
        "## Objective\n",
        "Predict a 'detractor' such that restaurant owner can look-up interesting (negative) feedback and act upon that."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "from imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier    \n",
        "import pandas as pd\n",
        "import pendulum\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import spacy\n",
        "\n",
        "\n",
        "# only use 2019 data as example\n",
        "df = pd.read_parquet(\"https://github.com/jads-nl/public-lectures/blob/main/nlp/data/dutch-restaurant-reviews-per-year/reviewYear%3D2019/058d741d776d45f18e0ccc51f71173dc.parquet?raw=true\")\n",
        "\n",
        "# initiate spacy model\n",
        "nlp = spacy.load(\"nl_core_news_lg\")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gH9ueGhkreG",
        "outputId": "d429b40e-fa49-4314-af56-ca96adf77f1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "um0Kzo9HqB-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select main columns"
      ],
      "metadata": {
        "id": "7pFiAZpeni-R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "reviews = df.loc[:, ['restoId', 'reviewerId', 'reviewerFame', 'reviewerNumReviews', 'reviewText']].copy()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Mq5--vRCnWpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format date columns"
      ],
      "metadata": {
        "id": "oOV7SzHNnYtH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "def parse_date(date):\n",
        "    return pendulum.from_format(date, fmt=\"D MMM YYYY\", locale=\"nl\")\n",
        "\n",
        "reviews[\"reviewDate\"] = df.reviewDate.apply(parse_date).dt.date"
      ],
      "outputs": [],
      "metadata": {
        "id": "4cli4hW9k1Yz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format numerical columns"
      ],
      "metadata": {
        "id": "93z9CaHLmhOo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "def clean_price(string):\n",
        "    \"Remove euro sign and whitespace in price\"\n",
        "    if string:\n",
        "        return float(string.split(\" \")[-1])\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "reviews[\"avgPrice\"] = df[\"avgPrice\"].fillna(0).apply(clean_price)\n",
        "\n",
        "\n",
        "# numerical columns have comma as decimal seperator --> cast to floats\n",
        "numerical_cols = [\n",
        "    \"scoreFood\",\n",
        "    \"scoreService\",\n",
        "    \"scoreDecor\",\n",
        "    \"reviewScoreOverall\",\n",
        "    \"scoreTotal\",\n",
        "]\n",
        "for col in numerical_cols:\n",
        "    reviews[col] = pd.to_numeric(df[col])"
      ],
      "outputs": [],
      "metadata": {
        "id": "YoQkhlkGnyOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format ordinal columns"
      ],
      "metadata": {
        "id": "8-u5eSdSoBjT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "map_scores = {\n",
        "    \"waitingTimeScore\": {\n",
        "        None: 0,\n",
        "        \"Hoog tempo\": 1,\n",
        "        \"Kort\": 2,\n",
        "        \"Redelijk\": 3,\n",
        "        \"Kan beter\": 4,\n",
        "        \"Lang\": 5,\n",
        "    },\n",
        "    \"valueForPriceScore\": {\n",
        "        None: 0,\n",
        "        \"Erg gunstig\": 1,\n",
        "        \"Gunstig\": 2,\n",
        "        \"Redelijk\": 3,\n",
        "        \"Precies goed\": 4,\n",
        "        \"Kan beter\": 5,\n",
        "    },\n",
        "    \"noiseLevelScore\": {\n",
        "        None: 0,\n",
        "        \"Erg rustig\": 1,\n",
        "        \"Rustig\": 2,\n",
        "        \"Precies goed\": 3,\n",
        "        \"Rumoerig\": 4,\n",
        "    },\n",
        "    \"reviewerFame\": {\n",
        "        None: 0,\n",
        "        \"Proever\": 1,\n",
        "        \"Fijnproever\": 2,\n",
        "        \"Expertproever\": 3,\n",
        "        \"Meesterproever\": 4\n",
        "    }\n",
        "}\n",
        "\n",
        "for col in map_scores.keys():\n",
        "    reviews[col] = (\n",
        "        df[col].apply(lambda x: map_scores[col].get(x, None)).astype(\"Int64\")\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "4ZjO0HKVoRUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text pre-processing"
      ],
      "metadata": {
        "id": "3VCQPqZKp4AK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter reviews that are short or in process"
      ],
      "metadata": {
        "id": "9vPzKjnurVVb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "def validate_review(review):\n",
        "    if review == '- Recensie is momenteel in behandeling -' or len(review) < 4:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "    \n",
        "\n",
        "reviews['is_valid'] = reviews.reviewText.apply(validate_review)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Hxs-NOL5r5o3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add simple features"
      ],
      "metadata": {
        "id": "9BXVyWnQvZ9P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "reviews['review_char_length_'] = df.reviewText.apply(lambda x: len(x))"
      ],
      "outputs": [],
      "metadata": {
        "id": "6uma80i9vmd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize and create Document-Term Matrix\n",
        "\n",
        "We will use [pandas sparse data structures](https://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html) to save memory. Note cell below takes about 9 minutes to complete."
      ],
      "metadata": {
        "id": "AkgXBreJsH8z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "%%time\n",
        "def tokenize_simple(text):\n",
        "    \"\"\"Tokenizer returning lowercase tokens with no stop words, no punctuation and no words with encoding errors\"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [token.lower_ for token in doc if not (token.is_stop or token.is_punct or (\"\\\\\" in token.lower_))]\n",
        "\n",
        "\n",
        "# some abbreviations aren't in spaCy's default Dutch stopwords list, so we add them\n",
        "nlp.Defaults.stop_words.update(['n', 'â€™n', 't'])\n",
        "\n",
        "count_vectorizer = CountVectorizer(tokenizer=tokenize_simple, stop_words=nlp.Defaults.stop_words, ngram_range=(1,1))\n",
        "dtm = pd.DataFrame.sparse.from_spmatrix(count_vectorizer.fit_transform(reviews.reviewText), columns=count_vectorizer.get_feature_names_out())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8min, sys: 116 ms, total: 8min\n",
            "Wall time: 8min\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-HflkHnscpd",
        "outputId": "8e8e91bf-20a4-410f-94ee-55c9c9be5da4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will only keep words in the DTM that occur twice or more over all the reviews. This reduces the width of the DTM."
      ],
      "metadata": {
        "id": "zMK0eFY9NZrz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "token_filter = (dtm.sum() > 2)\n",
        "token_filter[token_filter == True]\n",
        "print(f\"Full DTM: {dtm.shape}\")\n",
        "print(f\"Filtered DTM: {dtm.loc[:, token_filter].shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full DTM: (47048, 32820)\n",
            "Filtered DTM: (47048, 11047)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOzA_2btLesV",
        "outputId": "f1727982-1e53-4af0-fc62-c0012449c938"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary classification: `is_detractor`"
      ],
      "metadata": {
        "id": "9QOmgqE2w6Yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Y"
      ],
      "metadata": {
        "id": "gMfvALr-xxkc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "reviews[\"is_detractor\"] = reviews.reviewScoreOverall.apply(lambda x: True if x <= 6 else False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "JlsdS0FZx2Kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split\n",
        "\n",
        "(Cell below takes about two minute)."
      ],
      "metadata": {
        "id": "RVQwGzDeyER4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "%%time\n",
        "X = reviews[reviews.is_valid].drop(columns=[\"reviewDate\", \"reviewText\", \"scoreFood\", \"scoreService\", \"scoreDecor\", \"reviewScoreOverall\", \"scoreTotal\", \"is_detractor\"])\n",
        "y = reviews[reviews.is_valid].is_detractor\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in sss.split(X,y):\n",
        "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    dtm_train, dtm_test = dtm.loc[reviews.is_valid, token_filter].iloc[train_index, :], dtm.loc[reviews.is_valid, token_filter].iloc[test_index, :]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 29s, sys: 64 ms, total: 1min 29s\n",
            "Wall time: 1min 29s\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-fRiXteyFiF",
        "outputId": "af85aac2-a7bd-4ea2-a3e0-4766216cf447"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BalancedBaggingClassifier - without DTM\n",
        "\n"
      ],
      "metadata": {
        "id": "qYS0K_jf4cCM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "%%time\n",
        "clf1 = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
        "                                sampling_strategy='auto',\n",
        "                                replacement=False,\n",
        "                                random_state=0)\n",
        "clf1.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 458 ms, sys: 8.01 ms, total: 466 ms\n",
            "Wall time: 465 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
              "                          random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zONADb3Q0cUU",
        "outputId": "6efda006-b524-4cdb-9744-ac1b92fce97b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will skip fine-tuning the model, our purpose is to compare it with a model that adds text. Using the balanced accuracy to compare, which is defined as the average of recall obtained on each class."
      ],
      "metadata": {
        "id": "_DT_3yx-_6J_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "balanced_accuracy_score(y_test, clf1.predict(X_test)).round(2)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.73"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI-edVTr2SxA",
        "outputId": "8aec2b61-b2c8-4a98-aebf-0ebd180e2d2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BalancedBaggingClassifier - with DTM\n",
        "\n",
        "(Cell below takes about 50 minutes on Google Colab)"
      ],
      "metadata": {
        "id": "8h1CYS6F9E9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "%%time\n",
        "clf2 = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
        "                                sampling_strategy='auto',\n",
        "                                replacement=False,\n",
        "                                random_state=0)\n",
        "clf2.fit(dtm_train.join(X_train), y_train) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/dkapitan/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:616: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 56s, sys: 1min 19s, total: 4min 16s\n",
            "Wall time: 4min 16s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
              "                          random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZH6hYFAHpPT",
        "outputId": "f66accb5-0e34-4486-a75c-a43a0ad6f408"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "balanced_accuracy_score(y_test, clf2.predict(dtm_test.join(X_test))).round(2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/dkapitan/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:616: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2qh0773Jfqp",
        "outputId": "d7468855-5890-455f-f3b2-c68af698cb1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Closing remarks\n",
        "\n",
        "We have illustrated how a simple bag-of-words model can add to the performance of a classifier that uses structured data. We haven't optimized the modeling at all, but done a simple like-to-like comparison with the same parameters.\n",
        "\n",
        "Note that working with text requires more engineering: you need to make decisions about how to store and process the data because it can quickly expand beyond the memory of your (virtual) machine. Even with this simple model, we have used over 700 features from a truncated document-term matrix."
      ],
      "metadata": {
        "id": "f3oblv62bZqo"
      }
    }
  ]
}